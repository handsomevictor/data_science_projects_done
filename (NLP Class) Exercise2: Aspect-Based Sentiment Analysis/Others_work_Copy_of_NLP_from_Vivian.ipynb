{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy_of_NLP_Vivian.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"PKWK5RGYuDZV","executionInfo":{"status":"ok","timestamp":1647798242364,"user_tz":-60,"elapsed":1589,"user":{"displayName":"Victor Li","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16877734298003550452"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import os\n","pd.set_option('display.max_colwidth', 200)\n","import torch\n","from torch.optim import AdamW\n","from sklearn.model_selection import train_test_split\n","from torch.utils.data import Dataset, DataLoader,TensorDataset, RandomSampler, SequentialSampler\n","\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","from collections import defaultdict\n","import numpy as np "]},{"cell_type":"markdown","source":["Reference\n","https://curiousily.com/posts/sentiment-analysis-with-bert-and-hugging-face-using-pytorch-and-python/"],"metadata":{"id":"B1IZ_HXQpEkP"}},{"cell_type":"code","source":["!pip install transformers --quiet\n","import transformers\n","from transformers import AutoTokenizer, AutoModel"],"metadata":{"id":"YOECAHPSvFbO","executionInfo":{"status":"ok","timestamp":1647798246656,"user_tz":-60,"elapsed":4315,"user":{"displayName":"Victor Li","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16877734298003550452"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MwG7NENtvHDd","outputId":"01167235-6adf-4a66-d090-f00101a75d51","executionInfo":{"status":"ok","timestamp":1647798248430,"user_tz":-60,"elapsed":1778,"user":{"displayName":"Victor Li","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16877734298003550452"}}},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["import torch\n","def get_default_device():\n","    \"\"\"Pick GPU if available, else CPU\"\"\"\n","    if torch.cuda.is_available():\n","        return torch.device('cuda')\n","    else:\n","        return torch.device('cpu')"],"metadata":{"id":"Ta2Y59wJ9OGL","executionInfo":{"status":"ok","timestamp":1647798248431,"user_tz":-60,"elapsed":27,"user":{"displayName":"Victor Li","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16877734298003550452"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["class BertAsc(nn.Module):\n","    \"\"\"Full model\"\"\"\n","    def __init__(self, model_name=\"activebus/BERT_Review\", n_classes=3):\n","        super(BertAsc, self).__init__()\n","        self.bert = AutoModel.from_pretrained(model_name)\n","        self.dropout = nn.Dropout(p=0.2)\n","        self.linear = nn.Linear(self.bert.config.hidden_size, n_classes)\n","\n","    #############################################\n","    def forward(self, input_ids, attention_mask):\n","      output = self.bert(\n","        input_ids=input_ids,\n","        attention_mask=attention_mask\n","      )\n","      x = output[\"pooler_output\"]\n","      x = self.dropout(x)\n","      x = self.linear(x)\n","  \n","      return F.softmax(x, dim=1)"],"metadata":{"id":"ynqowzv39e6f","executionInfo":{"status":"ok","timestamp":1647798249622,"user_tz":-60,"elapsed":2,"user":{"displayName":"Victor Li","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16877734298003550452"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# load dataset\n","\n","def create_data_loader(df, tokenizer, batch_size, max_len=164):\n","  ds = ReviewDataset(\n","    reviews=df.X.to_numpy(),\n","    targets=df.Sentiment.to_numpy(),\n","    tokenizer=tokenizer,\n","    max_len=max_len\n","  )\n","  return DataLoader(\n","    ds,\n","    batch_size=batch_size,\n","    num_workers=4\n","  )\n","\n","def split_dataframe(df, test_size=0.2):\n","  df_train, df_val = train_test_split(\n","  df,\n","  test_size=test_size,\n","  random_state=42)\n","  return df_train, df_val\n","\n","\n","# Dataloader\n","\n","class ReviewDataset(Dataset):\n","\n","  def __init__(self, reviews, targets, tokenizer, max_len=164):\n","    self.reviews = reviews\n","    self.targets = targets\n","    self.tokenizer = tokenizer\n","    self.max_len = max_len\n","  \n","  def __len__(self):\n","    return len(self.reviews)\n","  \n","  def __getitem__(self, item):\n","    review = str(self.reviews[item])\n","    target = self.targets[item]\n","\n","    encoding = self.tokenizer.encode_plus(\n","        review, \n","        add_special_tokens=True, \n","        return_attention_mask=True,\n","        return_token_type_ids=False,\n","        return_tensors=\"pt\",\n","        padding='max_length',\n","        max_length=self.max_len\n","        )\n","\n","    return {\n","      'review_text': review,\n","      'input_ids': encoding['input_ids'].flatten(),\n","      'attention_mask': encoding['attention_mask'].flatten(),\n","      'targets': torch.tensor(target, dtype=torch.long)\n","    }"],"metadata":{"id":"AoKiV0gmJ5NV","executionInfo":{"status":"ok","timestamp":1647798250667,"user_tz":-60,"elapsed":2,"user":{"displayName":"Victor Li","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16877734298003550452"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"KsPL5Pz5-ejl","executionInfo":{"status":"ok","timestamp":1647798251219,"user_tz":-60,"elapsed":1,"user":{"displayName":"Victor Li","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16877734298003550452"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# train functions\n","\n","def train_epoch(model, data_loader, loss_fn, optimizer, device, scheduler, n_examples):\n","    model = model.train()\n","\n","    losses = []\n","    correct_predictions = 0\n","    \n","    for d in data_loader:\n","      input_ids = d[\"input_ids\"].to(device)\n","      attention_mask = d[\"attention_mask\"].to(device)\n","      targets = d[\"targets\"].to(device)\n","\n","      outputs = model(\n","        input_ids=input_ids,\n","        attention_mask=attention_mask\n","      )\n","\n","      _, preds = torch.max(outputs, dim=1)\n","      loss = loss_fn(outputs, targets)\n","\n","      correct_predictions += torch.sum(preds == targets)\n","      losses.append(loss.item())\n","\n","      loss.backward()\n","      nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n","      optimizer.step()\n","      scheduler.step()\n","      optimizer.zero_grad()\n","    \n","    return (correct_predictions.double() / n_examples), np.mean(losses)\n"],"metadata":{"id":"3RB27LUFBQCa","executionInfo":{"status":"ok","timestamp":1647799735702,"user_tz":-60,"elapsed":234,"user":{"displayName":"Victor Li","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16877734298003550452"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"n8rADbY--iZo","executionInfo":{"status":"ok","timestamp":1647796920194,"user_tz":-60,"elapsed":1,"user":{"displayName":"Victor Li","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16877734298003550452"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def eval_model(model, data_loader, loss_fn, device, n_examples):\n","    model = model.eval()\n","\n","    losses = []\n","    correct_predictions = 0\n","\n","    with torch.no_grad():\n","      for d in data_loader:\n","        input_ids = d[\"input_ids\"].to(device)\n","        attention_mask = d[\"attention_mask\"].to(device)\n","        targets = d[\"targets\"].to(device)\n","\n","        outputs = model(\n","          input_ids=input_ids,\n","          attention_mask=attention_mask\n","        )\n","        _, preds = torch.max(outputs, dim=1)\n","\n","        loss = loss_fn(outputs, targets)\n","\n","        correct_predictions += torch.sum(preds == targets)\n","        losses.append(loss.item())\n","\n","    return (correct_predictions.double() / n_examples), np.mean(losses) "],"metadata":{"id":"TgZEr_OyBQHq","executionInfo":{"status":"ok","timestamp":1647799764071,"user_tz":-60,"elapsed":2,"user":{"displayName":"Victor Li","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16877734298003550452"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["def predict_model(model, data_loader, loss_fn, device, n_examples):\n","    model = model.eval()\n","\n","    with torch.no_grad():\n","      for d in data_loader:\n","        input_ids = d[\"input_ids\"].to(device)\n","        attention_mask = d[\"attention_mask\"].to(device)\n","        targets = d[\"targets\"].to(device)\n","\n","        outputs = model(\n","          input_ids=input_ids,\n","          attention_mask=attention_mask\n","        )\n","        _, preds = torch.max(outputs, dim=1)\n","\n","    return preds"],"metadata":{"id":"vjaIlvAx2Hi3","executionInfo":{"status":"ok","timestamp":1647798254706,"user_tz":-60,"elapsed":1,"user":{"displayName":"Victor Li","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16877734298003550452"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["\n","class Classifier:\n","    \"\"\"The Classifier\"\"\"\n","\n","    def __init__(self):\n","        self.train = pd.read_csv('/content/drive/MyDrive/DSBA M2/2 NLP/exercise_2/data/traindata.csv',sep='\\t', header=None)\n","        mapping = {'positive':1,'negative':2,'neutral':0}\n","        self.train[0]=self.train[0].map(mapping)\n","        self.train.columns = ['Sentiment','Aspect','Target_word','Placing','Review']\n","        self.train['X'] = self.train.apply(lambda x: (str(x['Aspect']) + '#' + x['Target_word'] + '/' + x['Review']),axis=1)\n","        self.train_data = self.train[['X','Sentiment']]\n","\n","        self.PRETRAIN_MODEL = \"activebus/BERT_Review\"\n","\n","\n","        BS = 10\n","        self.EPOCHS = 1\n","        MAX_LEN = 164\n","        self.device = get_default_device()\n","\n","        # preprocess\n","        self.tokenizer = AutoTokenizer.from_pretrained(self.PRETRAIN_MODEL)\n","        self.df_train, self.df_val = split_dataframe(self.train_data, test_size = 0.1)\n","        self.train_dataloader = create_data_loader(self.df_train, tokenizer, BS, \n","                                        max_len= MAX_LEN)\n","        \n","        self.val_data_loader = create_data_loader(self.df_val, tokenizer, BS,\n","                                      max_len = MAX_LEN)\n","        \n","        # set upd training\n","        self.model = BertAsc(model_name=\"activebus/BERT_Review\", n_classes=3)\n","        # self.model = self.model.train()\n","\n","        self.model = self.model.to(device)\n","        self.optimizer = AdamW(self.model.parameters(), lr=2e-5)\n","        total_steps = len(self.train_dataloader) * EPOCHS\n","        self.scheduler = transformers.get_linear_schedule_with_warmup(\n","            self.optimizer,\n","            num_warmup_steps=0,\n","            num_training_steps=total_steps\n","        )\n","        self.loss_fn = nn.CrossEntropyLoss().to(self.device)\n","\n","        self.history = defaultdict(list)\n","        self.best_accuracy = 0\n","\n","    #############################################\n","    def train(self, trainfile, devfile=None):\n","\n","        for epoch in range(self.EPOCHS):\n","          print(f'Epoch {epoch + 1}/{self.EPOCHS}')\n","          print('-' * 10)\n","          train_acc, train_loss = train_epoch(\n","              self.model,\n","              self.train_dataloader,    \n","              self.loss_fn, \n","              self.optimizer, \n","              self.device, \n","              self.scheduler, \n","              len(self.df_train)\n","         )\n","\n","          val_acc, val_loss = eval_model(\n","              self.model,\n","              self.val_data_loader,\n","              loss_fn, \n","              device, \n","              len(self.df_val)\n","          )\n","\n","          print(f'Val   loss {val_loss} accuracy {val_acc}')\n","          print()\n","\n","          self.history['train_acc'].append(train_acc)\n","          self.history['train_loss'].append(train_loss)\n","          self.history['val_acc'].append(val_acc)\n","          self.history['val_loss'].append(val_loss)\n","\n","          if val_acc > self.best_accuracy:\n","             torch.save(self.model.state_dict(), 'best_model_state.bin')\n","             best_accuracy = val_acc\n","\n","    def predict(self, datafile):\n","        device = get_default_device()\n","        self.model = BertAsc(model_name=\"activebus/BERT_Review\", n_classes=3)\n","        self.model.load_state_dict(torch.load('best_model_state.bin'))\n","        self.model = self.model.to(device)\n","        self.model = self.model.eval()\n","        \"\"\"Predicts class labels for the input instances in file 'datafile'\n","        Returns the list of predicted labels\n","        \"\"\"\n","        # We load the data \n","        test = pd.read_csv('/content/drive/MyDrive/DSBA M2/2 NLP/exercise_2/data/devdata.csv',sep='\\t', header=None)\n","        mapping = {'positive':1,'negative':2,'neutral':0}\n","        test[0]=test[0].map(mapping)\n","        test.columns = ['Sentiment','Aspect','Target_word','Placing','Review']\n","        test['X'] = test.apply(lambda x: (str(x['Aspect']) + '#' + x['Target_word'] + '/' + x['Review']),axis=1)\n","        test_data = test[['X','Sentiment']]\n","\n","        # PARAMS\n","        #self.PRETRAIN_MODEL = \"activebus/BERT_Review\"\n","        BS = 10\n","        EPOCHS = 7\n","        MAX_LEN = 164\n","        loss_fn = nn.CrossEntropyLoss().to(device)\n","        #self.optimizer = AdamW(self.model.parameters(), lr=2e-5)\n","\n","\n","        # preprocess\n","        tokenizer = AutoTokenizer.from_pretrained(self.PRETRAIN_MODEL)\n","        test_dataloader = create_data_loader(test_data, tokenizer, 10, max_len = 164)\n","        #self.pred = predict_model(self.model, test_dataloader, loss_fn, device, len(test_data))\n","        \n","        predictions = []\n","\n","        with torch.no_grad():\n","          for d in test_dataloader:\n","            texts = d[\"review_text\"]\n","            input_ids = d[\"input_ids\"].to(device)\n","            attention_mask = d[\"attention_mask\"].to(device)\n","            targets = d[\"targets\"].to(device)\n","\n","            outputs = self.model(\n","            input_ids=input_ids,\n","            attention_mask=attention_mask)\n","\n","            preds = outputs.argmax(1)\n","            \n","            preds = preds.cpu().numpy()\n","   \n","            predictions += [\n","                            {2:'positive',1:'neutral', 0:'negative'}[x] for x in preds\n","            ]\n","        \n","        return  predictions"],"metadata":{"id":"THJgT7nEbY5V","executionInfo":{"status":"ok","timestamp":1647799840170,"user_tz":-60,"elapsed":369,"user":{"displayName":"Victor Li","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16877734298003550452"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"vPQ3hdEP-7A1","executionInfo":{"status":"ok","timestamp":1647799840578,"user_tz":-60,"elapsed":1,"user":{"displayName":"Victor Li","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16877734298003550452"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["import time, sys\n","import numpy as np\n","\n","\n","def set_reproducible():\n","    # The below is necessary to have reproducible behavior.\n","    import random as rn\n","    import os\n","    os.environ['PYTHONHASHSEED'] = '0'\n","    # The below is necessary for starting Numpy generated random numbers\n","    # in a well-defined initial state.\n","    np.random.seed(17)\n","    # The below is necessary for starting core Python generated random numbers\n","    # in a well-defined state.\n","    rn.seed(12345)\n","\n","\n","\n","def load_label_output(filename):\n","    with open(filename, 'r', encoding='UTF-8') as f:\n","        return [line.strip().split(\"\\t\")[0] for line in f if line.strip()]\n","\n","\n","\n","def eval_list(glabels, slabels):\n","    if (len(glabels) != len(slabels)):\n","        print(\"\\nWARNING: label count in system output (%d) is different from gold label count (%d)\\n\" % (\n","        len(slabels), len(glabels)))\n","    n = min(len(slabels), len(glabels))\n","    incorrect_count = 0\n","    for i in range(n):\n","        if slabels[i] != glabels[i]: incorrect_count += 1\n","    acc = (n - incorrect_count) / n\n","    return acc*100\n","\n","\n","\n","def train_and_eval(classifier, trainfile, devfile, testfile, run_id):\n","    print(f\"\\nRUN: {run_id}\")\n","    print(\"  %s.1. Training the classifier...\" % str(run_id))\n","    classifier.train(trainfile, devfile)\n","    print()\n","    print(\"  %s.2. Eval on the dev set...\" % str(run_id), end=\"\")\n","    slabels = classifier.predict(devfile)\n","    glabels = load_label_output(devfile)\n","    devacc = eval_list(glabels, slabels)\n","    print(\" Acc.: %.2f\" % devacc)\n","    testacc = -1\n","    if testfile is not None:\n","        # Evaluation on the test data\n","        print(\"  %s.3. Eval on the test set...\" % str(run_id), end=\"\")\n","        slabels = classifier.predict(testfile)\n","        glabels = load_label_output(testfile)\n","        testacc = eval_list(glabels, slabels)\n","        print(\" Acc.: %.2f\" % testacc)\n","    print()\n","    return (devacc, testacc)\n","\n","\n","#if __name__ == \"__main__\":\n","set_reproducible()\n","n_runs = 1\n","trainfile =  \"/content/drive/MyDrive/DSBA M2/2 NLP/exercise_2/data/traindata.csv\"\n","devfile =  \"/content/drive/MyDrive/DSBA M2/2 NLP/exercise_2/data/devdata.csv\"\n","testfile = None\n","\n","# Runs\n","start_time = time.perf_counter()\n","devaccs = []\n","testaccs = []\n","for i in range(1, n_runs+1):\n","    classifier =  Classifier()\n","    devacc, testacc = train_and_eval(classifier, trainfile, devfile, testfile, i)\n","    devaccs.append(np.round(devacc,2))\n","    testaccs.append(np.round(testacc,2))\n","print('\\nCompleted %d runs.' % n_runs)\n","total_exec_time = (time.perf_counter() - start_time)\n","print(\"Dev accs:\", devaccs)\n","print(\"Test accs:\", testaccs)\n","print()\n","print(\"Mean Dev Acc.: %.2f (%.2f)\" % (np.mean(devaccs), np.std(devaccs)))\n","print(\"Mean Test Acc.: %.2f (%.2f)\" % (np.mean(testaccs), np.std(testaccs)))\n","print(\"\\nExec time: %.2f s. ( %d per run )\" % (total_exec_time, total_exec_time / n_runs))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":507},"id":"Jrs6bb3OFz3g","outputId":"65f6aa91-341a-48f1-d3ce-43edb05dd806","executionInfo":{"status":"error","timestamp":1647799845745,"user_tz":-60,"elapsed":4932,"user":{"displayName":"Victor Li","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16877734298003550452"}}},"execution_count":33,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at activebus/BERT_Review were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["\n","RUN: 1\n","  1.1. Training the classifier...\n"]},{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-33-21dc017aaaec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_runs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0mdevacc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestacc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_and_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0mdevaccs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevacc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mtestaccs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestacc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-33-21dc017aaaec>\u001b[0m in \u001b[0;36mtrain_and_eval\u001b[0;34m(classifier, trainfile, devfile, testfile, run_id)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nRUN: {run_id}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"  %s.1. Training the classifier...\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"  %s.2. Eval on the dev set...\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: 'DataFrame' object is not callable"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"rfxYo8blWmrt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = BertAsc(model_name=\"activebus/BERT_Review\", n_classes=3)\n","model.load_state_dict(torch.load('best_model_state.bin'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N7h3wgUsYGh6","executionInfo":{"status":"ok","timestamp":1647798337763,"user_tz":-60,"elapsed":2464,"user":{"displayName":"Victor Li","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16877734298003550452"}},"outputId":"779c0292-cdea-4bda-e4e3-a413b94d25bd"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at activebus/BERT_Review were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["device = get_default_device()\n","model = model.to(device)"],"metadata":{"id":"rT21DXQaaAQV","executionInfo":{"status":"ok","timestamp":1647798365117,"user_tz":-60,"elapsed":232,"user":{"displayName":"Victor Li","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16877734298003550452"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["test = pd.read_csv('/content/drive/MyDrive/DSBA M2/2 NLP/exercise_2/data/devdata.csv',sep='\\t', header=None)\n","mapping = {'positive':1,'negative':2,'neutral':0}\n","test[0] = test[0].map(mapping)\n","test.columns = ['Sentiment','Aspect','Target_word','Placing','Review']\n","test['X'] = test.apply(lambda x: (str(x['Aspect']) + '#' + x['Target_word'] + '/' + x['Review']),axis=1)\n","test_data = test[['X','Sentiment']]"],"metadata":{"id":"j5QBD57GYGk6","executionInfo":{"status":"ok","timestamp":1647798367899,"user_tz":-60,"elapsed":221,"user":{"displayName":"Victor Li","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16877734298003550452"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["# PARAMS\n","#self.PRETRAIN_MODEL = \"activebus/BERT_Review\"\n","BS = 10\n","EPOCHS = 7\n","MAX_LEN = 164\n","loss_fn = nn.CrossEntropyLoss().to(device)\n","#self.optimizer = AdamW(self.model.parameters(), lr=2e-5)\n","\n","\n","# preprocess\n","PRETRAIN_MODEL = \"activebus/BERT_Review\"\n","tokenizer = AutoTokenizer.from_pretrained(PRETRAIN_MODEL)\n","test_dataloader = create_data_loader(test_data, tokenizer, 10, max_len = 164)\n","#self.pred = predict_model(self.model, test_dataloader, loss_fn, device, len(test_data))\n","\n","predictions = []"],"metadata":{"id":"UzunapnXYGoD","executionInfo":{"status":"ok","timestamp":1647798371883,"user_tz":-60,"elapsed":2956,"user":{"displayName":"Victor Li","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16877734298003550452"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["with torch.no_grad():\n","  for d in test_dataloader:\n","    texts = d[\"review_text\"]\n","    input_ids = d[\"input_ids\"].to(device)\n","    attention_mask = d[\"attention_mask\"].to(device)\n","    targets = d[\"targets\"].to(device)\n","\n","    outputs = model(\n","        input_ids=input_ids,\n","        attention_mask=attention_mask)\n","\n","    preds = outputs.argmax(1)\n","    \n","    preds = preds.cpu().numpy()\n","\n","    predictions += [\n","                    {2:'positive',1:'neutral', 0:'negative'}[x] for x in preds\n","    ]\n"],"metadata":{"id":"Yl45jIn-Yr05","executionInfo":{"status":"ok","timestamp":1647798380550,"user_tz":-60,"elapsed":2702,"user":{"displayName":"Victor Li","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16877734298003550452"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["test = pd.read_csv('/content/drive/MyDrive/DSBA M2/2 NLP/exercise_2/data/devdata.csv', sep='\\t', header=None)\n","temp = test.iloc[:,0]"],"metadata":{"id":"0S1-quJUaWq1","executionInfo":{"status":"ok","timestamp":1647798383234,"user_tz":-60,"elapsed":219,"user":{"displayName":"Victor Li","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16877734298003550452"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import classification_report\n","target_names = ['positive', 'neutral', 'negative']\n","print(classification_report(temp, predictions, target_names=target_names))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5L6IxhJWZgG7","executionInfo":{"status":"ok","timestamp":1647798383571,"user_tz":-60,"elapsed":12,"user":{"displayName":"Victor Li","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16877734298003550452"}},"outputId":"5d68a51d-a77d-4ea2-f9a5-bad671c17b06"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","    positive       0.00      0.00      0.00        98\n","     neutral       0.02      0.43      0.04        14\n","    negative       0.15      0.06      0.09       264\n","\n","    accuracy                           0.06       376\n","   macro avg       0.06      0.16      0.04       376\n","weighted avg       0.10      0.06      0.06       376\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"wnyNybqIZgEU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"Ovb0x8rWZgBE"},"execution_count":null,"outputs":[]}]}