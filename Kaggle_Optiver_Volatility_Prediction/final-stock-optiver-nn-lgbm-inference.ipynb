{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "functional-mozambique",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-07-05T17:50:17.732318Z",
     "iopub.status.busy": "2021-07-05T17:50:17.731903Z",
     "iopub.status.idle": "2021-07-05T17:50:19.647572Z",
     "shell.execute_reply": "2021-07-05T17:50:19.646491Z",
     "shell.execute_reply.started": "2021-07-05T17:50:17.732235Z"
    },
    "papermill": {
     "duration": 0.061319,
     "end_time": "2021-09-26T09:23:41.811202",
     "exception": false,
     "start_time": "2021-09-26T09:23:41.749883",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## TabNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "foreign-advertising",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-26T09:23:41.925727Z",
     "iopub.status.busy": "2021-09-26T09:23:41.924836Z",
     "iopub.status.idle": "2021-09-26T09:24:09.982696Z",
     "shell.execute_reply": "2021-09-26T09:24:09.981986Z"
    },
    "papermill": {
     "duration": 28.120032,
     "end_time": "2021-09-26T09:24:09.982871",
     "exception": false,
     "start_time": "2021-09-26T09:23:41.862839",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip -q install ../input/pytorchtabnet/pytorch_tabnet-3.1.1-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "norwegian-saudi",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-26T09:24:10.098133Z",
     "iopub.status.busy": "2021-09-26T09:24:10.097418Z",
     "iopub.status.idle": "2021-09-26T09:24:12.598995Z",
     "shell.execute_reply": "2021-09-26T09:24:12.598339Z"
    },
    "papermill": {
     "duration": 2.564502,
     "end_time": "2021-09-26T09:24:12.599164",
     "exception": false,
     "start_time": "2021-09-26T09:24:10.034662",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy.matlib\n",
    "\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import shutil\n",
    "import glob\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from pytorch_tabnet.metrics import Metric\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "\n",
    "import torch\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingWarmRestarts\n",
    "\n",
    "\n",
    "# setting some globl config\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "orange_black = [\n",
    "    '#fdc029', '#df861d', '#FF6347', '#aa3d01', '#a30e15', '#800000', '#171820'\n",
    "]\n",
    "plt.rcParams['figure.figsize'] = (16,9)\n",
    "plt.rcParams[\"figure.facecolor\"] = '#FFFACD'\n",
    "plt.rcParams[\"axes.facecolor\"] = '#FFFFE0'\n",
    "plt.rcParams[\"axes.grid\"] = True\n",
    "plt.rcParams[\"grid.color\"] = orange_black[3]\n",
    "plt.rcParams[\"grid.alpha\"] = 0.5\n",
    "plt.rcParams[\"grid.linestyle\"] = '--'\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "living-marks",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-26T09:24:12.711356Z",
     "iopub.status.busy": "2021-09-26T09:24:12.710673Z",
     "iopub.status.idle": "2021-09-26T09:24:14.309523Z",
     "shell.execute_reply": "2021-09-26T09:24:14.308980Z"
    },
    "papermill": {
     "duration": 1.658353,
     "end_time": "2021-09-26T09:24:14.309662",
     "exception": false,
     "start_time": "2021-09-26T09:24:12.651309",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our training set has 428932 rows\n",
      "Our test set has 3 rows\n",
      "Our training set has 0 missing values\n",
      "Our test set has 0 missing values\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "def read_train_test():\n",
    "    # Function to read our base train and test set\n",
    "    \n",
    "    train = pd.read_csv('../input/optiver-realized-volatility-prediction/train.csv')\n",
    "    test = pd.read_csv('../input/optiver-realized-volatility-prediction/test.csv')\n",
    "\n",
    "    # Create a key to merge with book and trade data\n",
    "    train['row_id'] = train['stock_id'].astype(str) + '-' + train['time_id'].astype(str)\n",
    "    test['row_id'] = test['stock_id'].astype(str) + '-' + test['time_id'].astype(str)\n",
    "    print(f'Our training set has {train.shape[0]} rows')\n",
    "    print(f'Our test set has {test.shape[0]} rows')\n",
    "    print(f'Our training set has {train.isna().sum().sum()} missing values')\n",
    "    print(f'Our test set has {test.isna().sum().sum()} missing values')\n",
    "    \n",
    "    return train, test\n",
    "train, test = read_train_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "interstate-modification",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-26T09:24:14.464723Z",
     "iopub.status.busy": "2021-09-26T09:24:14.427979Z",
     "iopub.status.idle": "2021-09-26T09:52:05.727280Z",
     "shell.execute_reply": "2021-09-26T09:52:05.727825Z"
    },
    "papermill": {
     "duration": 1671.364241,
     "end_time": "2021-09-26T09:52:05.728030",
     "exception": false,
     "start_time": "2021-09-26T09:24:14.363789",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 10.5min\n",
      "[Parallel(n_jobs=-1)]: Done 112 out of 112 | elapsed: 26.7min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.3s finished\n"
     ]
    }
   ],
   "source": [
    "# data directory\n",
    "data_dir = '../input/optiver-realized-volatility-prediction/'\n",
    "\n",
    "def calc_wap1(df):\n",
    "    # Function to calculate first WAP\n",
    "    wap = (df['bid_price1'] * df['ask_size1'] + df['ask_price1'] * df['bid_size1']) / (df['bid_size1'] + df['ask_size1'])\n",
    "    return wap\n",
    "\n",
    "def calc_wap2(df):\n",
    "    # Function to calculate second WAP\n",
    "    wap = (df['bid_price2'] * df['ask_size2'] + df['ask_price2'] * df['bid_size2']) / (df['bid_size2'] + df['ask_size2'])\n",
    "    return wap\n",
    "\n",
    "def log_return(series):\n",
    "    # Function to calculate the log of the return\n",
    "    return np.log(series).diff()\n",
    "\n",
    "def realized_volatility(series):\n",
    "    # Calculate the realized volatility\n",
    "    return np.sqrt(np.sum(series**2))\n",
    "\n",
    "def count_unique(series):\n",
    "    # Function to count unique elements of a series\n",
    "    return len(np.unique(series))\n",
    "\n",
    "def book_preprocessor(file_path):\n",
    "    # Function to preprocess book data (for each stock id)\n",
    "    \n",
    "    df = pd.read_parquet(file_path)\n",
    "    \n",
    "    # Calculate Wap\n",
    "    df['wap1'] = calc_wap1(df)\n",
    "    df['wap2'] = calc_wap2(df)\n",
    "    \n",
    "    # Calculate log returns\n",
    "    df['log_return1'] = df.groupby(['time_id'])['wap1'].apply(log_return)\n",
    "    df['log_return2'] = df.groupby(['time_id'])['wap2'].apply(log_return)\n",
    "    \n",
    "    # Calculate wap balance\n",
    "    df['wap_balance'] = abs(df['wap1'] - df['wap2'])\n",
    "    \n",
    "    # Calculate spread\n",
    "    df['price_spread'] = (df['ask_price1'] - df['bid_price1']) / ((df['ask_price1'] + df['bid_price1']) / 2)\n",
    "    df['price_spread2'] = (df['ask_price2'] - df['bid_price2']) / ((df['ask_price2'] + df['bid_price2']) / 2)\n",
    "    df['bid_spread'] = df['bid_price1'] - df['bid_price2']\n",
    "    df['ask_spread'] = df['ask_price1'] - df['ask_price2']\n",
    "    df[\"bid_ask_spread\"] = abs(df['bid_spread'] - df['ask_spread'])\n",
    "    df['total_volume'] = (df['ask_size1'] + df['ask_size2']) + (df['bid_size1'] + df['bid_size2'])\n",
    "    df['volume_imbalance'] = abs((df['ask_size1'] + df['ask_size2']) - (df['bid_size1'] + df['bid_size2']))\n",
    "    \n",
    "    # Dict for aggregations\n",
    "    create_feature_dict = {\n",
    "        'wap1': [np.sum, np.mean, np.std],\n",
    "        'wap2': [np.sum, np.mean, np.std],\n",
    "        'log_return1': [np.sum, realized_volatility, np.mean, np.std],\n",
    "        'log_return2': [np.sum, realized_volatility, np.mean, np.std],\n",
    "        'wap_balance': [np.sum, np.mean, np.std],\n",
    "        'price_spread':[np.sum, np.mean, np.std],\n",
    "        'price_spread2':[np.sum, np.mean, np.std],\n",
    "        'bid_spread':[np.sum, np.mean, np.std],\n",
    "        'ask_spread':[np.sum, np.mean, np.std],\n",
    "        'total_volume':[np.sum, np.mean, np.std],\n",
    "        'volume_imbalance':[np.sum, np.mean, np.std],\n",
    "        \"bid_ask_spread\":[np.sum, np.mean, np.std],\n",
    "    }\n",
    "    \n",
    "    def get_stats_window(seconds_in_bucket, add_suffix = False):\n",
    "        # Function to get group stats for different windows (seconds in bucket)\n",
    "        \n",
    "        # Group by the window\n",
    "        df_feature = df[df['seconds_in_bucket'] >= seconds_in_bucket].groupby(['time_id']).agg(create_feature_dict).reset_index()\n",
    "        \n",
    "        # Rename columns joining suffix\n",
    "        df_feature.columns = ['_'.join(col) for col in df_feature.columns]\n",
    "        \n",
    "        # Add a suffix to differentiate windows\n",
    "        if add_suffix:\n",
    "            df_feature = df_feature.add_suffix('_' + str(seconds_in_bucket))\n",
    "        return df_feature\n",
    "    \n",
    "    # Get the stats for different windows\n",
    "    df_feature = get_stats_window(seconds_in_bucket = 0, add_suffix = False)\n",
    "    df_feature_400 = get_stats_window(seconds_in_bucket = 400, add_suffix = True)\n",
    "    df_feature_300 = get_stats_window(seconds_in_bucket = 300, add_suffix = True)\n",
    "    df_feature_200 = get_stats_window(seconds_in_bucket = 200, add_suffix = True)\n",
    "    \n",
    "    # Merge all\n",
    "    df_feature = df_feature.merge(df_feature_400, how = 'left', left_on = 'time_id_', right_on = 'time_id__400')\n",
    "    df_feature = df_feature.merge(df_feature_300, how = 'left', left_on = 'time_id_', right_on = 'time_id__300')\n",
    "    df_feature = df_feature.merge(df_feature_200, how = 'left', left_on = 'time_id_', right_on = 'time_id__200')\n",
    "\n",
    "    # Drop unnecesary time_ids\n",
    "    df_feature.drop(['time_id__400', 'time_id__300', 'time_id__200'], axis = 1, inplace = True)\n",
    "    \n",
    "    \n",
    "    # Create row_id so we can merge\n",
    "    stock_id = file_path.split('=')[1]\n",
    "    df_feature['row_id'] = df_feature['time_id_'].apply(lambda x: f'{stock_id}-{x}')\n",
    "    df_feature.drop(['time_id_'], axis = 1, inplace = True)\n",
    "    \n",
    "    return df_feature\n",
    "\n",
    "\n",
    "def trade_preprocessor(file_path):\n",
    "    # Function to preprocess trade data (for each stock id)\n",
    "    \n",
    "    df = pd.read_parquet(file_path)\n",
    "    df['log_return'] = df.groupby('time_id')['price'].apply(log_return)\n",
    "    \n",
    "    # Dict for aggregations\n",
    "    create_feature_dict = {\n",
    "        'log_return':[realized_volatility],\n",
    "        'seconds_in_bucket':[count_unique],\n",
    "        'size':[np.sum, realized_volatility, np.mean, np.std, np.max, np.min],\n",
    "        'order_count':[np.mean,np.sum,np.max],\n",
    "    }\n",
    "    \n",
    "    def get_stats_window(seconds_in_bucket, add_suffix = False):\n",
    "        # Function to get group stats for different windows (seconds in bucket)\n",
    "        \n",
    "        # Group by the window\n",
    "        df_feature = df[df['seconds_in_bucket'] >= seconds_in_bucket].groupby(['time_id']).agg(create_feature_dict).reset_index()\n",
    "        \n",
    "        # Rename columns joining suffix\n",
    "        df_feature.columns = ['_'.join(col) for col in df_feature.columns]\n",
    "        \n",
    "        # Add a suffix to differentiate windows\n",
    "        if add_suffix:\n",
    "            df_feature = df_feature.add_suffix('_' + str(seconds_in_bucket))\n",
    "        return df_feature\n",
    "    \n",
    "    # Get the stats for different windows\n",
    "    df_feature = get_stats_window(seconds_in_bucket = 0, add_suffix = False)\n",
    "    df_feature_400 = get_stats_window(seconds_in_bucket = 400, add_suffix = True)\n",
    "    df_feature_300 = get_stats_window(seconds_in_bucket = 300, add_suffix = True)\n",
    "    df_feature_200 = get_stats_window(seconds_in_bucket = 200, add_suffix = True)\n",
    "    \n",
    "    def tendency(price, vol):    \n",
    "        df_diff = np.diff(price)\n",
    "        val = (df_diff/price[1:])*100\n",
    "        power = np.sum(val*vol[1:])\n",
    "        return(power)\n",
    "    \n",
    "    lis = []\n",
    "    for n_time_id in df['time_id'].unique():\n",
    "        df_id = df[df['time_id'] == n_time_id]        \n",
    "        tendencyV = tendency(df_id['price'].values, df_id['size'].values)      \n",
    "        f_max = np.sum(df_id['price'].values > np.mean(df_id['price'].values))\n",
    "        f_min = np.sum(df_id['price'].values < np.mean(df_id['price'].values))\n",
    "        df_max =  np.sum(np.diff(df_id['price'].values) > 0)\n",
    "        df_min =  np.sum(np.diff(df_id['price'].values) < 0)\n",
    "        abs_diff = np.median(np.abs( df_id['price'].values - np.mean(df_id['price'].values)))        \n",
    "        energy = np.mean(df_id['price'].values**2)\n",
    "        iqr_p = np.percentile(df_id['price'].values,75) - np.percentile(df_id['price'].values,25)\n",
    "        abs_diff_v = np.median(np.abs( df_id['size'].values - np.mean(df_id['size'].values)))        \n",
    "        energy_v = np.sum(df_id['size'].values**2)\n",
    "        iqr_p_v = np.percentile(df_id['size'].values,75) - np.percentile(df_id['size'].values,25)\n",
    "        \n",
    "        lis.append({'time_id':n_time_id,'tendency':tendencyV,'f_max':f_max,'f_min':f_min,'df_max':df_max,'df_min':df_min,\n",
    "                   'abs_diff':abs_diff,'energy':energy,'iqr_p':iqr_p,'abs_diff_v':abs_diff_v,'energy_v':energy_v,'iqr_p_v':iqr_p_v})\n",
    "    \n",
    "    df_lr = pd.DataFrame(lis)\n",
    "        \n",
    "   \n",
    "    df_feature = df_feature.merge(df_lr, how = 'left', left_on = 'time_id_', right_on = 'time_id')\n",
    "    \n",
    "    # Merge all\n",
    "    df_feature = df_feature.merge(df_feature_400, how = 'left', left_on = 'time_id_', right_on = 'time_id__400')\n",
    "    df_feature = df_feature.merge(df_feature_300, how = 'left', left_on = 'time_id_', right_on = 'time_id__300')\n",
    "    df_feature = df_feature.merge(df_feature_200, how = 'left', left_on = 'time_id_', right_on = 'time_id__200')\n",
    "\n",
    "    # Drop unnecesary time_ids\n",
    "    df_feature.drop(['time_id__400', 'time_id__300', 'time_id__200','time_id'], axis = 1, inplace = True)\n",
    "    df_feature = df_feature.add_prefix('trade_')\n",
    "    stock_id = file_path.split('=')[1]\n",
    "    df_feature['row_id'] = df_feature['trade_time_id_'].apply(lambda x:f'{stock_id}-{x}')\n",
    "    df_feature.drop(['trade_time_id_'], axis = 1, inplace = True)\n",
    "    \n",
    "    def order_sum(df, sec:str):\n",
    "        new_col = 'size_tau' + sec\n",
    "        bucket_col = 'trade_seconds_in_bucket_count_unique' + sec\n",
    "        df[new_col] = np.sqrt(1/df[bucket_col])\n",
    "        \n",
    "        new_col2 = 'size_tau2' + sec\n",
    "        order_col = 'trade_order_count_sum' + sec\n",
    "        df[new_col2] = np.sqrt(1/df[order_col])\n",
    "        \n",
    "        if sec == '400_':\n",
    "            df['size_tau2_d'] = df['size_tau2_400'] - df['size_tau2']\n",
    "        \n",
    "\n",
    "    \n",
    "    for sec in ['','_200','_300','_400']:\n",
    "        order_sum(df_feature, sec)\n",
    "        \n",
    "    df_feature['size_tau2_d'] = df_feature['size_tau2_400'] - df_feature['size_tau2']\n",
    "    \n",
    "    return df_feature\n",
    "\n",
    "\n",
    "def get_time_stock(df):\n",
    "    # Function to get group stats for the stock_id and time_id\n",
    "    \n",
    "    # Get realized volatility columns\n",
    "    vol_cols = ['log_return1_realized_volatility', 'log_return2_realized_volatility', 'log_return1_realized_volatility_400', 'log_return2_realized_volatility_400', \n",
    "                'log_return1_realized_volatility_300', 'log_return2_realized_volatility_300', 'log_return1_realized_volatility_200', 'log_return2_realized_volatility_200', \n",
    "                'trade_log_return_realized_volatility', 'trade_log_return_realized_volatility_400', 'trade_log_return_realized_volatility_300', 'trade_log_return_realized_volatility_200']\n",
    "\n",
    "    # Group by the stock id\n",
    "    df_stock_id = df.groupby(['stock_id'])[vol_cols].agg(['mean', 'std', 'max', 'min', ]).reset_index()\n",
    "    \n",
    "    # Rename columns joining suffix\n",
    "    df_stock_id.columns = ['_'.join(col) for col in df_stock_id.columns]\n",
    "    df_stock_id = df_stock_id.add_suffix('_' + 'stock')\n",
    "\n",
    "    # Group by the stock id\n",
    "    df_time_id = df.groupby(['time_id'])[vol_cols].agg(['mean', 'std', 'max', 'min', ]).reset_index()\n",
    "    \n",
    "    # Rename columns joining suffix\n",
    "    df_time_id.columns = ['_'.join(col) for col in df_time_id.columns]\n",
    "    df_time_id = df_time_id.add_suffix('_' + 'time')\n",
    "    \n",
    "    # Merge with original dataframe\n",
    "    df = df.merge(df_stock_id, how = 'left', left_on = ['stock_id'], right_on = ['stock_id__stock'])\n",
    "    df = df.merge(df_time_id, how = 'left', left_on = ['time_id'], right_on = ['time_id__time'])\n",
    "    df.drop(['stock_id__stock', 'time_id__time'], axis = 1, inplace = True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def create_agg_features(train, test):\n",
    "\n",
    "    # Making agg features\n",
    "\n",
    "    train_p = pd.read_csv('../input/optiver-realized-volatility-prediction/train.csv')\n",
    "    train_p = train_p.pivot(index='time_id', columns='stock_id', values='target')\n",
    "    corr = train_p.corr()\n",
    "    ids = corr.index\n",
    "    kmeans = KMeans(n_clusters=7, random_state=42).fit(corr.values)\n",
    "    l = []\n",
    "    for n in range(7):\n",
    "        l.append ( [ (x-1) for x in ( (ids+1)*(kmeans.labels_ == n)) if x > 0] )\n",
    "\n",
    "    mat = []\n",
    "    matTest = []\n",
    "    n = 0\n",
    "    for ind in l:\n",
    "        newDf = train.loc[train['stock_id'].isin(ind) ]\n",
    "        newDf = newDf.groupby(['time_id']).agg(np.nanmean)\n",
    "        newDf.loc[:,'stock_id'] = str(n)+'c1'\n",
    "        mat.append ( newDf )\n",
    "        newDf = test.loc[test['stock_id'].isin(ind) ]    \n",
    "        newDf = newDf.groupby(['time_id']).agg(np.nanmean)\n",
    "        newDf.loc[:,'stock_id'] = str(n)+'c1'\n",
    "        matTest.append ( newDf )\n",
    "        n+=1\n",
    "\n",
    "    mat1 = pd.concat(mat).reset_index()\n",
    "    mat1.drop(columns=['target'],inplace=True)\n",
    "    mat2 = pd.concat(matTest).reset_index()\n",
    "    \n",
    "    mat2 = pd.concat([mat2,mat1.loc[mat1.time_id==5]])\n",
    "    \n",
    "    mat1 = mat1.pivot(index='time_id', columns='stock_id')\n",
    "    mat1.columns = [\"_\".join(x) for x in mat1.columns.ravel()]\n",
    "    mat1.reset_index(inplace=True)\n",
    "    \n",
    "    mat2 = mat2.pivot(index='time_id', columns='stock_id')\n",
    "    mat2.columns = [\"_\".join(x) for x in mat2.columns.ravel()]\n",
    "    mat2.reset_index(inplace=True)\n",
    "    \n",
    "    prefix = ['log_return1_realized_volatility', 'total_volume_mean', 'trade_size_mean', 'trade_order_count_mean','price_spread_mean','bid_spread_mean','ask_spread_mean',\n",
    "              'volume_imbalance_mean', 'bid_ask_spread_mean','size_tau2']\n",
    "    selected_cols=mat1.filter(regex='|'.join(f'^{x}.(0|1|3|4|6)c1' for x in prefix)).columns.tolist()\n",
    "    selected_cols.append('time_id')\n",
    "    \n",
    "    train_m = pd.merge(train,mat1[selected_cols],how='left',on='time_id')\n",
    "    test_m = pd.merge(test,mat2[selected_cols],how='left',on='time_id')\n",
    "    \n",
    "    # filling missing values with train means\n",
    "\n",
    "    features = [col for col in train_m.columns.tolist() if col not in ['time_id','target','row_id']]\n",
    "    train_m[features] = train_m[features].fillna(train_m[features].mean())\n",
    "    test_m[features] = test_m[features].fillna(train_m[features].mean())\n",
    "\n",
    "    return train_m, test_m\n",
    "    \n",
    "    \n",
    "def preprocessor(list_stock_ids, is_train = True):\n",
    "    # Funtion to make preprocessing function in parallel (for each stock id)\n",
    "    \n",
    "    # Parrallel for loop\n",
    "    def for_joblib(stock_id):\n",
    "        # Train\n",
    "        if is_train:\n",
    "            file_path_book = data_dir + \"book_train.parquet/stock_id=\" + str(stock_id)\n",
    "            file_path_trade = data_dir + \"trade_train.parquet/stock_id=\" + str(stock_id)\n",
    "        # Test\n",
    "        else:\n",
    "            file_path_book = data_dir + \"book_test.parquet/stock_id=\" + str(stock_id)\n",
    "            file_path_trade = data_dir + \"trade_test.parquet/stock_id=\" + str(stock_id)\n",
    "    \n",
    "        # Preprocess book and trade data and merge them\n",
    "        df_tmp = pd.merge(book_preprocessor(file_path_book), trade_preprocessor(file_path_trade), on = 'row_id', how = 'left')\n",
    "        \n",
    "        # Return the merge dataframe\n",
    "        return df_tmp\n",
    "    \n",
    "    # Use parallel api to call paralle for loop\n",
    "    df = Parallel(n_jobs = -1, verbose = 1)(delayed(for_joblib)(stock_id) for stock_id in list_stock_ids)\n",
    "    \n",
    "    # Concatenate all the dataframes that return from Parallel\n",
    "    df = pd.concat(df, ignore_index = True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Get unique stock ids \n",
    "train_stock_ids = train['stock_id'].unique()\n",
    "\n",
    "# Preprocess them using Parallel and our single stock id functions\n",
    "train_ = preprocessor(train_stock_ids, is_train = True)\n",
    "train = train.merge(train_, on = ['row_id'], how = 'left')\n",
    "\n",
    "# Get unique stock ids \n",
    "test_stock_ids = test['stock_id'].unique()\n",
    "\n",
    "# Preprocess them using Parallel and our single stock id functions\n",
    "test_ = preprocessor(test_stock_ids, is_train = False)\n",
    "test = test.merge(test_, on = ['row_id'], how = 'left')\n",
    "\n",
    "# Get group stats of time_id and stock_id\n",
    "train = get_time_stock(train)\n",
    "test = get_time_stock(test)\n",
    "\n",
    "# Fill inf values\n",
    "train.replace([np.inf, -np.inf], np.nan,inplace=True)\n",
    "test.replace([np.inf, -np.inf], np.nan,inplace=True)\n",
    "\n",
    "# Aggregating some features\n",
    "train, test = create_agg_features(train,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "expressed-religious",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-26T09:52:05.845615Z",
     "iopub.status.busy": "2021-09-26T09:52:05.844623Z",
     "iopub.status.idle": "2021-09-26T09:52:14.165422Z",
     "shell.execute_reply": "2021-09-26T09:52:14.164854Z"
    },
    "papermill": {
     "duration": 8.383482,
     "end_time": "2021-09-26T09:52:14.165577",
     "exception": false,
     "start_time": "2021-09-26T09:52:05.782095",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: model_params.json (deflated 45%)\r\n",
      "  adding: network.pt (deflated 20%)\r\n",
      "  adding: model_params.json (deflated 45%)\r\n",
      "  adding: network.pt (deflated 20%)\r\n",
      "  adding: model_params.json (deflated 45%)\r\n",
      "  adding: network.pt (deflated 20%)\r\n",
      "  adding: model_params.json (deflated 45%)\r\n",
      "  adding: network.pt (deflated 20%)\r\n",
      "  adding: model_params.json (deflated 45%)\r\n",
      "  adding: network.pt (deflated 20%)\r\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for fold in range(5):\n",
    "    !cp -r ../input/optiver-tabnet-models/fold{str(fold)}/* .\n",
    "    !zip fold{str(fold)}.zip model_params.json network.pt\n",
    "    \n",
    "modelpath = [os.path.join(\"./\",s) for s in os.listdir(\"./\") if (\"zip\" in s)]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "alien-practice",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-26T09:52:14.574474Z",
     "iopub.status.busy": "2021-09-26T09:52:14.573682Z",
     "iopub.status.idle": "2021-09-26T09:52:26.859645Z",
     "shell.execute_reply": "2021-09-26T09:52:26.859118Z"
    },
    "papermill": {
     "duration": 12.638695,
     "end_time": "2021-09-26T09:52:26.859787",
     "exception": false,
     "start_time": "2021-09-26T09:52:14.221092",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cpu\n",
      "Device used : cpu\n",
      "Device used : cpu\n",
      "Device used : cpu\n",
      "Device used : cpu\n",
      "Device used : cpu\n"
     ]
    }
   ],
   "source": [
    "X = train.drop(['row_id', 'target', 'time_id'], axis = 1)\n",
    "y = train['target']\n",
    "X_test=test.copy()\n",
    "X_test.drop(['time_id','row_id'], axis=1,inplace=True)\n",
    "\n",
    "def rmspe(y_true, y_pred):\n",
    "    # Function to calculate the root mean squared percentage error\n",
    "    return np.sqrt(np.mean(np.square((y_true - y_pred) / y_true)))\n",
    "\n",
    "class RMSPE(Metric):\n",
    "    def __init__(self):\n",
    "        self._name = \"rmspe\"\n",
    "        self._maximize = False\n",
    "\n",
    "    def __call__(self, y_true, y_score):\n",
    "        \n",
    "        return np.sqrt(np.mean(np.square((y_true - y_score) / y_true)))\n",
    "    \n",
    "\n",
    "\n",
    "def RMSPELoss(y_pred, y_true):\n",
    "    return torch.sqrt(torch.mean( ((y_true - y_pred) / y_true) ** 2 )).clone()\n",
    "\n",
    "nunique = X.nunique()\n",
    "types = X.dtypes\n",
    "\n",
    "categorical_columns = []\n",
    "categorical_dims =  {}\n",
    "\n",
    "for col in X.columns:\n",
    "    if  col == 'stock_id':\n",
    "        l_enc = LabelEncoder()\n",
    "        X[col] = l_enc.fit_transform(X[col].values)\n",
    "        X_test[col] = l_enc.transform(X_test[col].values)\n",
    "        categorical_columns.append(col)\n",
    "        categorical_dims[col] = len(l_enc.classes_)\n",
    "    else:\n",
    "        scaler = StandardScaler()\n",
    "        X[col] = scaler.fit_transform(X[col].values.reshape(-1, 1))\n",
    "        X_test[col] = scaler.transform(X_test[col].values.reshape(-1, 1))\n",
    "        \n",
    "\n",
    "\n",
    "cat_idxs = [ i for i, f in enumerate(X.columns.tolist()) if f in categorical_columns]\n",
    "\n",
    "cat_dims = [ categorical_dims[f] for i, f in enumerate(X.columns.tolist()) if f in categorical_columns]\n",
    "\n",
    "tabnet_params = dict(\n",
    "    cat_idxs=cat_idxs,\n",
    "    cat_dims=cat_dims,\n",
    "    cat_emb_dim=1,\n",
    "    n_d = 16,\n",
    "    n_a = 16,\n",
    "    n_steps = 2,\n",
    "    gamma = 2,\n",
    "    n_independent = 2,\n",
    "    n_shared = 2,\n",
    "    lambda_sparse = 0,\n",
    "    optimizer_fn = Adam,\n",
    "    optimizer_params = dict(lr = (2e-2)),\n",
    "    mask_type = \"entmax\",\n",
    "    scheduler_params = dict(T_0=200, T_mult=1, eta_min=1e-4, last_epoch=-1, verbose=False),\n",
    "    scheduler_fn = CosineAnnealingWarmRestarts,\n",
    "    seed = 42,\n",
    "    verbose = 10\n",
    "    \n",
    ")\n",
    "\n",
    "# kfold = KFold(n_splits = 5, random_state = 42, shuffle = True)\n",
    "# # Create out of folds array\n",
    "# oof_predictions = np.zeros((X.shape[0], 1))\n",
    "# test_predictions = np.zeros(X_test.shape[0])\n",
    "# feature_importances = pd.DataFrame()\n",
    "# feature_importances[\"feature\"] = X.columns.tolist()\n",
    "# stats = pd.DataFrame()\n",
    "# explain_matrices = []\n",
    "# masks_ =[]\n",
    "\n",
    "clf =  TabNetRegressor(**tabnet_params)\n",
    "\n",
    "# for fold, (trn_ind, val_ind) in enumerate(kfold.split(X)):\n",
    "#     print(f'Training fold {fold + 1}')\n",
    "#     X_train, X_val = X.iloc[trn_ind].values, X.iloc[val_ind].values\n",
    "#     y_train, y_val = y.iloc[trn_ind].values.reshape(-1,1), y.iloc[val_ind].values.reshape(-1,1)\n",
    "\n",
    "\n",
    "    \n",
    "#     clf.fit(\n",
    "#       X_train, y_train,\n",
    "#       eval_set=[(X_val, y_val)],\n",
    "#       max_epochs = 200,\n",
    "#       patience = 50,\n",
    "#       batch_size = 1024*20, \n",
    "#       virtual_batch_size = 128*20,\n",
    "#       num_workers = 4,\n",
    "#       drop_last = False,\n",
    "#       eval_metric=[RMSPE],\n",
    "#       loss_fn=RMSPELoss\n",
    "#       )\n",
    "    \n",
    "#     saving_path_name = f\"./fold{fold}\"\n",
    "#     saved_filepath = clf.save_model(saving_path_name)\n",
    "    \n",
    "#     explain_matrix, masks = clf.explain(X_val)\n",
    "#     explain_matrices.append(explain_matrix)\n",
    "#     masks_.append(masks[0])\n",
    "#     masks_.append(masks[1])\n",
    "      \n",
    "#     oof_predictions[val_ind] = clf.predict(X_val)\n",
    "#     test_predictions+=clf.predict(X_test.values).flatten()/5\n",
    "#     feature_importances[f\"importance_fold{fold}+1\"] = clf.feature_importances_\n",
    "    \n",
    "#     stats[f'fold{fold+1}_train_rmspe']=clf.history['loss']\n",
    "#     stats[f'fold{fold+1}_val_rmspe']=clf.history['val_0_rmspe']\n",
    "preds=[]\n",
    "for path in modelpath:\n",
    "    \n",
    "    clf.load_model(path)\n",
    "    preds.append(clf.predict(X_test.values).squeeze(-1))\n",
    "    \n",
    "model1_predictions = np.mean(preds,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marked-sentence",
   "metadata": {
    "papermill": {
     "duration": 0.057834,
     "end_time": "2021-09-26T09:52:26.974932",
     "exception": false,
     "start_time": "2021-09-26T09:52:26.917098",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## NN\n",
    "https://www.kaggle.com/lucasmorin/tf-keras-nn-with-stock-embedding\n",
    "\n",
    "A simple NN starter using stock Embedding.\n",
    "\n",
    "Embedding layer from : https://www.kaggle.com/colinmorris/embedding-layers\n",
    "\n",
    "--- Features from ---\n",
    "\n",
    "https://www.kaggle.com/ragnar123/optiver-realized-volatility-lgbm-baseline but I have optimized the LGB params."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "incorporate-waterproof",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-26T09:52:27.096320Z",
     "iopub.status.busy": "2021-09-26T09:52:27.095287Z",
     "iopub.status.idle": "2021-09-26T09:52:27.098737Z",
     "shell.execute_reply": "2021-09-26T09:52:27.098115Z",
     "shell.execute_reply.started": "2021-09-24T08:13:33.695954Z"
    },
    "papermill": {
     "duration": 0.06723,
     "end_time": "2021-09-26T09:52:27.098878",
     "exception": false,
     "start_time": "2021-09-26T09:52:27.031648",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import glob\n",
    "import os\n",
    "import gc\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from sklearn import preprocessing, model_selection\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import numpy.matlib\n",
    "\n",
    "\n",
    "path_submissions = '/'\n",
    "\n",
    "target_name = 'target'\n",
    "scores_folds = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joined-testing",
   "metadata": {
    "papermill": {
     "duration": 0.056298,
     "end_time": "2021-09-26T09:52:27.212229",
     "exception": false,
     "start_time": "2021-09-26T09:52:27.155931",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "desperate-helen",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-26T09:52:27.378302Z",
     "iopub.status.busy": "2021-09-26T09:52:27.341131Z",
     "iopub.status.idle": "2021-09-26T09:52:27.412112Z",
     "shell.execute_reply": "2021-09-26T09:52:27.411422Z",
     "shell.execute_reply.started": "2021-09-24T08:13:34.896487Z"
    },
    "papermill": {
     "duration": 0.143411,
     "end_time": "2021-09-26T09:52:27.412253",
     "exception": false,
     "start_time": "2021-09-26T09:52:27.268842",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data directory\n",
    "data_dir = '../input/optiver-realized-volatility-prediction/'\n",
    "# Calculate the realized absolute variation\n",
    "def realized_absvar(series):\n",
    "    return np.sqrt(np.pi/(2*series.count()))*np.sum(np.abs(series))\n",
    "# realized bipower variation \n",
    "def realized_bipowvar(series):\n",
    "    cnt = series.count()\n",
    "    if cnt<3:\n",
    "        return np.nan\n",
    "    else:\n",
    "        cons = (np.pi/2)*(cnt/(cnt-2))\n",
    "        return cons*np.nansum(np.abs(series)*np.abs(series.shift()))\n",
    "# Calculate order book depth\n",
    "def calc_depth(df):\n",
    "    depth = df['bid_price1'] * df['bid_size1'] + df['ask_price1'] * df['ask_size1'] + df['bid_price2'] * df[\n",
    "               'bid_size2'] + df['ask_price2'] * df['ask_size2']\n",
    "    return depth\n",
    "# Calculate order book slope\n",
    "def calc_slope(df):\n",
    "    v0 = (df['bid_size1']+df['ask_size1'])/2\n",
    "    p0 = (df['bid_price1']+df['ask_price1'])/2\n",
    "    slope_bid = ((df['bid_size1']/v0)-1)/abs((df['bid_price1']/p0)-1)+(\n",
    "                (df['bid_size2']/df['bid_size1'])-1)/abs((df['bid_price2']/df['bid_price1'])-1)\n",
    "    slope_ask = ((df[\n",
    "        'ask_size1']/v0)-1)/abs((df['ask_price1']/p0)-1)+(\n",
    "                (df['ask_size2']/df['ask_size1'])-1)/abs((df['ask_price2']/df['ask_price1'])-1)\n",
    "    return (slope_bid+slope_ask)/2, abs(slope_bid-slope_ask)\n",
    "# Calculate order book dispersion\n",
    "def calc_dispersion(df):\n",
    "    bspread = df['bid_price1'] - df['bid_price2']\n",
    "    aspread = df['ask_price2'] - df['ask_price1']\n",
    "    bmid = (df['bid_price1'] + df['ask_price1'])/2  - df['bid_price1']\n",
    "    bmid2 = (df['bid_price1'] + df['ask_price1'])/2  - df['bid_price2']\n",
    "    amid = df['ask_price1'] - (df['bid_price1'] + df['ask_price1'])/2\n",
    "    amid2 = df['ask_price2'] - (df['bid_price1'] + df['ask_price1'])/2\n",
    "    bdisp = (df['bid_size1']*bmid + df['bid_size2']*bspread)/(df['bid_size1']+df['bid_size2'])\n",
    "    bdisp2 = (df['bid_size1']*bmid + df['bid_size2']*bmid2)/(df['bid_size1']+df['bid_size2'])\n",
    "    adisp = (df['ask_size1']*amid + df['ask_size2']*aspread)/(df['ask_size1']+df['ask_size2'])      \n",
    "    adisp2 = (df['ask_size1']*amid + df['ask_size2']*amid2)/(df['ask_size1']+df['ask_size2'])\n",
    "    return bspread, aspread, bmid, amid, bdisp, adisp, (bdisp + adisp)/2, (bdisp2 + adisp2)/2\n",
    "def calc_price_impact(df):\n",
    "    ask = (df['ask_price1'] * df['ask_size1'] + df['ask_price2'] * df['ask_size2'])/(df['ask_size1']+df['ask_size2'])\n",
    "    bid = (df['bid_price1'] * df['bid_size1'] + df['bid_price2'] * df['bid_size2'])/(df['bid_size1']+df['bid_size2'])\n",
    "    return (df['ask_price1'] - ask)/df['ask_price1'], (df['bid_price1'] - bid)/df['bid_price1']\n",
    "#  order flow imbalance\n",
    "def calc_ofi(df):\n",
    "    a = df['bid_size1']*np.where(df['bid_price1'].diff()>=0,1,0)\n",
    "    b = df['bid_size1'].shift()*np.where(df['bid_price1'].diff()<=0,1,0)\n",
    "    c = df['ask_size1']*np.where(df['ask_price1'].diff()<=0,1,0)\n",
    "    d = df['ask_size1'].shift()*np.where(df['ask_price1'].diff()>=0,1,0)\n",
    "    return a - b - c + d\n",
    "\n",
    "# Function to calculate first WAP\n",
    "def calc_wap1(df):\n",
    "    wap = (df['bid_price1'] * df['ask_size1'] + df['ask_price1'] * df['bid_size1']) / (df['bid_size1'] + df['ask_size1'])\n",
    "    return wap\n",
    "\n",
    "# Function to calculate second WAP\n",
    "def calc_wap2(df):\n",
    "    wap = (df['bid_price2'] * df['ask_size2'] + df['ask_price2'] * df['bid_size2']) / (df['bid_size2'] + df['ask_size2'])\n",
    "    return wap\n",
    "\n",
    "# Function to calculate the log of the return\n",
    "# Remember that logb(x / y) = logb(x) - logb(y)\n",
    "def log_return(series):\n",
    "    return np.log(series).diff()\n",
    "\n",
    "# Calculate the realized volatility\n",
    "def realized_volatility(series):\n",
    "    return np.sqrt(np.sum(series**2))\n",
    "\n",
    "# Function to count unique elements of a series\n",
    "def count_unique(series):\n",
    "    return len(np.unique(series))\n",
    "\n",
    "# Function to read our base train and test set\n",
    "def read_train_test():\n",
    "    train = pd.read_csv('../input/optiver-realized-volatility-prediction/train.csv')\n",
    "    test = pd.read_csv('../input/optiver-realized-volatility-prediction/test.csv')\n",
    "    # Create a key to merge with book and trade data\n",
    "    train['row_id'] = train['stock_id'].astype(str) + '-' + train['time_id'].astype(str)\n",
    "    test['row_id'] = test['stock_id'].astype(str) + '-' + test['time_id'].astype(str)\n",
    "    print(f'Our training set has {train.shape[0]} rows')\n",
    "    return train, test\n",
    "\n",
    "# Function to preprocess book data (for each stock id)\n",
    "def book_preprocessor(file_path):\n",
    "    df = pd.read_parquet(file_path)\n",
    "    #calc_depth\n",
    "    df['calc_depth']=calc_depth(df)\n",
    "    #calc_slope\n",
    "    df['calc_slope1'],df['calc_slope2']=calc_slope(df)\n",
    "    #calc_dispersion\n",
    "    df['bspread'], df['aspread'], df['bmid'], df['amid'], df['bdisp'], df['adisp'], df['a_bdisp_1'], df['ba_disp2'] = calc_dispersion(df)\n",
    "    #calc_price_impact\n",
    "    df['calc_price_impact1'],df['calc_price_impact2']=calc_price_impact(df)\n",
    "    #calc_ofi\n",
    "    df['calc_ofi']=calc_ofi(df)\n",
    "    # Calculate Wap\n",
    "    df['wap1'] = calc_wap1(df)\n",
    "    df['wap2'] = calc_wap2(df)\n",
    "    # Calculate log returns\n",
    "    df['log_return1'] = df.groupby(['time_id'])['wap1'].apply(log_return)\n",
    "    df['log_return2'] = df.groupby(['time_id'])['wap2'].apply(log_return)\n",
    "    # Calculate wap balance\n",
    "    df['wap_balance'] = abs(df['wap1'] - df['wap2'])\n",
    "    # Calculate spread\n",
    "    df['price_spread'] = (df['ask_price1'] - df['bid_price1']) / ((df['ask_price1'] + df['bid_price1']) / 2)\n",
    "    df['price_spread2'] = (df['ask_price2'] - df['bid_price2']) / ((df['ask_price2'] + df['bid_price2']) / 2)\n",
    "    df['bid_spread'] = df['bid_price1'] - df['bid_price2']\n",
    "    df['ask_spread'] = df['ask_price1'] - df['ask_price2']\n",
    "    df[\"bid_ask_spread\"] = abs(df['bid_spread'] - df['ask_spread'])\n",
    "    df['total_volume'] = (df['ask_size1'] + df['ask_size2']) + (df['bid_size1'] + df['bid_size2'])\n",
    "    df['volume_imbalance'] = abs((df['ask_size1'] + df['ask_size2']) - (df['bid_size1'] + df['bid_size2']))\n",
    "    \n",
    "    # Dict for aggregations\n",
    "    create_feature_dict = {\n",
    "\n",
    "        'calc_depth':[np.sum, np.mean, np.std],\n",
    "        'calc_slope1':[np.sum, np.mean, np.std],\n",
    "        'calc_slope2':[np.sum, np.mean, np.std],\n",
    "        'calc_price_impact1':[np.sum, np.mean, np.std],\n",
    "        'calc_price_impact2':[np.sum, np.mean, np.std],\n",
    "        'calc_ofi':[np.sum, np.mean, np.std],\n",
    "        \n",
    "        'wap1': [np.sum, np.mean, np.std],\n",
    "        'wap2': [np.sum, np.mean, np.std],\n",
    "        'log_return1': [np.sum, realized_volatility, np.mean, np.std, realized_absvar, realized_bipowvar],\n",
    "        'log_return2': [np.sum, realized_volatility, np.mean, np.std, realized_absvar, realized_bipowvar],\n",
    "        'wap_balance': [np.sum, np.mean, np.std],\n",
    "        'price_spread':[np.sum, np.mean, np.std],\n",
    "        'price_spread2':[np.sum, np.mean, np.std],\n",
    "        'bid_spread':[np.sum, np.mean, np.std],\n",
    "        'ask_spread':[np.sum, np.mean, np.std],\n",
    "        'total_volume':[np.sum, np.mean, np.std],\n",
    "        'volume_imbalance':[np.sum, np.mean, np.std],\n",
    "        \"bid_ask_spread\":[np.sum, np.mean, np.std],\n",
    "    }\n",
    "    \n",
    "    # Function to get group stats for different windows (seconds in bucket)\n",
    "    def get_stats_window(seconds_in_bucket, add_suffix = False):\n",
    "        # Group by the window\n",
    "        df_feature = df[df['seconds_in_bucket'] >= seconds_in_bucket].groupby(['time_id']).agg(create_feature_dict).reset_index()\n",
    "        # Rename columns joining suffix\n",
    "        df_feature.columns = ['_'.join(col) for col in df_feature.columns]\n",
    "        # Add a suffix to differentiate windows\n",
    "        if add_suffix:\n",
    "            df_feature = df_feature.add_suffix('_' + str(seconds_in_bucket))\n",
    "        return df_feature\n",
    "    \n",
    "    # Get the stats for different windows\n",
    "    df_feature = get_stats_window(seconds_in_bucket = 0, add_suffix = False)\n",
    "    df_feature_450 = get_stats_window(seconds_in_bucket = 450, add_suffix = True)\n",
    "#     df_feature_500 = get_stats_window(seconds_in_bucket = 500, add_suffix = True)\n",
    "#     df_feature_400 = get_stats_window(seconds_in_bucket = 400, add_suffix = True)\n",
    "    df_feature_300 = get_stats_window(seconds_in_bucket = 300, add_suffix = True)\n",
    "#     df_feature_200 = get_stats_window(seconds_in_bucket = 200, add_suffix = True)\n",
    "    df_feature_150 = get_stats_window(seconds_in_bucket = 150, add_suffix = True)\n",
    "\n",
    "    # Merge all\n",
    "    df_feature = df_feature.merge(df_feature_450, how = 'left', left_on = 'time_id_', right_on = 'time_id__450')\n",
    "    df_feature = df_feature.merge(df_feature_300, how = 'left', left_on = 'time_id_', right_on = 'time_id__300')\n",
    "#     df_feature = df_feature.merge(df_feature_300, how = 'left', left_on = 'time_id_', right_on = 'time_id__300')\n",
    "    df_feature = df_feature.merge(df_feature_150, how = 'left', left_on = 'time_id_', right_on = 'time_id__150')\n",
    "#     df_feature = df_feature.merge(df_feature_100, how = 'left', left_on = 'time_id_', right_on = 'time_id__100')\n",
    "    # Drop unnecesary time_ids\n",
    "    df_feature.drop(['time_id__450', 'time_id__300', 'time_id__150'], axis = 1, inplace = True)\n",
    "    \n",
    "    \n",
    "    # Create row_id so we can merge\n",
    "    stock_id = file_path.split('=')[1]\n",
    "    df_feature['row_id'] = df_feature['time_id_'].apply(lambda x: f'{stock_id}-{x}')\n",
    "    df_feature.drop(['time_id_'], axis = 1, inplace = True)\n",
    "    return df_feature\n",
    "\n",
    "# Function to preprocess trade data (for each stock id)\n",
    "def trade_preprocessor(file_path):\n",
    "    df = pd.read_parquet(file_path)\n",
    "    df['log_return'] = df.groupby('time_id')['price'].apply(log_return)\n",
    "    \n",
    "    # Dict for aggregations\n",
    "    create_feature_dict = {\n",
    "        'log_return':[realized_volatility,realized_absvar,realized_bipowvar],\n",
    "        'seconds_in_bucket':[count_unique],\n",
    "        'size':[np.sum, realized_volatility, np.mean, np.std, np.max, np.min],\n",
    "        'order_count':[np.mean,np.sum,np.max],\n",
    "    }\n",
    "    \n",
    "    # Function to get group stats for different windows (seconds in bucket)\n",
    "    def get_stats_window(seconds_in_bucket, add_suffix = False):\n",
    "        # Group by the window\n",
    "        df_feature = df[df['seconds_in_bucket'] >= seconds_in_bucket].groupby(['time_id']).agg(create_feature_dict).reset_index()\n",
    "        # Rename columns joining suffix\n",
    "        df_feature.columns = ['_'.join(col) for col in df_feature.columns]\n",
    "        # Add a suffix to differentiate windows\n",
    "        if add_suffix:\n",
    "            df_feature = df_feature.add_suffix('_' + str(seconds_in_bucket))\n",
    "        return df_feature\n",
    "    \n",
    "\n",
    "    # Get the stats for different windows\n",
    "    df_feature = get_stats_window(seconds_in_bucket = 0, add_suffix = False)\n",
    "    df_feature_450 = get_stats_window(seconds_in_bucket = 450, add_suffix = True)\n",
    "#     df_feature_500 = get_stats_window(seconds_in_bucket = 500, add_suffix = True)\n",
    "#     df_feature_400 = get_stats_window(seconds_in_bucket = 400, add_suffix = True)\n",
    "    df_feature_300 = get_stats_window(seconds_in_bucket = 300, add_suffix = True)\n",
    "#     df_feature_200 = get_stats_window(seconds_in_bucket = 200, add_suffix = True)\n",
    "    df_feature_150 = get_stats_window(seconds_in_bucket = 150, add_suffix = True)\n",
    "    \n",
    "    def tendency(price, vol):    \n",
    "        df_diff = np.diff(price)\n",
    "        val = (df_diff/price[1:])*100\n",
    "        power = np.sum(val*vol[1:])\n",
    "        return(power)\n",
    "    \n",
    "    lis = []\n",
    "    for n_time_id in df['time_id'].unique():\n",
    "        df_id = df[df['time_id'] == n_time_id]        \n",
    "        tendencyV = tendency(df_id['price'].values, df_id['size'].values)      \n",
    "        f_max = np.sum(df_id['price'].values > np.mean(df_id['price'].values))\n",
    "        f_min = np.sum(df_id['price'].values < np.mean(df_id['price'].values))\n",
    "        df_max =  np.sum(np.diff(df_id['price'].values) > 0)\n",
    "        df_min =  np.sum(np.diff(df_id['price'].values) < 0)\n",
    "        # new\n",
    "        abs_diff = np.median(np.abs( df_id['price'].values - np.mean(df_id['price'].values)))        \n",
    "        energy = np.mean(df_id['price'].values**2)\n",
    "        iqr_p = np.percentile(df_id['price'].values,75) - np.percentile(df_id['price'].values,25)\n",
    "        \n",
    "        # vol vars\n",
    "        \n",
    "        abs_diff_v = np.median(np.abs( df_id['size'].values - np.mean(df_id['size'].values)))        \n",
    "        energy_v = np.sum(df_id['size'].values**2)\n",
    "        iqr_p_v = np.percentile(df_id['size'].values,75) - np.percentile(df_id['size'].values,25)\n",
    "        \n",
    "        lis.append({'time_id':n_time_id,'tendency':tendencyV,'f_max':f_max,'f_min':f_min,'df_max':df_max,'df_min':df_min,\n",
    "                   'abs_diff':abs_diff,'energy':energy,'iqr_p':iqr_p,'abs_diff_v':abs_diff_v,'energy_v':energy_v,'iqr_p_v':iqr_p_v})\n",
    "    \n",
    "    df_lr = pd.DataFrame(lis)\n",
    "        \n",
    "   \n",
    "    df_feature = df_feature.merge(df_lr, how = 'left', left_on = 'time_id_', right_on = 'time_id')\n",
    "    \n",
    "    # Merge all\n",
    "    df_feature = df_feature.merge(df_feature_450, how = 'left', left_on = 'time_id_', right_on = 'time_id__450')\n",
    "    df_feature = df_feature.merge(df_feature_300, how = 'left', left_on = 'time_id_', right_on = 'time_id__300')\n",
    "#     df_feature = df_feature.merge(df_feature_300, how = 'left', left_on = 'time_id_', right_on = 'time_id__300')\n",
    "    df_feature = df_feature.merge(df_feature_150, how = 'left', left_on = 'time_id_', right_on = 'time_id__150')\n",
    "#     df_feature = df_feature.merge(df_feature_100, how = 'left', left_on = 'time_id_', right_on = 'time_id__100')\n",
    "    # Drop unnecesary time_ids\n",
    "    df_feature.drop(['time_id__450', 'time_id__300', 'time_id__150','time_id'], axis = 1, inplace = True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    df_feature = df_feature.add_prefix('trade_')\n",
    "    stock_id = file_path.split('=')[1]\n",
    "    df_feature['row_id'] = df_feature['trade_time_id_'].apply(lambda x:f'{stock_id}-{x}')\n",
    "    df_feature.drop(['trade_time_id_'], axis = 1, inplace = True)\n",
    "    return df_feature\n",
    "\n",
    "# Function to get group stats for the stock_id and time_id\n",
    "def get_time_stock(df):\n",
    "    # Get realized volatility columns\n",
    "    vol_cols = ['log_return1_realized_volatility', 'log_return2_realized_volatility', 'log_return1_realized_volatility_450', 'log_return2_realized_volatility_450', \n",
    "                'log_return1_realized_volatility_300', 'log_return2_realized_volatility_300', 'log_return1_realized_volatility_150', 'log_return2_realized_volatility_150', \n",
    "                'trade_log_return_realized_volatility', 'trade_log_return_realized_volatility_450', 'trade_log_return_realized_volatility_300', 'trade_log_return_realized_volatility_150']\n",
    "#     vol_cols = ['log_return1_realized_volatility', 'log_return2_realized_volatility',\n",
    "#                 'log_return1_realized_volatility_600', 'log_return2_realized_volatility_600', \n",
    "#                 'log_return1_realized_volatility_400', 'log_return2_realized_volatility_400',\n",
    "# #                 'log_return1_realized_volatility_300', 'log_return2_realized_volatility_300', \n",
    "#                 'log_return1_realized_volatility_200', 'log_return2_realized_volatility_200',\n",
    "# #                 'log_return1_realized_volatility_100', 'log_return2_realized_volatility_100', \n",
    "#                 'trade_log_return_realized_volatility',\n",
    "#                 'trade_log_return_realized_volatility_600', \n",
    "#                 'trade_log_return_realized_volatility_400',\n",
    "# #                 'trade_log_return_realized_volatility_300',\n",
    "# #                 'trade_log_return_realized_volatility_100',\n",
    "#                 'trade_log_return_realized_volatility_200']\n",
    "\n",
    "    # Group by the stock id\n",
    "    df_stock_id = df.groupby(['stock_id'])[vol_cols].agg(['mean', 'std', 'max', 'min', ]).reset_index()\n",
    "    # Rename columns joining suffix\n",
    "    df_stock_id.columns = ['_'.join(col) for col in df_stock_id.columns]\n",
    "    df_stock_id = df_stock_id.add_suffix('_' + 'stock')\n",
    "\n",
    "    # Group by the stock id\n",
    "    df_time_id = df.groupby(['time_id'])[vol_cols].agg(['mean', 'std', 'max', 'min', ]).reset_index()\n",
    "    # Rename columns joining suffix\n",
    "    df_time_id.columns = ['_'.join(col) for col in df_time_id.columns]\n",
    "    df_time_id = df_time_id.add_suffix('_' + 'time')\n",
    "    \n",
    "    # Merge with original dataframe\n",
    "    df = df.merge(df_stock_id, how = 'left', left_on = ['stock_id'], right_on = ['stock_id__stock'])\n",
    "    df = df.merge(df_time_id, how = 'left', left_on = ['time_id'], right_on = ['time_id__time'])\n",
    "    df.drop(['stock_id__stock', 'time_id__time'], axis = 1, inplace = True)\n",
    "    return df\n",
    "    \n",
    "# Funtion to make preprocessing function in parallel (for each stock id)\n",
    "def preprocessor(list_stock_ids, is_train = True):\n",
    "    \n",
    "    # Parrallel for loop\n",
    "    def for_joblib(stock_id):\n",
    "        # Train\n",
    "        if is_train:\n",
    "            file_path_book = data_dir + \"book_train.parquet/stock_id=\" + str(stock_id)\n",
    "            file_path_trade = data_dir + \"trade_train.parquet/stock_id=\" + str(stock_id)\n",
    "        # Test\n",
    "        else:\n",
    "            file_path_book = data_dir + \"book_test.parquet/stock_id=\" + str(stock_id)\n",
    "            file_path_trade = data_dir + \"trade_test.parquet/stock_id=\" + str(stock_id)\n",
    "    \n",
    "        # Preprocess book and trade data and merge them\n",
    "        df_tmp = pd.merge(book_preprocessor(file_path_book), trade_preprocessor(file_path_trade), on = 'row_id', how = 'left')\n",
    "        \n",
    "        # Return the merge dataframe\n",
    "        return df_tmp\n",
    "    \n",
    "    # Use parallel api to call paralle for loop\n",
    "    df = Parallel(n_jobs = -1, verbose = 1)(delayed(for_joblib)(stock_id) for stock_id in list_stock_ids)\n",
    "    # Concatenate all the dataframes that return from Parallel\n",
    "    df = pd.concat(df, ignore_index = True)\n",
    "    return df\n",
    "\n",
    "# Function to calculate the root mean squared percentage error\n",
    "def rmspe(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square((y_true - y_pred) / y_true)))\n",
    "\n",
    "# Function to early stop with root mean squared percentage error\n",
    "def feval_rmspe(y_pred, lgb_train):\n",
    "    y_true = lgb_train.get_label()\n",
    "    return 'RMSPE', rmspe(y_true, y_pred), False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "chemical-issue",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-26T09:52:27.532322Z",
     "iopub.status.busy": "2021-09-26T09:52:27.531671Z",
     "iopub.status.idle": "2021-09-26T10:56:48.570906Z",
     "shell.execute_reply": "2021-09-26T10:56:48.570314Z",
     "shell.execute_reply.started": "2021-09-24T08:13:34.985082Z"
    },
    "papermill": {
     "duration": 3861.102063,
     "end_time": "2021-09-26T10:56:48.571072",
     "exception": false,
     "start_time": "2021-09-26T09:52:27.469009",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our training set has 428932 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 24.9min\n",
      "[Parallel(n_jobs=-1)]: Done 112 out of 112 | elapsed: 63.4min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.4s finished\n"
     ]
    }
   ],
   "source": [
    "# Read train and test\n",
    "train, test = read_train_test()\n",
    "\n",
    "# Get unique stock ids \n",
    "train_stock_ids = train['stock_id'].unique()\n",
    "# Preprocess them using Parallel and our single stock id functions\n",
    "train_ = preprocessor(train_stock_ids, is_train = True)\n",
    "train = train.merge(train_, on = ['row_id'], how = 'left')\n",
    "\n",
    "# Get unique stock ids \n",
    "test_stock_ids = test['stock_id'].unique()\n",
    "# Preprocess them using Parallel and our single stock id functions\n",
    "test_ = preprocessor(test_stock_ids, is_train = False)\n",
    "test = test.merge(test_, on = ['row_id'], how = 'left')\n",
    "\n",
    "# Get group stats of time_id and stock_id\n",
    "train = get_time_stock(train)\n",
    "test = get_time_stock(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "educational-robinson",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-26T10:56:48.693899Z",
     "iopub.status.busy": "2021-09-26T10:56:48.693239Z",
     "iopub.status.idle": "2021-09-26T10:56:50.291527Z",
     "shell.execute_reply": "2021-09-26T10:56:50.290974Z",
     "shell.execute_reply.started": "2021-09-24T09:20:14.500321Z"
    },
    "papermill": {
     "duration": 1.66208,
     "end_time": "2021-09-26T10:56:50.291677",
     "exception": false,
     "start_time": "2021-09-26T10:56:48.629597",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train.to_pickle('dataset_baseline_train_best.pkl')\n",
    "test.to_pickle('dataset_baseline_test_best.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "published-magnet",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-26T10:56:50.424541Z",
     "iopub.status.busy": "2021-09-26T10:56:50.423812Z",
     "iopub.status.idle": "2021-09-26T10:56:50.427802Z",
     "shell.execute_reply": "2021-09-26T10:56:50.428304Z",
     "shell.execute_reply.started": "2021-09-24T09:20:17.024638Z"
    },
    "papermill": {
     "duration": 0.078004,
     "end_time": "2021-09-26T10:56:50.428483",
     "exception": false,
     "start_time": "2021-09-26T10:56:50.350479",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['stock_id',\n",
       " 'time_id',\n",
       " 'target',\n",
       " 'row_id',\n",
       " 'calc_depth_sum',\n",
       " 'calc_depth_mean',\n",
       " 'calc_depth_std',\n",
       " 'calc_slope1_sum',\n",
       " 'calc_slope1_mean',\n",
       " 'calc_slope1_std',\n",
       " 'calc_slope2_sum',\n",
       " 'calc_slope2_mean',\n",
       " 'calc_slope2_std',\n",
       " 'calc_price_impact1_sum',\n",
       " 'calc_price_impact1_mean',\n",
       " 'calc_price_impact1_std',\n",
       " 'calc_price_impact2_sum',\n",
       " 'calc_price_impact2_mean',\n",
       " 'calc_price_impact2_std',\n",
       " 'calc_ofi_sum',\n",
       " 'calc_ofi_mean',\n",
       " 'calc_ofi_std',\n",
       " 'wap1_sum',\n",
       " 'wap1_mean',\n",
       " 'wap1_std',\n",
       " 'wap2_sum',\n",
       " 'wap2_mean',\n",
       " 'wap2_std',\n",
       " 'log_return1_sum',\n",
       " 'log_return1_realized_volatility',\n",
       " 'log_return1_mean',\n",
       " 'log_return1_std',\n",
       " 'log_return1_realized_absvar',\n",
       " 'log_return1_realized_bipowvar',\n",
       " 'log_return2_sum',\n",
       " 'log_return2_realized_volatility',\n",
       " 'log_return2_mean',\n",
       " 'log_return2_std',\n",
       " 'log_return2_realized_absvar',\n",
       " 'log_return2_realized_bipowvar',\n",
       " 'wap_balance_sum',\n",
       " 'wap_balance_mean',\n",
       " 'wap_balance_std',\n",
       " 'price_spread_sum',\n",
       " 'price_spread_mean',\n",
       " 'price_spread_std',\n",
       " 'price_spread2_sum',\n",
       " 'price_spread2_mean',\n",
       " 'price_spread2_std',\n",
       " 'bid_spread_sum',\n",
       " 'bid_spread_mean',\n",
       " 'bid_spread_std',\n",
       " 'ask_spread_sum',\n",
       " 'ask_spread_mean',\n",
       " 'ask_spread_std',\n",
       " 'total_volume_sum',\n",
       " 'total_volume_mean',\n",
       " 'total_volume_std',\n",
       " 'volume_imbalance_sum',\n",
       " 'volume_imbalance_mean',\n",
       " 'volume_imbalance_std',\n",
       " 'bid_ask_spread_sum',\n",
       " 'bid_ask_spread_mean',\n",
       " 'bid_ask_spread_std',\n",
       " 'calc_depth_sum_450',\n",
       " 'calc_depth_mean_450',\n",
       " 'calc_depth_std_450',\n",
       " 'calc_slope1_sum_450',\n",
       " 'calc_slope1_mean_450',\n",
       " 'calc_slope1_std_450',\n",
       " 'calc_slope2_sum_450',\n",
       " 'calc_slope2_mean_450',\n",
       " 'calc_slope2_std_450',\n",
       " 'calc_price_impact1_sum_450',\n",
       " 'calc_price_impact1_mean_450',\n",
       " 'calc_price_impact1_std_450',\n",
       " 'calc_price_impact2_sum_450',\n",
       " 'calc_price_impact2_mean_450',\n",
       " 'calc_price_impact2_std_450',\n",
       " 'calc_ofi_sum_450',\n",
       " 'calc_ofi_mean_450',\n",
       " 'calc_ofi_std_450',\n",
       " 'wap1_sum_450',\n",
       " 'wap1_mean_450',\n",
       " 'wap1_std_450',\n",
       " 'wap2_sum_450',\n",
       " 'wap2_mean_450',\n",
       " 'wap2_std_450',\n",
       " 'log_return1_sum_450',\n",
       " 'log_return1_realized_volatility_450',\n",
       " 'log_return1_mean_450',\n",
       " 'log_return1_std_450',\n",
       " 'log_return1_realized_absvar_450',\n",
       " 'log_return1_realized_bipowvar_450',\n",
       " 'log_return2_sum_450',\n",
       " 'log_return2_realized_volatility_450',\n",
       " 'log_return2_mean_450',\n",
       " 'log_return2_std_450',\n",
       " 'log_return2_realized_absvar_450',\n",
       " 'log_return2_realized_bipowvar_450',\n",
       " 'wap_balance_sum_450',\n",
       " 'wap_balance_mean_450',\n",
       " 'wap_balance_std_450',\n",
       " 'price_spread_sum_450',\n",
       " 'price_spread_mean_450',\n",
       " 'price_spread_std_450',\n",
       " 'price_spread2_sum_450',\n",
       " 'price_spread2_mean_450',\n",
       " 'price_spread2_std_450',\n",
       " 'bid_spread_sum_450',\n",
       " 'bid_spread_mean_450',\n",
       " 'bid_spread_std_450',\n",
       " 'ask_spread_sum_450',\n",
       " 'ask_spread_mean_450',\n",
       " 'ask_spread_std_450',\n",
       " 'total_volume_sum_450',\n",
       " 'total_volume_mean_450',\n",
       " 'total_volume_std_450',\n",
       " 'volume_imbalance_sum_450',\n",
       " 'volume_imbalance_mean_450',\n",
       " 'volume_imbalance_std_450',\n",
       " 'bid_ask_spread_sum_450',\n",
       " 'bid_ask_spread_mean_450',\n",
       " 'bid_ask_spread_std_450',\n",
       " 'calc_depth_sum_300',\n",
       " 'calc_depth_mean_300',\n",
       " 'calc_depth_std_300',\n",
       " 'calc_slope1_sum_300',\n",
       " 'calc_slope1_mean_300',\n",
       " 'calc_slope1_std_300',\n",
       " 'calc_slope2_sum_300',\n",
       " 'calc_slope2_mean_300',\n",
       " 'calc_slope2_std_300',\n",
       " 'calc_price_impact1_sum_300',\n",
       " 'calc_price_impact1_mean_300',\n",
       " 'calc_price_impact1_std_300',\n",
       " 'calc_price_impact2_sum_300',\n",
       " 'calc_price_impact2_mean_300',\n",
       " 'calc_price_impact2_std_300',\n",
       " 'calc_ofi_sum_300',\n",
       " 'calc_ofi_mean_300',\n",
       " 'calc_ofi_std_300',\n",
       " 'wap1_sum_300',\n",
       " 'wap1_mean_300',\n",
       " 'wap1_std_300',\n",
       " 'wap2_sum_300',\n",
       " 'wap2_mean_300',\n",
       " 'wap2_std_300',\n",
       " 'log_return1_sum_300',\n",
       " 'log_return1_realized_volatility_300',\n",
       " 'log_return1_mean_300',\n",
       " 'log_return1_std_300',\n",
       " 'log_return1_realized_absvar_300',\n",
       " 'log_return1_realized_bipowvar_300',\n",
       " 'log_return2_sum_300',\n",
       " 'log_return2_realized_volatility_300',\n",
       " 'log_return2_mean_300',\n",
       " 'log_return2_std_300',\n",
       " 'log_return2_realized_absvar_300',\n",
       " 'log_return2_realized_bipowvar_300',\n",
       " 'wap_balance_sum_300',\n",
       " 'wap_balance_mean_300',\n",
       " 'wap_balance_std_300',\n",
       " 'price_spread_sum_300',\n",
       " 'price_spread_mean_300',\n",
       " 'price_spread_std_300',\n",
       " 'price_spread2_sum_300',\n",
       " 'price_spread2_mean_300',\n",
       " 'price_spread2_std_300',\n",
       " 'bid_spread_sum_300',\n",
       " 'bid_spread_mean_300',\n",
       " 'bid_spread_std_300',\n",
       " 'ask_spread_sum_300',\n",
       " 'ask_spread_mean_300',\n",
       " 'ask_spread_std_300',\n",
       " 'total_volume_sum_300',\n",
       " 'total_volume_mean_300',\n",
       " 'total_volume_std_300',\n",
       " 'volume_imbalance_sum_300',\n",
       " 'volume_imbalance_mean_300',\n",
       " 'volume_imbalance_std_300',\n",
       " 'bid_ask_spread_sum_300',\n",
       " 'bid_ask_spread_mean_300',\n",
       " 'bid_ask_spread_std_300',\n",
       " 'calc_depth_sum_150',\n",
       " 'calc_depth_mean_150',\n",
       " 'calc_depth_std_150',\n",
       " 'calc_slope1_sum_150',\n",
       " 'calc_slope1_mean_150',\n",
       " 'calc_slope1_std_150',\n",
       " 'calc_slope2_sum_150',\n",
       " 'calc_slope2_mean_150',\n",
       " 'calc_slope2_std_150',\n",
       " 'calc_price_impact1_sum_150',\n",
       " 'calc_price_impact1_mean_150',\n",
       " 'calc_price_impact1_std_150',\n",
       " 'calc_price_impact2_sum_150',\n",
       " 'calc_price_impact2_mean_150',\n",
       " 'calc_price_impact2_std_150',\n",
       " 'calc_ofi_sum_150',\n",
       " 'calc_ofi_mean_150',\n",
       " 'calc_ofi_std_150',\n",
       " 'wap1_sum_150',\n",
       " 'wap1_mean_150',\n",
       " 'wap1_std_150',\n",
       " 'wap2_sum_150',\n",
       " 'wap2_mean_150',\n",
       " 'wap2_std_150',\n",
       " 'log_return1_sum_150',\n",
       " 'log_return1_realized_volatility_150',\n",
       " 'log_return1_mean_150',\n",
       " 'log_return1_std_150',\n",
       " 'log_return1_realized_absvar_150',\n",
       " 'log_return1_realized_bipowvar_150',\n",
       " 'log_return2_sum_150',\n",
       " 'log_return2_realized_volatility_150',\n",
       " 'log_return2_mean_150',\n",
       " 'log_return2_std_150',\n",
       " 'log_return2_realized_absvar_150',\n",
       " 'log_return2_realized_bipowvar_150',\n",
       " 'wap_balance_sum_150',\n",
       " 'wap_balance_mean_150',\n",
       " 'wap_balance_std_150',\n",
       " 'price_spread_sum_150',\n",
       " 'price_spread_mean_150',\n",
       " 'price_spread_std_150',\n",
       " 'price_spread2_sum_150',\n",
       " 'price_spread2_mean_150',\n",
       " 'price_spread2_std_150',\n",
       " 'bid_spread_sum_150',\n",
       " 'bid_spread_mean_150',\n",
       " 'bid_spread_std_150',\n",
       " 'ask_spread_sum_150',\n",
       " 'ask_spread_mean_150',\n",
       " 'ask_spread_std_150',\n",
       " 'total_volume_sum_150',\n",
       " 'total_volume_mean_150',\n",
       " 'total_volume_std_150',\n",
       " 'volume_imbalance_sum_150',\n",
       " 'volume_imbalance_mean_150',\n",
       " 'volume_imbalance_std_150',\n",
       " 'bid_ask_spread_sum_150',\n",
       " 'bid_ask_spread_mean_150',\n",
       " 'bid_ask_spread_std_150',\n",
       " 'trade_log_return_realized_volatility',\n",
       " 'trade_log_return_realized_absvar',\n",
       " 'trade_log_return_realized_bipowvar',\n",
       " 'trade_seconds_in_bucket_count_unique',\n",
       " 'trade_size_sum',\n",
       " 'trade_size_realized_volatility',\n",
       " 'trade_size_mean',\n",
       " 'trade_size_std',\n",
       " 'trade_size_amax',\n",
       " 'trade_size_amin',\n",
       " 'trade_order_count_mean',\n",
       " 'trade_order_count_sum',\n",
       " 'trade_order_count_amax',\n",
       " 'trade_tendency',\n",
       " 'trade_f_max',\n",
       " 'trade_f_min',\n",
       " 'trade_df_max',\n",
       " 'trade_df_min',\n",
       " 'trade_abs_diff',\n",
       " 'trade_energy',\n",
       " 'trade_iqr_p',\n",
       " 'trade_abs_diff_v',\n",
       " 'trade_energy_v',\n",
       " 'trade_iqr_p_v',\n",
       " 'trade_log_return_realized_volatility_450',\n",
       " 'trade_log_return_realized_absvar_450',\n",
       " 'trade_log_return_realized_bipowvar_450',\n",
       " 'trade_seconds_in_bucket_count_unique_450',\n",
       " 'trade_size_sum_450',\n",
       " 'trade_size_realized_volatility_450',\n",
       " 'trade_size_mean_450',\n",
       " 'trade_size_std_450',\n",
       " 'trade_size_amax_450',\n",
       " 'trade_size_amin_450',\n",
       " 'trade_order_count_mean_450',\n",
       " 'trade_order_count_sum_450',\n",
       " 'trade_order_count_amax_450',\n",
       " 'trade_log_return_realized_volatility_300',\n",
       " 'trade_log_return_realized_absvar_300',\n",
       " 'trade_log_return_realized_bipowvar_300',\n",
       " 'trade_seconds_in_bucket_count_unique_300',\n",
       " 'trade_size_sum_300',\n",
       " 'trade_size_realized_volatility_300',\n",
       " 'trade_size_mean_300',\n",
       " 'trade_size_std_300',\n",
       " 'trade_size_amax_300',\n",
       " 'trade_size_amin_300',\n",
       " 'trade_order_count_mean_300',\n",
       " 'trade_order_count_sum_300',\n",
       " 'trade_order_count_amax_300',\n",
       " 'trade_log_return_realized_volatility_150',\n",
       " 'trade_log_return_realized_absvar_150',\n",
       " 'trade_log_return_realized_bipowvar_150',\n",
       " 'trade_seconds_in_bucket_count_unique_150',\n",
       " 'trade_size_sum_150',\n",
       " 'trade_size_realized_volatility_150',\n",
       " 'trade_size_mean_150',\n",
       " 'trade_size_std_150',\n",
       " 'trade_size_amax_150',\n",
       " 'trade_size_amin_150',\n",
       " 'trade_order_count_mean_150',\n",
       " 'trade_order_count_sum_150',\n",
       " 'trade_order_count_amax_150',\n",
       " 'log_return1_realized_volatility_mean_stock',\n",
       " 'log_return1_realized_volatility_std_stock',\n",
       " 'log_return1_realized_volatility_max_stock',\n",
       " 'log_return1_realized_volatility_min_stock',\n",
       " 'log_return2_realized_volatility_mean_stock',\n",
       " 'log_return2_realized_volatility_std_stock',\n",
       " 'log_return2_realized_volatility_max_stock',\n",
       " 'log_return2_realized_volatility_min_stock',\n",
       " 'log_return1_realized_volatility_450_mean_stock',\n",
       " 'log_return1_realized_volatility_450_std_stock',\n",
       " 'log_return1_realized_volatility_450_max_stock',\n",
       " 'log_return1_realized_volatility_450_min_stock',\n",
       " 'log_return2_realized_volatility_450_mean_stock',\n",
       " 'log_return2_realized_volatility_450_std_stock',\n",
       " 'log_return2_realized_volatility_450_max_stock',\n",
       " 'log_return2_realized_volatility_450_min_stock',\n",
       " 'log_return1_realized_volatility_300_mean_stock',\n",
       " 'log_return1_realized_volatility_300_std_stock',\n",
       " 'log_return1_realized_volatility_300_max_stock',\n",
       " 'log_return1_realized_volatility_300_min_stock',\n",
       " 'log_return2_realized_volatility_300_mean_stock',\n",
       " 'log_return2_realized_volatility_300_std_stock',\n",
       " 'log_return2_realized_volatility_300_max_stock',\n",
       " 'log_return2_realized_volatility_300_min_stock',\n",
       " 'log_return1_realized_volatility_150_mean_stock',\n",
       " 'log_return1_realized_volatility_150_std_stock',\n",
       " 'log_return1_realized_volatility_150_max_stock',\n",
       " 'log_return1_realized_volatility_150_min_stock',\n",
       " 'log_return2_realized_volatility_150_mean_stock',\n",
       " 'log_return2_realized_volatility_150_std_stock',\n",
       " 'log_return2_realized_volatility_150_max_stock',\n",
       " 'log_return2_realized_volatility_150_min_stock',\n",
       " 'trade_log_return_realized_volatility_mean_stock',\n",
       " 'trade_log_return_realized_volatility_std_stock',\n",
       " 'trade_log_return_realized_volatility_max_stock',\n",
       " 'trade_log_return_realized_volatility_min_stock',\n",
       " 'trade_log_return_realized_volatility_450_mean_stock',\n",
       " 'trade_log_return_realized_volatility_450_std_stock',\n",
       " 'trade_log_return_realized_volatility_450_max_stock',\n",
       " 'trade_log_return_realized_volatility_450_min_stock',\n",
       " 'trade_log_return_realized_volatility_300_mean_stock',\n",
       " 'trade_log_return_realized_volatility_300_std_stock',\n",
       " 'trade_log_return_realized_volatility_300_max_stock',\n",
       " 'trade_log_return_realized_volatility_300_min_stock',\n",
       " 'trade_log_return_realized_volatility_150_mean_stock',\n",
       " 'trade_log_return_realized_volatility_150_std_stock',\n",
       " 'trade_log_return_realized_volatility_150_max_stock',\n",
       " 'trade_log_return_realized_volatility_150_min_stock',\n",
       " 'log_return1_realized_volatility_mean_time',\n",
       " 'log_return1_realized_volatility_std_time',\n",
       " 'log_return1_realized_volatility_max_time',\n",
       " 'log_return1_realized_volatility_min_time',\n",
       " 'log_return2_realized_volatility_mean_time',\n",
       " 'log_return2_realized_volatility_std_time',\n",
       " 'log_return2_realized_volatility_max_time',\n",
       " 'log_return2_realized_volatility_min_time',\n",
       " 'log_return1_realized_volatility_450_mean_time',\n",
       " 'log_return1_realized_volatility_450_std_time',\n",
       " 'log_return1_realized_volatility_450_max_time',\n",
       " 'log_return1_realized_volatility_450_min_time',\n",
       " 'log_return2_realized_volatility_450_mean_time',\n",
       " 'log_return2_realized_volatility_450_std_time',\n",
       " 'log_return2_realized_volatility_450_max_time',\n",
       " 'log_return2_realized_volatility_450_min_time',\n",
       " 'log_return1_realized_volatility_300_mean_time',\n",
       " 'log_return1_realized_volatility_300_std_time',\n",
       " 'log_return1_realized_volatility_300_max_time',\n",
       " 'log_return1_realized_volatility_300_min_time',\n",
       " 'log_return2_realized_volatility_300_mean_time',\n",
       " 'log_return2_realized_volatility_300_std_time',\n",
       " 'log_return2_realized_volatility_300_max_time',\n",
       " 'log_return2_realized_volatility_300_min_time',\n",
       " 'log_return1_realized_volatility_150_mean_time',\n",
       " 'log_return1_realized_volatility_150_std_time',\n",
       " 'log_return1_realized_volatility_150_max_time',\n",
       " 'log_return1_realized_volatility_150_min_time',\n",
       " 'log_return2_realized_volatility_150_mean_time',\n",
       " 'log_return2_realized_volatility_150_std_time',\n",
       " 'log_return2_realized_volatility_150_max_time',\n",
       " 'log_return2_realized_volatility_150_min_time',\n",
       " 'trade_log_return_realized_volatility_mean_time',\n",
       " 'trade_log_return_realized_volatility_std_time',\n",
       " 'trade_log_return_realized_volatility_max_time',\n",
       " 'trade_log_return_realized_volatility_min_time',\n",
       " 'trade_log_return_realized_volatility_450_mean_time',\n",
       " 'trade_log_return_realized_volatility_450_std_time',\n",
       " 'trade_log_return_realized_volatility_450_max_time',\n",
       " 'trade_log_return_realized_volatility_450_min_time',\n",
       " 'trade_log_return_realized_volatility_300_mean_time',\n",
       " 'trade_log_return_realized_volatility_300_std_time',\n",
       " 'trade_log_return_realized_volatility_300_max_time',\n",
       " 'trade_log_return_realized_volatility_300_min_time',\n",
       " 'trade_log_return_realized_volatility_150_mean_time',\n",
       " 'trade_log_return_realized_volatility_150_std_time',\n",
       " 'trade_log_return_realized_volatility_150_max_time',\n",
       " 'trade_log_return_realized_volatility_150_min_time']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "yellow-savannah",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-26T10:56:50.550760Z",
     "iopub.status.busy": "2021-09-26T10:56:50.550066Z",
     "iopub.status.idle": "2021-09-26T10:56:50.574943Z",
     "shell.execute_reply": "2021-09-26T10:56:50.575500Z",
     "shell.execute_reply.started": "2021-09-24T09:20:17.043099Z"
    },
    "papermill": {
     "duration": 0.087847,
     "end_time": "2021-09-26T10:56:50.575677",
     "exception": false,
     "start_time": "2021-09-26T10:56:50.487830",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# replace by order sum (tau)\n",
    "train['size_tau'] = np.sqrt( 1/ train['trade_seconds_in_bucket_count_unique'] )\n",
    "test['size_tau'] = np.sqrt( 1/ test['trade_seconds_in_bucket_count_unique'] )\n",
    "train['size_tau_450'] = np.sqrt( 1/ train['trade_seconds_in_bucket_count_unique_450'] )\n",
    "test['size_tau_450'] = np.sqrt( 1/ test['trade_seconds_in_bucket_count_unique_450'] )\n",
    "train['size_tau_300'] = np.sqrt( 1/ train['trade_seconds_in_bucket_count_unique_300'] )\n",
    "test['size_tau_300'] = np.sqrt( 1/ test['trade_seconds_in_bucket_count_unique_300'] )\n",
    "train['size_tau_150'] = np.sqrt( 1/ train['trade_seconds_in_bucket_count_unique_150'] )\n",
    "test['size_tau_150'] = np.sqrt( 1/ test['trade_seconds_in_bucket_count_unique_150'] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "grateful-amount",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-26T10:56:50.697798Z",
     "iopub.status.busy": "2021-09-26T10:56:50.697158Z",
     "iopub.status.idle": "2021-09-26T10:56:50.723591Z",
     "shell.execute_reply": "2021-09-26T10:56:50.724128Z",
     "shell.execute_reply.started": "2021-09-24T09:20:17.081102Z"
    },
    "papermill": {
     "duration": 0.089176,
     "end_time": "2021-09-26T10:56:50.724342",
     "exception": false,
     "start_time": "2021-09-26T10:56:50.635166",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train['size_tau2'] = np.sqrt( 1/ train['trade_order_count_sum'] )\n",
    "test['size_tau2'] = np.sqrt( 1/ test['trade_order_count_sum'] )\n",
    "train['size_tau2_450'] = np.sqrt( 0.25/ train['trade_order_count_sum'] )\n",
    "test['size_tau2_450'] = np.sqrt( 0.25/ test['trade_order_count_sum'] )\n",
    "train['size_tau2_300'] = np.sqrt( 0.5/ train['trade_order_count_sum'] )\n",
    "test['size_tau2_300'] = np.sqrt( 0.5/ test['trade_order_count_sum'] )\n",
    "train['size_tau2_150'] = np.sqrt( 0.75/ train['trade_order_count_sum'] )\n",
    "test['size_tau2_150'] = np.sqrt( 0.75/ test['trade_order_count_sum'] )\n",
    "\n",
    "# delta tau\n",
    "train['size_tau2_d'] = train['size_tau2_450'] - train['size_tau2']\n",
    "test['size_tau2_d'] = test['size_tau2_450'] - test['size_tau2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "smart-footwear",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-26T10:56:50.848990Z",
     "iopub.status.busy": "2021-09-26T10:56:50.848342Z",
     "iopub.status.idle": "2021-09-26T10:56:50.862290Z",
     "shell.execute_reply": "2021-09-26T10:56:50.861709Z",
     "shell.execute_reply.started": "2021-09-24T09:20:17.114167Z"
    },
    "papermill": {
     "duration": 0.07647,
     "end_time": "2021-09-26T10:56:50.862448",
     "exception": false,
     "start_time": "2021-09-26T10:56:50.785978",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train['book_BPV_jump1'] = train['log_return1_realized_volatility'] - train['log_return1_realized_bipowvar'].values\n",
    "train['book_BPV_jump1'] = np.where(train['book_BPV_jump1']<0, 0, train['book_BPV_jump1'])\n",
    "\n",
    "test['book_BPV_jump1'] = test['log_return1_realized_volatility'] - test['log_return1_realized_bipowvar'].values\n",
    "test['book_BPV_jump1'] = np.where(test['book_BPV_jump1']<0, 0, test['book_BPV_jump1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nuclear-webster",
   "metadata": {
    "papermill": {
     "duration": 0.060017,
     "end_time": "2021-09-26T10:56:50.981767",
     "exception": false,
     "start_time": "2021-09-26T10:56:50.921750",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training model and making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "disabled-tyler",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-26T10:56:51.129975Z",
     "iopub.status.busy": "2021-09-26T10:56:51.128858Z",
     "iopub.status.idle": "2021-09-26T10:56:56.789446Z",
     "shell.execute_reply": "2021-09-26T10:56:56.788550Z",
     "shell.execute_reply.started": "2021-09-24T09:20:17.131358Z"
    },
    "papermill": {
     "duration": 5.741764,
     "end_time": "2021-09-26T10:56:56.789610",
     "exception": false,
     "start_time": "2021-09-26T10:56:51.047846",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(42)\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "legislative-tutorial",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-26T10:56:56.924287Z",
     "iopub.status.busy": "2021-09-26T10:56:56.923580Z",
     "iopub.status.idle": "2021-09-26T10:57:08.622124Z",
     "shell.execute_reply": "2021-09-26T10:57:08.620893Z",
     "shell.execute_reply.started": "2021-09-24T09:20:23.297993Z"
    },
    "papermill": {
     "duration": 11.763411,
     "end_time": "2021-09-26T10:57:08.622328",
     "exception": false,
     "start_time": "2021-09-26T10:56:56.858917",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# kfold based on the knn++ algorithm\n",
    "\n",
    "out_train = pd.read_csv('../input/optiver-realized-volatility-prediction/train.csv')\n",
    "out_train = out_train.pivot(index='time_id', columns='stock_id', values='target')\n",
    "\n",
    "#out_train[out_train.isna().any(axis=1)]\n",
    "out_train = out_train.fillna(out_train.mean())\n",
    "out_train.head()\n",
    "\n",
    "# code to add the just the read data after first execution\n",
    "\n",
    "# data separation based on knn ++\n",
    "nfolds = 5 # number of folds\n",
    "index = []\n",
    "totDist = []\n",
    "values = []\n",
    "# generates a matriz with the values of \n",
    "mat = out_train.values\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "mat = scaler.fit_transform(mat)\n",
    "\n",
    "nind = int(mat.shape[0]/nfolds) # number of individuals\n",
    "\n",
    "# adds index in the last column\n",
    "mat = np.c_[mat,np.arange(mat.shape[0])]\n",
    "\n",
    "\n",
    "lineNumber = np.random.choice(np.array(mat.shape[0]), size=nfolds, replace=False)\n",
    "\n",
    "lineNumber = np.sort(lineNumber)[::-1]\n",
    "\n",
    "for n in range(nfolds):\n",
    "    totDist.append(np.zeros(mat.shape[0]-nfolds))\n",
    "\n",
    "# saves index\n",
    "for n in range(nfolds):\n",
    "    \n",
    "    values.append([lineNumber[n]])    \n",
    "\n",
    "\n",
    "s=[]\n",
    "for n in range(nfolds):\n",
    "    s.append(mat[lineNumber[n],:])\n",
    "    \n",
    "    mat = np.delete(mat, obj=lineNumber[n], axis=0)\n",
    "\n",
    "for n in range(nind-1):    \n",
    "\n",
    "    luck = np.random.uniform(0,1,nfolds)\n",
    "    \n",
    "    for cycle in range(nfolds):\n",
    "         # saves the values of index           \n",
    "\n",
    "        s[cycle] = np.matlib.repmat(s[cycle], mat.shape[0], 1)\n",
    "\n",
    "        sumDist = np.sum( (mat[:,:-1] - s[cycle][:,:-1])**2 , axis=1)   \n",
    "        totDist[cycle] += sumDist        \n",
    "                \n",
    "        # probabilities\n",
    "        f = totDist[cycle]/np.sum(totDist[cycle]) # normalizing the totdist\n",
    "        j = 0\n",
    "        kn = 0\n",
    "        for val in f:\n",
    "            j += val        \n",
    "            if (j > luck[cycle]): # the column was selected\n",
    "                break\n",
    "            kn +=1\n",
    "        lineNumber[cycle] = kn\n",
    "        \n",
    "        # delete line of the value added    \n",
    "        for n_iter in range(nfolds):\n",
    "            \n",
    "            totDist[n_iter] = np.delete(totDist[n_iter],obj=lineNumber[cycle], axis=0)\n",
    "            j= 0\n",
    "        \n",
    "        s[cycle] = mat[lineNumber[cycle],:]\n",
    "        values[cycle].append(int(mat[lineNumber[cycle],-1]))\n",
    "        mat = np.delete(mat, obj=lineNumber[cycle], axis=0)\n",
    "\n",
    "\n",
    "for n_mod in range(nfolds):\n",
    "    values[n_mod] = out_train.index[values[n_mod]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "suburban-universe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-26T10:57:08.753394Z",
     "iopub.status.busy": "2021-09-26T10:57:08.752747Z",
     "iopub.status.idle": "2021-09-26T10:57:08.755410Z",
     "shell.execute_reply": "2021-09-26T10:57:08.755850Z",
     "shell.execute_reply.started": "2021-09-24T09:20:35.038455Z"
    },
    "papermill": {
     "duration": 0.071599,
     "end_time": "2021-09-26T10:57:08.756026",
     "exception": false,
     "start_time": "2021-09-26T10:57:08.684427",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def root_mean_squared_per_error(y_true, y_pred):\n",
    "         return K.sqrt(K.mean(K.square( (y_true - y_pred)/ y_true )))\n",
    "    \n",
    "es = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', patience=20, verbose=0,\n",
    "    mode='min',restore_best_weights=True)\n",
    "\n",
    "plateau = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=0.1, patience=7, verbose=0,\n",
    "    mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "clean-coupon",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-26T10:57:08.945982Z",
     "iopub.status.busy": "2021-09-26T10:57:08.944981Z",
     "iopub.status.idle": "2021-09-26T10:57:08.947455Z",
     "shell.execute_reply": "2021-09-26T10:57:08.947962Z",
     "shell.execute_reply.started": "2021-09-24T09:20:35.046336Z"
    },
    "papermill": {
     "duration": 0.068735,
     "end_time": "2021-09-26T10:57:08.948166",
     "exception": false,
     "start_time": "2021-09-26T10:57:08.879431",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "colNames = list(train)\n",
    "\n",
    "colNames.remove('time_id')\n",
    "colNames.remove('target')\n",
    "colNames.remove('row_id')\n",
    "colNames.remove('stock_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "virgin-sport",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-26T10:57:09.072721Z",
     "iopub.status.busy": "2021-09-26T10:57:09.071716Z",
     "iopub.status.idle": "2021-09-26T10:58:14.081729Z",
     "shell.execute_reply": "2021-09-26T10:58:14.081131Z",
     "shell.execute_reply.started": "2021-09-24T09:20:35.059695Z"
    },
    "papermill": {
     "duration": 65.074472,
     "end_time": "2021-09-26T10:58:14.081897",
     "exception": false,
     "start_time": "2021-09-26T10:57:09.007425",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train.replace([np.inf, -np.inf], np.nan,inplace=True)\n",
    "test.replace([np.inf, -np.inf], np.nan,inplace=True)\n",
    "qt_train = []\n",
    "\n",
    "for col in colNames:\n",
    "    #print(col)\n",
    "    qt = QuantileTransformer(random_state=42,n_quantiles=1000, output_distribution='normal')\n",
    "    train[col] = qt.fit_transform(train[[col]])\n",
    "    test[col] = qt.transform(test[[col]])    \n",
    "    qt_train.append(qt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "textile-captain",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-26T10:58:14.205979Z",
     "iopub.status.busy": "2021-09-26T10:58:14.205304Z",
     "iopub.status.idle": "2021-09-26T10:58:14.208200Z",
     "shell.execute_reply": "2021-09-26T10:58:14.207661Z",
     "shell.execute_reply.started": "2021-09-24T09:21:39.343736Z"
    },
    "papermill": {
     "duration": 0.066127,
     "end_time": "2021-09-26T10:58:14.208336",
     "exception": false,
     "start_time": "2021-09-26T10:58:14.142209",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "small-royalty",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-26T10:58:14.338728Z",
     "iopub.status.busy": "2021-09-26T10:58:14.338080Z",
     "iopub.status.idle": "2021-09-26T10:58:17.226281Z",
     "shell.execute_reply": "2021-09-26T10:58:17.225613Z",
     "shell.execute_reply.started": "2021-09-24T09:21:39.639286Z"
    },
    "papermill": {
     "duration": 2.958588,
     "end_time": "2021-09-26T10:58:17.226435",
     "exception": false,
     "start_time": "2021-09-26T10:58:14.267847",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 4 3 1 3 0 1 3 5 1 0 4 3 3 3 3 3 1 3 3 6 0 0 3 6 3 0 3 6 3 6 3 3 0 4 6 3\n",
      " 6 3 3 3 0 3 3 0 4 3 3 3 4 0 6 6 6 1 4 1 3 0 3 3 0 3 0 0 6 4 0 6 4 5 2 6 4\n",
      " 4 3 4 0 6 4 4 3 0 0 4 4 6 6 3 4 0 3 3 3 3 6 0 6 6 0 0 3 0 0 3 3 0 0 3 4 3\n",
      " 4]\n",
      "[5, 10, 22, 23, 29, 36, 44, 48, 56, 66, 69, 72, 73, 76, 87, 94, 95, 102, 109, 112, 113, 115, 116, 120, 122]\n",
      "[3, 6, 9, 18, 61, 63]\n",
      "[81]\n",
      "[0, 2, 4, 7, 13, 14, 15, 16, 17, 19, 20, 26, 28, 30, 32, 34, 35, 39, 41, 42, 43, 46, 47, 51, 52, 53, 64, 67, 68, 70, 85, 93, 100, 103, 104, 105, 107, 114, 118, 119, 123, 125]\n",
      "[1, 11, 37, 50, 55, 62, 75, 78, 83, 84, 86, 89, 90, 96, 97, 101, 124, 126]\n",
      "[8, 80]\n",
      "[21, 27, 31, 33, 38, 40, 58, 59, 60, 74, 77, 82, 88, 98, 99, 108, 110, 111]\n"
     ]
    }
   ],
   "source": [
    "# making agg features\n",
    "\n",
    "train_p = pd.read_csv('../input/optiver-realized-volatility-prediction/train.csv')\n",
    "train_p = train_p.pivot(index='time_id', columns='stock_id', values='target')\n",
    "\n",
    "corr = train_p.corr()\n",
    "\n",
    "ids = corr.index\n",
    "\n",
    "kmeans = KMeans(n_clusters=7, random_state=0).fit(corr.values)\n",
    "print(kmeans.labels_)\n",
    "\n",
    "l = []\n",
    "for n in range(7):\n",
    "    l.append ( [ (x-1) for x in ( (ids+1)*(kmeans.labels_ == n)) if x > 0] )\n",
    "    \n",
    "\n",
    "mat = []\n",
    "matTest = []\n",
    "\n",
    "n = 0\n",
    "for ind in l:\n",
    "    print(ind)\n",
    "    newDf = train.loc[train['stock_id'].isin(ind) ]\n",
    "    newDf = newDf.groupby(['time_id']).agg(np.nanmean)\n",
    "    newDf.loc[:,'stock_id'] = str(n)+'c1'\n",
    "    mat.append ( newDf )\n",
    "    \n",
    "    newDf = test.loc[test['stock_id'].isin(ind) ]    \n",
    "    newDf = newDf.groupby(['time_id']).agg(np.nanmean)\n",
    "    newDf.loc[:,'stock_id'] = str(n)+'c1'\n",
    "    matTest.append ( newDf )\n",
    "    \n",
    "    n+=1\n",
    "    \n",
    "mat1 = pd.concat(mat).reset_index()\n",
    "mat1.drop(columns=['target'],inplace=True)\n",
    "\n",
    "mat2 = pd.concat(matTest).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "assigned-germany",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-26T10:58:17.354907Z",
     "iopub.status.busy": "2021-09-26T10:58:17.354127Z",
     "iopub.status.idle": "2021-09-26T10:58:17.357696Z",
     "shell.execute_reply": "2021-09-26T10:58:17.356986Z",
     "shell.execute_reply.started": "2021-09-24T09:21:42.792566Z"
    },
    "papermill": {
     "duration": 0.069249,
     "end_time": "2021-09-26T10:58:17.357862",
     "exception": false,
     "start_time": "2021-09-26T10:58:17.288613",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "matTest = []\n",
    "mat = []\n",
    "kmeans = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "white-version",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-26T10:58:17.488858Z",
     "iopub.status.busy": "2021-09-26T10:58:17.487870Z",
     "iopub.status.idle": "2021-09-26T10:58:17.533646Z",
     "shell.execute_reply": "2021-09-26T10:58:17.534166Z",
     "shell.execute_reply.started": "2021-09-24T09:21:42.79815Z"
    },
    "papermill": {
     "duration": 0.114988,
     "end_time": "2021-09-26T10:58:17.534374",
     "exception": false,
     "start_time": "2021-09-26T10:58:17.419386",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#mat2 #= mat1.pivot(index='time_id', columns='stock_idmat2\n",
    "mat2 = pd.concat([mat2,mat1.loc[mat1.time_id==5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "sixth-timing",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-26T10:58:17.659567Z",
     "iopub.status.busy": "2021-09-26T10:58:17.658884Z",
     "iopub.status.idle": "2021-09-26T10:58:18.034356Z",
     "shell.execute_reply": "2021-09-26T10:58:18.033751Z",
     "shell.execute_reply.started": "2021-09-24T09:21:42.862518Z"
    },
    "papermill": {
     "duration": 0.439436,
     "end_time": "2021-09-26T10:58:18.034512",
     "exception": false,
     "start_time": "2021-09-26T10:58:17.595076",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mat1 = mat1.pivot(index='time_id', columns='stock_id')\n",
    "mat1.columns = [\"_\".join(x) for x in mat1.columns.ravel()]\n",
    "mat1.reset_index(inplace=True)\n",
    "\n",
    "mat2 = mat2.pivot(index='time_id', columns='stock_id')\n",
    "mat2.columns = [\"_\".join(x) for x in mat2.columns.ravel()]\n",
    "mat2.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "lasting-departure",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-26T10:58:18.164386Z",
     "iopub.status.busy": "2021-09-26T10:58:18.163682Z",
     "iopub.status.idle": "2021-09-26T10:58:18.165651Z",
     "shell.execute_reply": "2021-09-26T10:58:18.166178Z",
     "shell.execute_reply.started": "2021-09-24T09:21:43.233724Z"
    },
    "papermill": {
     "duration": 0.07014,
     "end_time": "2021-09-26T10:58:18.166356",
     "exception": false,
     "start_time": "2021-09-26T10:58:18.096216",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nnn = ['time_id',\n",
    "     'log_return1_realized_volatility_0c1',\n",
    "     'log_return1_realized_volatility_1c1',     \n",
    "     'log_return1_realized_volatility_3c1',\n",
    "     'log_return1_realized_volatility_4c1',     \n",
    "     'log_return1_realized_volatility_6c1',\n",
    "     'total_volume_mean_0c1',\n",
    "     'total_volume_mean_1c1', \n",
    "     'total_volume_mean_3c1',\n",
    "     'total_volume_mean_4c1', \n",
    "     'total_volume_mean_6c1',\n",
    "     'trade_size_mean_0c1',\n",
    "     'trade_size_mean_1c1', \n",
    "     'trade_size_mean_3c1',\n",
    "     'trade_size_mean_4c1', \n",
    "     'trade_size_mean_6c1',\n",
    "     'trade_order_count_mean_0c1',\n",
    "     'trade_order_count_mean_1c1',\n",
    "     'trade_order_count_mean_3c1',\n",
    "     'trade_order_count_mean_4c1',\n",
    "     'trade_order_count_mean_6c1',      \n",
    "     'price_spread_mean_0c1',\n",
    "     'price_spread_mean_1c1',\n",
    "     'price_spread_mean_3c1',\n",
    "     'price_spread_mean_4c1',\n",
    "     'price_spread_mean_6c1',   \n",
    "     'bid_spread_mean_0c1',\n",
    "     'bid_spread_mean_1c1',\n",
    "     'bid_spread_mean_3c1',\n",
    "     'bid_spread_mean_4c1',\n",
    "     'bid_spread_mean_6c1',       \n",
    "     'ask_spread_mean_0c1',\n",
    "     'ask_spread_mean_1c1',\n",
    "     'ask_spread_mean_3c1',\n",
    "     'ask_spread_mean_4c1',\n",
    "     'ask_spread_mean_6c1',   \n",
    "     'volume_imbalance_mean_0c1',\n",
    "     'volume_imbalance_mean_1c1',\n",
    "     'volume_imbalance_mean_3c1',\n",
    "     'volume_imbalance_mean_4c1',\n",
    "     'volume_imbalance_mean_6c1',       \n",
    "     'bid_ask_spread_mean_0c1',\n",
    "     'bid_ask_spread_mean_1c1',\n",
    "     'bid_ask_spread_mean_3c1',\n",
    "     'bid_ask_spread_mean_4c1',\n",
    "     'bid_ask_spread_mean_6c1',\n",
    "     'size_tau2_0c1',\n",
    "     'size_tau2_1c1',\n",
    "     'size_tau2_3c1',\n",
    "     'size_tau2_4c1',\n",
    "     'size_tau2_6c1'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "abstract-bedroom",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-26T10:58:18.291192Z",
     "iopub.status.busy": "2021-09-26T10:58:18.290492Z",
     "iopub.status.idle": "2021-09-26T10:58:18.294444Z",
     "shell.execute_reply": "2021-09-26T10:58:18.293803Z",
     "shell.execute_reply.started": "2021-09-24T09:21:43.241912Z"
    },
    "papermill": {
     "duration": 0.067743,
     "end_time": "2021-09-26T10:58:18.294588",
     "exception": false,
     "start_time": "2021-09-26T10:58:18.226845",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import copy\n",
    "#trainCopy = copy.copy(train)\n",
    "#testCopy = copy.copy(test)\n",
    "\n",
    "#train = copy.copy(trainCopy)\n",
    "#test = copy.copy(trainCopy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "infrared-republic",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-26T10:58:18.423806Z",
     "iopub.status.busy": "2021-09-26T10:58:18.423163Z",
     "iopub.status.idle": "2021-09-26T10:58:56.190782Z",
     "shell.execute_reply": "2021-09-26T10:58:56.191287Z",
     "shell.execute_reply.started": "2021-09-24T09:21:43.261175Z"
    },
    "papermill": {
     "duration": 37.83582,
     "end_time": "2021-09-26T10:58:56.191495",
     "exception": false,
     "start_time": "2021-09-26T10:58:18.355675",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.merge(train,mat1[nnn],how='left',on='time_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "burning-interest",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-26T10:58:56.334868Z",
     "iopub.status.busy": "2021-09-26T10:58:56.334196Z",
     "iopub.status.idle": "2021-09-26T10:58:56.337632Z",
     "shell.execute_reply": "2021-09-26T10:58:56.337084Z",
     "shell.execute_reply.started": "2021-09-24T09:22:23.439202Z"
    },
    "papermill": {
     "duration": 0.085274,
     "end_time": "2021-09-26T10:58:56.337773",
     "exception": false,
     "start_time": "2021-09-26T10:58:56.252499",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = pd.merge(test,mat2[nnn],how='left',on='time_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "working-caribbean",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-26T10:58:56.463557Z",
     "iopub.status.busy": "2021-09-26T10:58:56.462920Z",
     "iopub.status.idle": "2021-09-26T10:58:56.466272Z",
     "shell.execute_reply": "2021-09-26T10:58:56.465677Z",
     "shell.execute_reply.started": "2021-09-24T09:22:23.46283Z"
    },
    "papermill": {
     "duration": 0.067691,
     "end_time": "2021-09-26T10:58:56.466407",
     "exception": false,
     "start_time": "2021-09-26T10:58:56.398716",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mat1= []\n",
    "mat2= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "italic-reviewer",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-26T10:58:56.594480Z",
     "iopub.status.busy": "2021-09-26T10:58:56.593503Z",
     "iopub.status.idle": "2021-09-26T10:58:56.621868Z",
     "shell.execute_reply": "2021-09-26T10:58:56.621348Z",
     "shell.execute_reply.started": "2021-09-24T09:22:23.474847Z"
    },
    "papermill": {
     "duration": 0.095162,
     "end_time": "2021-09-26T10:58:56.622001",
     "exception": false,
     "start_time": "2021-09-26T10:58:56.526839",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_id</th>\n",
       "      <th>time_id</th>\n",
       "      <th>row_id</th>\n",
       "      <th>calc_depth_sum</th>\n",
       "      <th>calc_depth_mean</th>\n",
       "      <th>calc_depth_std</th>\n",
       "      <th>calc_slope1_sum</th>\n",
       "      <th>calc_slope1_mean</th>\n",
       "      <th>calc_slope1_std</th>\n",
       "      <th>calc_slope2_sum</th>\n",
       "      <th>...</th>\n",
       "      <th>bid_ask_spread_mean_0c1</th>\n",
       "      <th>bid_ask_spread_mean_1c1</th>\n",
       "      <th>bid_ask_spread_mean_3c1</th>\n",
       "      <th>bid_ask_spread_mean_4c1</th>\n",
       "      <th>bid_ask_spread_mean_6c1</th>\n",
       "      <th>size_tau2_0c1</th>\n",
       "      <th>size_tau2_1c1</th>\n",
       "      <th>size_tau2_3c1</th>\n",
       "      <th>size_tau2_4c1</th>\n",
       "      <th>size_tau2_6c1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0-4</td>\n",
       "      <td>-5.199338</td>\n",
       "      <td>-0.864069</td>\n",
       "      <td>-2.941674</td>\n",
       "      <td>-2.786773</td>\n",
       "      <td>-3.095377</td>\n",
       "      <td>-2.243477</td>\n",
       "      <td>-3.830389</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.816375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.107081</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0-32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>0-34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 462 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   stock_id  time_id row_id  calc_depth_sum  calc_depth_mean  calc_depth_std  \\\n",
       "0         0        4    0-4       -5.199338        -0.864069       -2.941674   \n",
       "1         0       32   0-32             NaN              NaN             NaN   \n",
       "2         0       34   0-34             NaN              NaN             NaN   \n",
       "\n",
       "   calc_slope1_sum  calc_slope1_mean  calc_slope1_std  calc_slope2_sum  ...  \\\n",
       "0        -2.786773         -3.095377        -2.243477        -3.830389  ...   \n",
       "1              NaN               NaN              NaN              NaN  ...   \n",
       "2              NaN               NaN              NaN              NaN  ...   \n",
       "\n",
       "   bid_ask_spread_mean_0c1  bid_ask_spread_mean_1c1  bid_ask_spread_mean_3c1  \\\n",
       "0                      NaN                      NaN                 0.816375   \n",
       "1                      NaN                      NaN                      NaN   \n",
       "2                      NaN                      NaN                      NaN   \n",
       "\n",
       "   bid_ask_spread_mean_4c1  bid_ask_spread_mean_6c1  size_tau2_0c1  \\\n",
       "0                      NaN                      NaN            NaN   \n",
       "1                      NaN                      NaN            NaN   \n",
       "2                      NaN                      NaN            NaN   \n",
       "\n",
       "   size_tau2_1c1  size_tau2_3c1  size_tau2_4c1  size_tau2_6c1  \n",
       "0            NaN       3.107081            NaN            NaN  \n",
       "1            NaN            NaN            NaN            NaN  \n",
       "2            NaN            NaN            NaN            NaN  \n",
       "\n",
       "[3 rows x 462 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "negative-checkout",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-26T10:58:56.750738Z",
     "iopub.status.busy": "2021-09-26T10:58:56.750030Z",
     "iopub.status.idle": "2021-09-26T10:58:56.766957Z",
     "shell.execute_reply": "2021-09-26T10:58:56.766430Z",
     "shell.execute_reply.started": "2021-09-24T09:22:23.515408Z"
    },
    "papermill": {
     "duration": 0.083931,
     "end_time": "2021-09-26T10:58:56.767121",
     "exception": false,
     "start_time": "2021-09-26T10:58:56.683190",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#https://bignerdranch.com/blog/implementing-swish-activation-function-in-keras/\n",
    "from keras.backend import sigmoid\n",
    "def swish(x, beta = 1):\n",
    "    return (x * sigmoid(beta * x))\n",
    "\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras.layers import Activation\n",
    "get_custom_objects().update({'swish': Activation(swish)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "retired-saver",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-26T10:58:56.900119Z",
     "iopub.status.busy": "2021-09-26T10:58:56.899436Z",
     "iopub.status.idle": "2021-09-26T10:58:56.904190Z",
     "shell.execute_reply": "2021-09-26T10:58:56.903657Z",
     "shell.execute_reply.started": "2021-09-24T09:23:36.214551Z"
    },
    "papermill": {
     "duration": 0.075911,
     "end_time": "2021-09-26T10:58:56.904325",
     "exception": false,
     "start_time": "2021-09-26T10:58:56.828414",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "hidden_units = (128,64,32)\n",
    "stock_embedding_size = 24\n",
    "\n",
    "cat_data = train['stock_id']\n",
    "\n",
    "def base_model():\n",
    "    \n",
    "    # Each instance will consist of two inputs: a single user id, and a single movie id\n",
    "    stock_id_input = keras.Input(shape=(1,), name='stock_id')\n",
    "    num_input = keras.Input(shape=(len(colNames) + len(nnn) - 1,), name='num_data')\n",
    "\n",
    "\n",
    "    #embedding, flatenning and concatenating\n",
    "    stock_embedded = keras.layers.Embedding(max(cat_data)+1, stock_embedding_size, \n",
    "                                           input_length=1, name='stock_embedding')(stock_id_input)\n",
    "    stock_flattened = keras.layers.Flatten()(stock_embedded)\n",
    "    out = keras.layers.Concatenate()([stock_flattened, num_input])\n",
    "    \n",
    "    # Add one or more hidden layers\n",
    "    for n_hidden in hidden_units:\n",
    "\n",
    "        out = keras.layers.Dense(n_hidden, activation='swish')(out)\n",
    "        #out = keras.layers.Dropout(0.2)(out)\n",
    "        out = keras.layers.Dense(n_hidden, activation='relu')(out)\n",
    "        #out = keras.layers.Dropout(0.2)(out)\n",
    "        #out = keras.layers.Dense(n_hidden, activation='linear')(out)\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "    #out = keras.layers.Concatenate()([out, num_input])\n",
    "\n",
    "    # A single output: our predicted rating\n",
    "    out = keras.layers.Dense(1, activation='linear', name='prediction')(out)\n",
    "    \n",
    "    \n",
    "    model = keras.Model(\n",
    "    inputs = [stock_id_input, num_input],\n",
    "    outputs = out,\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "shared-trustee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-26T10:58:57.050412Z",
     "iopub.status.busy": "2021-09-26T10:58:57.049673Z",
     "iopub.status.idle": "2021-09-26T11:21:00.323001Z",
     "shell.execute_reply": "2021-09-26T11:21:00.322295Z",
     "shell.execute_reply.started": "2021-09-24T09:23:39.277303Z"
    },
    "papermill": {
     "duration": 1323.357494,
     "end_time": "2021-09-26T11:21:00.323174",
     "exception": false,
     "start_time": "2021-09-26T10:58:56.965680",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV 1/5\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "stock_id (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "stock_embedding (Embedding)     (None, 1, 24)        3048        stock_id[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 24)           0           stock_embedding[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "num_data (InputLayer)           [(None, 459)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 483)          0           flatten[0][0]                    \n",
      "                                                                 num_data[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          61952       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          16512       dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 64)           8256        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 64)           4160        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 32)           2080        dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 32)           1056        dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Dense)              (None, 1)            33          dense_5[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 97,097\n",
      "Trainable params: 97,097\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/1000\n",
      "336/336 [==============================] - 6s 16ms/step - loss: 1.8875 - val_loss: 0.4247\n",
      "Epoch 2/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.3161 - val_loss: 0.2433\n",
      "Epoch 3/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2756 - val_loss: 0.3021\n",
      "Epoch 4/1000\n",
      "336/336 [==============================] - 5s 14ms/step - loss: 0.2580 - val_loss: 0.2347\n",
      "Epoch 5/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2459 - val_loss: 0.2548\n",
      "Epoch 6/1000\n",
      "336/336 [==============================] - 5s 14ms/step - loss: 0.2644 - val_loss: 0.2316\n",
      "Epoch 7/1000\n",
      "336/336 [==============================] - 5s 14ms/step - loss: 0.2311 - val_loss: 0.2752\n",
      "Epoch 8/1000\n",
      "336/336 [==============================] - 5s 14ms/step - loss: 0.2271 - val_loss: 0.3539\n",
      "Epoch 9/1000\n",
      "336/336 [==============================] - 5s 13ms/step - loss: 0.2638 - val_loss: 0.2209\n",
      "Epoch 10/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2341 - val_loss: 0.2441\n",
      "Epoch 11/1000\n",
      "336/336 [==============================] - 5s 14ms/step - loss: 0.2228 - val_loss: 0.2116\n",
      "Epoch 12/1000\n",
      "336/336 [==============================] - 5s 13ms/step - loss: 0.2160 - val_loss: 0.2320\n",
      "Epoch 13/1000\n",
      "336/336 [==============================] - 5s 14ms/step - loss: 0.2186 - val_loss: 0.3175\n",
      "Epoch 14/1000\n",
      "336/336 [==============================] - 5s 14ms/step - loss: 0.2286 - val_loss: 0.2122\n",
      "Epoch 15/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2140 - val_loss: 0.2704\n",
      "Epoch 16/1000\n",
      "336/336 [==============================] - 5s 13ms/step - loss: 0.2270 - val_loss: 0.2106\n",
      "Epoch 17/1000\n",
      "336/336 [==============================] - 5s 14ms/step - loss: 0.2146 - val_loss: 0.2149\n",
      "Epoch 18/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2105 - val_loss: 0.2187\n",
      "Epoch 19/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2108 - val_loss: 0.2202\n",
      "Epoch 20/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2131 - val_loss: 0.2248\n",
      "Epoch 21/1000\n",
      "336/336 [==============================] - 5s 14ms/step - loss: 0.2221 - val_loss: 0.2206\n",
      "Epoch 22/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2114 - val_loss: 0.2101\n",
      "Epoch 23/1000\n",
      "336/336 [==============================] - 5s 14ms/step - loss: 0.2059 - val_loss: 0.2550\n",
      "Epoch 24/1000\n",
      "336/336 [==============================] - 5s 14ms/step - loss: 0.2455 - val_loss: 0.2280\n",
      "Epoch 25/1000\n",
      "336/336 [==============================] - 5s 14ms/step - loss: 0.2617 - val_loss: 0.2524\n",
      "Epoch 26/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2236 - val_loss: 0.2172\n",
      "Epoch 27/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2145 - val_loss: 0.2142\n",
      "Epoch 28/1000\n",
      "336/336 [==============================] - 5s 14ms/step - loss: 0.2114 - val_loss: 0.2199\n",
      "Epoch 29/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2193 - val_loss: 0.2395\n",
      "Epoch 30/1000\n",
      "336/336 [==============================] - 5s 13ms/step - loss: 0.2050 - val_loss: 0.2092\n",
      "Epoch 31/1000\n",
      "336/336 [==============================] - 5s 14ms/step - loss: 0.2008 - val_loss: 0.2102\n",
      "Epoch 32/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.1994 - val_loss: 0.2099\n",
      "Epoch 33/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.1988 - val_loss: 0.2119\n",
      "Epoch 34/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.1973 - val_loss: 0.2177\n",
      "Epoch 35/1000\n",
      "336/336 [==============================] - 5s 14ms/step - loss: 0.1966 - val_loss: 0.2269\n",
      "Epoch 36/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.1997 - val_loss: 0.2124\n",
      "Epoch 37/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.1962 - val_loss: 0.2110\n",
      "Epoch 38/1000\n",
      "336/336 [==============================] - 5s 14ms/step - loss: 0.1939 - val_loss: 0.2097\n",
      "Epoch 39/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.1937 - val_loss: 0.2101\n",
      "Epoch 40/1000\n",
      "336/336 [==============================] - 5s 13ms/step - loss: 0.1934 - val_loss: 0.2097\n",
      "Epoch 41/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.1938 - val_loss: 0.2098\n",
      "Epoch 42/1000\n",
      "336/336 [==============================] - 5s 14ms/step - loss: 0.1935 - val_loss: 0.2097\n",
      "Epoch 43/1000\n",
      "336/336 [==============================] - 5s 14ms/step - loss: 0.1938 - val_loss: 0.2102\n",
      "Epoch 44/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.1938 - val_loss: 0.2097\n",
      "Epoch 45/1000\n",
      "336/336 [==============================] - 5s 14ms/step - loss: 0.1937 - val_loss: 0.2097\n",
      "Epoch 46/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.1939 - val_loss: 0.2097\n",
      "Epoch 47/1000\n",
      "336/336 [==============================] - 5s 13ms/step - loss: 0.1933 - val_loss: 0.2097\n",
      "Epoch 48/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.1929 - val_loss: 0.2097\n",
      "Epoch 49/1000\n",
      "336/336 [==============================] - 5s 14ms/step - loss: 0.1931 - val_loss: 0.2098\n",
      "Epoch 50/1000\n",
      "336/336 [==============================] - 5s 13ms/step - loss: 0.1932 - val_loss: 0.2098\n",
      "Fold 1 NN: 0.20923\n",
      "CV 2/5\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "stock_id (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "stock_embedding (Embedding)     (None, 1, 24)        3048        stock_id[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 24)           0           stock_embedding[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "num_data (InputLayer)           [(None, 459)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 483)          0           flatten_1[0][0]                  \n",
      "                                                                 num_data[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 128)          61952       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 128)          16512       dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 64)           8256        dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 64)           4160        dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 32)           2080        dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 32)           1056        dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Dense)              (None, 1)            33          dense_11[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 97,097\n",
      "Trainable params: 97,097\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/1000\n",
      "336/336 [==============================] - 6s 15ms/step - loss: 1.9984 - val_loss: 0.2623\n",
      "Epoch 2/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2967 - val_loss: 0.2361\n",
      "Epoch 3/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2382 - val_loss: 0.2322\n",
      "Epoch 4/1000\n",
      "336/336 [==============================] - 5s 14ms/step - loss: 0.2531 - val_loss: 0.2395\n",
      "Epoch 5/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2408 - val_loss: 0.2263\n",
      "Epoch 6/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2286 - val_loss: 0.2259\n",
      "Epoch 7/1000\n",
      "336/336 [==============================] - 5s 14ms/step - loss: 0.2226 - val_loss: 0.2679\n",
      "Epoch 8/1000\n",
      "336/336 [==============================] - 5s 14ms/step - loss: 0.2231 - val_loss: 0.2475\n",
      "Epoch 9/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2197 - val_loss: 0.2262\n",
      "Epoch 10/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2200 - val_loss: 0.2297\n",
      "Epoch 11/1000\n",
      "336/336 [==============================] - 5s 14ms/step - loss: 0.2335 - val_loss: 0.2673\n",
      "Epoch 12/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2308 - val_loss: 0.2319\n",
      "Epoch 13/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2265 - val_loss: 0.2214\n",
      "Epoch 14/1000\n",
      "336/336 [==============================] - 5s 13ms/step - loss: 0.2103 - val_loss: 0.2185\n",
      "Epoch 15/1000\n",
      "336/336 [==============================] - 5s 15ms/step - loss: 0.2113 - val_loss: 0.2204\n",
      "Epoch 16/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2128 - val_loss: 0.2425\n",
      "Epoch 17/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2173 - val_loss: 0.2406\n",
      "Epoch 18/1000\n",
      "336/336 [==============================] - 5s 14ms/step - loss: 0.2286 - val_loss: 0.2623\n",
      "Epoch 19/1000\n",
      "336/336 [==============================] - 5s 14ms/step - loss: 0.2423 - val_loss: 0.2230\n",
      "Epoch 20/1000\n",
      "336/336 [==============================] - 5s 13ms/step - loss: 0.2247 - val_loss: 0.3140\n",
      "Epoch 21/1000\n",
      "336/336 [==============================] - 5s 14ms/step - loss: 0.2520 - val_loss: 0.2411\n",
      "Epoch 22/1000\n",
      "336/336 [==============================] - 5s 15ms/step - loss: 0.2193 - val_loss: 0.2230\n",
      "Epoch 23/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2132 - val_loss: 0.2194\n",
      "Epoch 24/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2109 - val_loss: 0.2175\n",
      "Epoch 25/1000\n",
      "336/336 [==============================] - 5s 14ms/step - loss: 0.2098 - val_loss: 0.2175\n",
      "Epoch 26/1000\n",
      "336/336 [==============================] - 5s 14ms/step - loss: 0.2096 - val_loss: 0.2156\n",
      "Epoch 27/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2088 - val_loss: 0.2170\n",
      "Epoch 28/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2076 - val_loss: 0.2154\n",
      "Epoch 29/1000\n",
      "336/336 [==============================] - 5s 15ms/step - loss: 0.2070 - val_loss: 0.2146\n",
      "Epoch 30/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2066 - val_loss: 0.2183\n",
      "Epoch 31/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2067 - val_loss: 0.2187\n",
      "Epoch 32/1000\n",
      "336/336 [==============================] - 5s 14ms/step - loss: 0.2063 - val_loss: 0.2172\n",
      "Epoch 33/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2066 - val_loss: 0.2169\n",
      "Epoch 34/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2052 - val_loss: 0.2209\n",
      "Epoch 35/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2047 - val_loss: 0.2142\n",
      "Epoch 36/1000\n",
      "336/336 [==============================] - 5s 15ms/step - loss: 0.2042 - val_loss: 0.2260\n",
      "Epoch 37/1000\n",
      "336/336 [==============================] - 5s 14ms/step - loss: 0.2044 - val_loss: 0.2133\n",
      "Epoch 38/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2034 - val_loss: 0.2204\n",
      "Epoch 39/1000\n",
      "336/336 [==============================] - 5s 14ms/step - loss: 0.2036 - val_loss: 0.2154\n",
      "Epoch 40/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2028 - val_loss: 0.2139\n",
      "Epoch 41/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2027 - val_loss: 0.2161\n",
      "Epoch 42/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2020 - val_loss: 0.2140\n",
      "Epoch 43/1000\n",
      "336/336 [==============================] - 5s 14ms/step - loss: 0.2011 - val_loss: 0.2140\n",
      "Epoch 44/1000\n",
      "336/336 [==============================] - 5s 15ms/step - loss: 0.2007 - val_loss: 0.2161\n",
      "Epoch 45/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.1992 - val_loss: 0.2125\n",
      "Epoch 46/1000\n",
      "336/336 [==============================] - 5s 14ms/step - loss: 0.1990 - val_loss: 0.2126\n",
      "Epoch 47/1000\n",
      "336/336 [==============================] - 5s 13ms/step - loss: 0.1982 - val_loss: 0.2123\n",
      "Epoch 48/1000\n",
      "336/336 [==============================] - 5s 14ms/step - loss: 0.1986 - val_loss: 0.2130\n",
      "Epoch 49/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.1986 - val_loss: 0.2133\n",
      "Epoch 50/1000\n",
      "336/336 [==============================] - 5s 13ms/step - loss: 0.1982 - val_loss: 0.2129\n",
      "Epoch 51/1000\n",
      "336/336 [==============================] - 5s 15ms/step - loss: 0.1985 - val_loss: 0.2126\n",
      "Epoch 52/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.1985 - val_loss: 0.2131\n",
      "Epoch 53/1000\n",
      "336/336 [==============================] - 5s 14ms/step - loss: 0.1979 - val_loss: 0.2138\n",
      "Epoch 54/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.1992 - val_loss: 0.2128\n",
      "Epoch 55/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.1980 - val_loss: 0.2128\n",
      "Epoch 56/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.1974 - val_loss: 0.2128\n",
      "Epoch 57/1000\n",
      "336/336 [==============================] - 5s 13ms/step - loss: 0.1985 - val_loss: 0.2133\n",
      "Epoch 58/1000\n",
      "336/336 [==============================] - 5s 15ms/step - loss: 0.1982 - val_loss: 0.2131\n",
      "Epoch 59/1000\n",
      "336/336 [==============================] - 5s 14ms/step - loss: 0.1980 - val_loss: 0.2131\n",
      "Epoch 60/1000\n",
      "336/336 [==============================] - 5s 14ms/step - loss: 0.1980 - val_loss: 0.2129\n",
      "Epoch 61/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.1979 - val_loss: 0.2132\n",
      "Epoch 62/1000\n",
      "336/336 [==============================] - 5s 13ms/step - loss: 0.1976 - val_loss: 0.2131\n",
      "Epoch 63/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.1979 - val_loss: 0.2131\n",
      "Epoch 64/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.1975 - val_loss: 0.2131\n",
      "Epoch 65/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.1981 - val_loss: 0.2131\n",
      "Epoch 66/1000\n",
      "336/336 [==============================] - 5s 15ms/step - loss: 0.1986 - val_loss: 0.2131\n",
      "Epoch 67/1000\n",
      "336/336 [==============================] - 5s 14ms/step - loss: 0.1977 - val_loss: 0.2130\n",
      "Fold 2 NN: 0.21225\n",
      "CV 3/5\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "stock_id (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "stock_embedding (Embedding)     (None, 1, 24)        3048        stock_id[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 24)           0           stock_embedding[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "num_data (InputLayer)           [(None, 459)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 483)          0           flatten_2[0][0]                  \n",
      "                                                                 num_data[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 128)          61952       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 128)          16512       dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 64)           8256        dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 64)           4160        dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 32)           2080        dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 32)           1056        dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Dense)              (None, 1)            33          dense_17[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 97,097\n",
      "Trainable params: 97,097\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/1000\n",
      "336/336 [==============================] - 6s 14ms/step - loss: 3.6788 - val_loss: 0.2789\n",
      "Epoch 2/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.3393 - val_loss: 0.2489\n",
      "Epoch 3/1000\n",
      "336/336 [==============================] - 5s 14ms/step - loss: 0.2461 - val_loss: 0.2229\n",
      "Epoch 4/1000\n",
      "336/336 [==============================] - 5s 16ms/step - loss: 0.2777 - val_loss: 0.2545\n",
      "Epoch 5/1000\n",
      "336/336 [==============================] - 5s 14ms/step - loss: 0.2353 - val_loss: 0.2167\n",
      "Epoch 6/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2454 - val_loss: 0.2197\n",
      "Epoch 7/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2349 - val_loss: 0.2368\n",
      "Epoch 8/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2359 - val_loss: 0.2605\n",
      "Epoch 9/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2313 - val_loss: 0.2375\n",
      "Epoch 10/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2326 - val_loss: 0.2117\n",
      "Epoch 11/1000\n",
      "336/336 [==============================] - 5s 14ms/step - loss: 0.2193 - val_loss: 0.2606\n",
      "Epoch 12/1000\n",
      "336/336 [==============================] - 5s 16ms/step - loss: 0.2182 - val_loss: 0.2123\n",
      "Epoch 13/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2153 - val_loss: 0.2171\n",
      "Epoch 14/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2128 - val_loss: 0.2144\n",
      "Epoch 15/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2182 - val_loss: 0.2145\n",
      "Epoch 16/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2206 - val_loss: 0.2290\n",
      "Epoch 17/1000\n",
      "336/336 [==============================] - 5s 13ms/step - loss: 0.2451 - val_loss: 0.2184\n",
      "Epoch 18/1000\n",
      "336/336 [==============================] - 5s 13ms/step - loss: 0.2060 - val_loss: 0.2074\n",
      "Epoch 19/1000\n",
      "336/336 [==============================] - 5s 15ms/step - loss: 0.2034 - val_loss: 0.2078\n",
      "Epoch 20/1000\n",
      "336/336 [==============================] - 5s 15ms/step - loss: 0.2026 - val_loss: 0.2069\n",
      "Epoch 21/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2024 - val_loss: 0.2071\n",
      "Epoch 22/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2018 - val_loss: 0.2067\n",
      "Epoch 23/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2017 - val_loss: 0.2085\n",
      "Epoch 24/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2020 - val_loss: 0.2072\n",
      "Epoch 25/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2012 - val_loss: 0.2071\n",
      "Epoch 26/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2006 - val_loss: 0.2065\n",
      "Epoch 27/1000\n",
      "336/336 [==============================] - 6s 17ms/step - loss: 0.2005 - val_loss: 0.2076\n",
      "Epoch 28/1000\n",
      "336/336 [==============================] - 5s 13ms/step - loss: 0.2005 - val_loss: 0.2072\n",
      "Epoch 29/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.1996 - val_loss: 0.2218\n",
      "Epoch 30/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2005 - val_loss: 0.2082\n",
      "Epoch 31/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.1987 - val_loss: 0.2089\n",
      "Epoch 32/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.1989 - val_loss: 0.2118\n",
      "Epoch 33/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.1985 - val_loss: 0.2078\n",
      "Epoch 34/1000\n",
      "336/336 [==============================] - 5s 15ms/step - loss: 0.1960 - val_loss: 0.2080\n",
      "Epoch 35/1000\n",
      "336/336 [==============================] - 5s 15ms/step - loss: 0.1955 - val_loss: 0.2080\n",
      "Epoch 36/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.1947 - val_loss: 0.2080\n",
      "Epoch 37/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.1947 - val_loss: 0.2091\n",
      "Epoch 38/1000\n",
      "336/336 [==============================] - 5s 14ms/step - loss: 0.1946 - val_loss: 0.2080\n",
      "Epoch 39/1000\n",
      "336/336 [==============================] - 5s 13ms/step - loss: 0.1944 - val_loss: 0.2082\n",
      "Epoch 40/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.1948 - val_loss: 0.2083\n",
      "Epoch 41/1000\n",
      "336/336 [==============================] - 5s 14ms/step - loss: 0.1943 - val_loss: 0.2085\n",
      "Epoch 42/1000\n",
      "336/336 [==============================] - 5s 14ms/step - loss: 0.1951 - val_loss: 0.2083\n",
      "Epoch 43/1000\n",
      "336/336 [==============================] - 5s 15ms/step - loss: 0.1945 - val_loss: 0.2084\n",
      "Epoch 44/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.1940 - val_loss: 0.2083\n",
      "Epoch 45/1000\n",
      "336/336 [==============================] - 5s 13ms/step - loss: 0.1943 - val_loss: 0.2084\n",
      "Epoch 46/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.1943 - val_loss: 0.2083\n",
      "Fold 3 NN: 0.20651\n",
      "CV 4/5\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "stock_id (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "stock_embedding (Embedding)     (None, 1, 24)        3048        stock_id[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 24)           0           stock_embedding[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "num_data (InputLayer)           [(None, 459)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 483)          0           flatten_3[0][0]                  \n",
      "                                                                 num_data[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 128)          61952       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 128)          16512       dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 64)           8256        dense_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 64)           4160        dense_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 32)           2080        dense_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 32)           1056        dense_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Dense)              (None, 1)            33          dense_23[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 97,097\n",
      "Trainable params: 97,097\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/1000\n",
      "336/336 [==============================] - 6s 15ms/step - loss: 2.8529 - val_loss: 0.3657\n",
      "Epoch 2/1000\n",
      "336/336 [==============================] - 5s 16ms/step - loss: 0.4095 - val_loss: 0.2422\n",
      "Epoch 3/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2604 - val_loss: 0.2538\n",
      "Epoch 4/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2713 - val_loss: 0.2670\n",
      "Epoch 5/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2557 - val_loss: 0.2471\n",
      "Epoch 6/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2483 - val_loss: 0.2278\n",
      "Epoch 7/1000\n",
      "336/336 [==============================] - 5s 14ms/step - loss: 0.2619 - val_loss: 0.4256\n",
      "Epoch 8/1000\n",
      "336/336 [==============================] - 5s 13ms/step - loss: 0.2985 - val_loss: 0.2264\n",
      "Epoch 9/1000\n",
      "336/336 [==============================] - 5s 15ms/step - loss: 0.2306 - val_loss: 0.3164\n",
      "Epoch 10/1000\n",
      "336/336 [==============================] - 5s 15ms/step - loss: 0.2601 - val_loss: 0.2277\n",
      "Epoch 11/1000\n",
      "336/336 [==============================] - 6s 17ms/step - loss: 0.2401 - val_loss: 0.2836\n",
      "Epoch 12/1000\n",
      "336/336 [==============================] - 5s 14ms/step - loss: 0.2376 - val_loss: 0.2288\n",
      "Epoch 13/1000\n",
      "336/336 [==============================] - 5s 14ms/step - loss: 0.2403 - val_loss: 0.2403\n",
      "Epoch 14/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2281 - val_loss: 0.2216\n",
      "Epoch 15/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2369 - val_loss: 0.2907\n",
      "Epoch 16/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2263 - val_loss: 0.2226\n",
      "Epoch 17/1000\n",
      "336/336 [==============================] - 5s 16ms/step - loss: 0.2279 - val_loss: 0.2393\n",
      "Epoch 18/1000\n",
      "336/336 [==============================] - 5s 14ms/step - loss: 0.2293 - val_loss: 0.3365\n",
      "Epoch 19/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2444 - val_loss: 0.2221\n",
      "Epoch 20/1000\n",
      "336/336 [==============================] - 5s 14ms/step - loss: 0.2154 - val_loss: 0.2387\n",
      "Epoch 21/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2142 - val_loss: 0.2184\n",
      "Epoch 22/1000\n",
      "336/336 [==============================] - 5s 14ms/step - loss: 0.2165 - val_loss: 1.0437\n",
      "Epoch 23/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.4069 - val_loss: 0.2787\n",
      "Epoch 24/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2399 - val_loss: 0.2209\n",
      "Epoch 25/1000\n",
      "336/336 [==============================] - 5s 16ms/step - loss: 0.2150 - val_loss: 0.2487\n",
      "Epoch 26/1000\n",
      "336/336 [==============================] - 5s 14ms/step - loss: 0.2183 - val_loss: 0.2168\n",
      "Epoch 27/1000\n",
      "336/336 [==============================] - 5s 14ms/step - loss: 0.2172 - val_loss: 0.2194\n",
      "Epoch 28/1000\n",
      "336/336 [==============================] - 5s 14ms/step - loss: 0.2132 - val_loss: 0.2556\n",
      "Epoch 29/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2136 - val_loss: 0.2494\n",
      "Epoch 30/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2207 - val_loss: 0.2175\n",
      "Epoch 31/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2101 - val_loss: 0.2929\n",
      "Epoch 32/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2503 - val_loss: 0.2140\n",
      "Epoch 33/1000\n",
      "336/336 [==============================] - 5s 16ms/step - loss: 0.2044 - val_loss: 0.2227\n",
      "Epoch 34/1000\n",
      "336/336 [==============================] - 5s 15ms/step - loss: 0.2164 - val_loss: 0.2199\n",
      "Epoch 35/1000\n",
      "336/336 [==============================] - 5s 14ms/step - loss: 0.2129 - val_loss: 0.2379\n",
      "Epoch 36/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2054 - val_loss: 0.2158\n",
      "Epoch 37/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2040 - val_loss: 0.2167\n",
      "Epoch 38/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2065 - val_loss: 0.3814\n",
      "Epoch 39/1000\n",
      "336/336 [==============================] - 5s 14ms/step - loss: 0.2474 - val_loss: 0.2196\n",
      "Epoch 40/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.1922 - val_loss: 0.2159\n",
      "Epoch 41/1000\n",
      "336/336 [==============================] - 5s 13ms/step - loss: 0.1903 - val_loss: 0.2165\n",
      "Epoch 42/1000\n",
      "336/336 [==============================] - 5s 14ms/step - loss: 0.1894 - val_loss: 0.2176\n",
      "Epoch 43/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.1894 - val_loss: 0.2181\n",
      "Epoch 44/1000\n",
      "336/336 [==============================] - 5s 13ms/step - loss: 0.1885 - val_loss: 0.2209\n",
      "Epoch 45/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.1886 - val_loss: 0.2210\n",
      "Epoch 46/1000\n",
      "336/336 [==============================] - 5s 13ms/step - loss: 0.1888 - val_loss: 0.2196\n",
      "Epoch 47/1000\n",
      "336/336 [==============================] - 5s 14ms/step - loss: 0.1870 - val_loss: 0.2182\n",
      "Epoch 48/1000\n",
      "336/336 [==============================] - 5s 16ms/step - loss: 0.1869 - val_loss: 0.2183\n",
      "Epoch 49/1000\n",
      "336/336 [==============================] - 5s 15ms/step - loss: 0.1865 - val_loss: 0.2184\n",
      "Epoch 50/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.1867 - val_loss: 0.2180\n",
      "Epoch 51/1000\n",
      "336/336 [==============================] - 5s 14ms/step - loss: 0.1862 - val_loss: 0.2181\n",
      "Epoch 52/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.1865 - val_loss: 0.2183\n",
      "Fold 4 NN: 0.21403\n",
      "CV 5/5\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "stock_id (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "stock_embedding (Embedding)     (None, 1, 24)        3048        stock_id[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 24)           0           stock_embedding[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "num_data (InputLayer)           [(None, 459)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 483)          0           flatten_4[0][0]                  \n",
      "                                                                 num_data[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 128)          61952       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 128)          16512       dense_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, 64)           8256        dense_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_27 (Dense)                (None, 64)           4160        dense_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_28 (Dense)                (None, 32)           2080        dense_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_29 (Dense)                (None, 32)           1056        dense_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Dense)              (None, 1)            33          dense_29[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 97,097\n",
      "Trainable params: 97,097\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/1000\n",
      "336/336 [==============================] - 5s 14ms/step - loss: 2.9868 - val_loss: 0.2905\n",
      "Epoch 2/1000\n",
      "336/336 [==============================] - 5s 14ms/step - loss: 0.3194 - val_loss: 0.2459\n",
      "Epoch 3/1000\n",
      "336/336 [==============================] - 5s 13ms/step - loss: 0.2931 - val_loss: 0.4861\n",
      "Epoch 4/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.3536 - val_loss: 0.5961\n",
      "Epoch 5/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.3384 - val_loss: 0.2458\n",
      "Epoch 6/1000\n",
      "336/336 [==============================] - 5s 13ms/step - loss: 0.3941 - val_loss: 0.2588\n",
      "Epoch 7/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2395 - val_loss: 0.2233\n",
      "Epoch 8/1000\n",
      "336/336 [==============================] - 5s 16ms/step - loss: 0.2327 - val_loss: 0.2232\n",
      "Epoch 9/1000\n",
      "336/336 [==============================] - 5s 16ms/step - loss: 0.2206 - val_loss: 0.2193\n",
      "Epoch 10/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2151 - val_loss: 0.2396\n",
      "Epoch 11/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2246 - val_loss: 0.2414\n",
      "Epoch 12/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2217 - val_loss: 0.2250\n",
      "Epoch 13/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2138 - val_loss: 0.2273\n",
      "Epoch 14/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2144 - val_loss: 0.2239\n",
      "Epoch 15/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2461 - val_loss: 0.2979\n",
      "Epoch 16/1000\n",
      "336/336 [==============================] - 5s 14ms/step - loss: 0.2250 - val_loss: 0.3133\n",
      "Epoch 17/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2140 - val_loss: 0.2142\n",
      "Epoch 18/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2060 - val_loss: 0.2147\n",
      "Epoch 19/1000\n",
      "336/336 [==============================] - 5s 14ms/step - loss: 0.2048 - val_loss: 0.2138\n",
      "Epoch 20/1000\n",
      "336/336 [==============================] - 5s 14ms/step - loss: 0.2048 - val_loss: 0.2136\n",
      "Epoch 21/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2040 - val_loss: 0.2132\n",
      "Epoch 22/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2043 - val_loss: 0.2144\n",
      "Epoch 23/1000\n",
      "336/336 [==============================] - 6s 17ms/step - loss: 0.2035 - val_loss: 0.2162\n",
      "Epoch 24/1000\n",
      "336/336 [==============================] - 5s 15ms/step - loss: 0.2034 - val_loss: 0.2137\n",
      "Epoch 25/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2036 - val_loss: 0.2143\n",
      "Epoch 26/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2031 - val_loss: 0.2130\n",
      "Epoch 27/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2032 - val_loss: 0.2132\n",
      "Epoch 28/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2030 - val_loss: 0.2146\n",
      "Epoch 29/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2019 - val_loss: 0.2141\n",
      "Epoch 30/1000\n",
      "336/336 [==============================] - 5s 14ms/step - loss: 0.2013 - val_loss: 0.2143\n",
      "Epoch 31/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2011 - val_loss: 0.2125\n",
      "Epoch 32/1000\n",
      "336/336 [==============================] - 5s 13ms/step - loss: 0.2011 - val_loss: 0.2135\n",
      "Epoch 33/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2016 - val_loss: 0.2251\n",
      "Epoch 34/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.2011 - val_loss: 0.2134\n",
      "Epoch 35/1000\n",
      "336/336 [==============================] - 5s 13ms/step - loss: 0.2007 - val_loss: 0.2130\n",
      "Epoch 36/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.1994 - val_loss: 0.2146\n",
      "Epoch 37/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.1996 - val_loss: 0.2190\n",
      "Epoch 38/1000\n",
      "336/336 [==============================] - 6s 17ms/step - loss: 0.1992 - val_loss: 0.2251\n",
      "Epoch 39/1000\n",
      "336/336 [==============================] - 5s 16ms/step - loss: 0.1973 - val_loss: 0.2124\n",
      "Epoch 40/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.1967 - val_loss: 0.2131\n",
      "Epoch 41/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.1967 - val_loss: 0.2131\n",
      "Epoch 42/1000\n",
      "336/336 [==============================] - 5s 13ms/step - loss: 0.1968 - val_loss: 0.2126\n",
      "Epoch 43/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.1966 - val_loss: 0.2138\n",
      "Epoch 44/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.1967 - val_loss: 0.2126\n",
      "Epoch 45/1000\n",
      "336/336 [==============================] - 5s 14ms/step - loss: 0.1967 - val_loss: 0.2125\n",
      "Epoch 46/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.1963 - val_loss: 0.2126\n",
      "Epoch 47/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.1965 - val_loss: 0.2128\n",
      "Epoch 48/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.1965 - val_loss: 0.2127\n",
      "Epoch 49/1000\n",
      "336/336 [==============================] - 5s 13ms/step - loss: 0.1968 - val_loss: 0.2129\n",
      "Epoch 50/1000\n",
      "336/336 [==============================] - 5s 13ms/step - loss: 0.1965 - val_loss: 0.2130\n",
      "Epoch 51/1000\n",
      "336/336 [==============================] - 5s 14ms/step - loss: 0.1965 - val_loss: 0.2126\n",
      "Epoch 52/1000\n",
      "336/336 [==============================] - 5s 14ms/step - loss: 0.1961 - val_loss: 0.2128\n",
      "Epoch 53/1000\n",
      "336/336 [==============================] - 5s 15ms/step - loss: 0.1968 - val_loss: 0.2129\n",
      "Epoch 54/1000\n",
      "336/336 [==============================] - 5s 16ms/step - loss: 0.1961 - val_loss: 0.2129\n",
      "Epoch 55/1000\n",
      "336/336 [==============================] - 5s 14ms/step - loss: 0.1969 - val_loss: 0.2129\n",
      "Epoch 56/1000\n",
      "336/336 [==============================] - 5s 14ms/step - loss: 0.1960 - val_loss: 0.2129\n",
      "Epoch 57/1000\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.1963 - val_loss: 0.2129\n",
      "Epoch 58/1000\n",
      "336/336 [==============================] - 5s 13ms/step - loss: 0.1970 - val_loss: 0.2129\n",
      "Epoch 59/1000\n",
      "336/336 [==============================] - 5s 14ms/step - loss: 0.1954 - val_loss: 0.2128\n",
      "Fold 5 NN: 0.21241\n"
     ]
    }
   ],
   "source": [
    "model_name = 'NN'\n",
    "pred_name = 'pred_{}'.format(model_name)\n",
    "\n",
    "n_folds = 5\n",
    "kf = model_selection.KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "scores_folds[model_name] = []\n",
    "counter = 1\n",
    "\n",
    "features_to_consider = list(train)\n",
    "\n",
    "features_to_consider.remove('time_id')\n",
    "features_to_consider.remove('target')\n",
    "features_to_consider.remove('row_id')\n",
    "try:\n",
    "    features_to_consider.remove('pred_NN')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n",
    "train[features_to_consider] = train[features_to_consider].fillna(train[features_to_consider].mean())\n",
    "test[features_to_consider] = test[features_to_consider].fillna(train[features_to_consider].mean())\n",
    "\n",
    "train[pred_name] = 0\n",
    "test['target'] = 0\n",
    "\n",
    "\n",
    "for n_count in range(n_folds):\n",
    "    print('CV {}/{}'.format(counter, n_folds))\n",
    "    \n",
    "    indexes = np.arange(nfolds).astype(int)    \n",
    "    indexes = np.delete(indexes,obj=n_count, axis=0) \n",
    "    \n",
    "    indexes = np.r_[values[indexes[0]],values[indexes[1]],values[indexes[2]],values[indexes[3]]]\n",
    "    \n",
    "    X_train = train.loc[train.time_id.isin(indexes), features_to_consider]\n",
    "    y_train = train.loc[train.time_id.isin(indexes), target_name]\n",
    "    X_test = train.loc[train.time_id.isin(values[n_count]), features_to_consider]\n",
    "    y_test = train.loc[train.time_id.isin(values[n_count]), target_name]\n",
    "    \n",
    "    #############################################################################################\n",
    "    # NN\n",
    "    #############################################################################################\n",
    "    \n",
    "    model = base_model()\n",
    "    model.summary()\n",
    "    model.compile(\n",
    "        keras.optimizers.Adam(learning_rate=0.003),\n",
    "        loss=root_mean_squared_per_error\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        features_to_consider.remove('stock_id')\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    num_data = X_train[features_to_consider]\n",
    "    \n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))         \n",
    "    num_data = scaler.fit_transform(num_data.values)    \n",
    "    \n",
    "    cat_data = X_train['stock_id']    \n",
    "    target =  y_train\n",
    "    \n",
    "    num_data_test = X_test[features_to_consider]\n",
    "    num_data_test = scaler.transform(num_data_test.values)\n",
    "    cat_data_test = X_test['stock_id']\n",
    "\n",
    "    model.fit([cat_data, num_data], \n",
    "              target,               \n",
    "              batch_size=1024,\n",
    "              epochs=1000,\n",
    "              validation_data=([cat_data_test, num_data_test], y_test),\n",
    "              callbacks=[es, plateau],\n",
    "              validation_batch_size=len(y_test),\n",
    "              shuffle=True,\n",
    "             verbose = 1)\n",
    "\n",
    "    preds = model.predict([cat_data_test, num_data_test]).reshape(1,-1)[0]\n",
    "    \n",
    "    score = round(rmspe(y_true = y_test, y_pred = preds),5)\n",
    "    print('Fold {} {}: {}'.format(counter, model_name, score))\n",
    "    scores_folds[model_name].append(score)\n",
    "    \n",
    "    tt =scaler.transform(test[features_to_consider].values)\n",
    "    test[target_name] += model.predict([test['stock_id'], tt]).reshape(1,-1)[0].clip(0,1e10)\n",
    "    #test[target_name] += model.predict([test['stock_id'], test[features_to_consider]]).reshape(1,-1)[0].clip(0,1e10)\n",
    "       \n",
    "    counter += 1\n",
    "    features_to_consider.append('stock_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "about-cache",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-26T11:21:12.807528Z",
     "iopub.status.busy": "2021-09-26T11:21:12.806891Z",
     "iopub.status.idle": "2021-09-26T11:21:12.825119Z",
     "shell.execute_reply": "2021-09-26T11:21:12.825668Z",
     "shell.execute_reply.started": "2021-09-24T09:45:38.34565Z"
    },
    "papermill": {
     "duration": 6.246754,
     "end_time": "2021-09-26T11:21:12.825833",
     "exception": false,
     "start_time": "2021-09-26T11:21:06.579079",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSPE NN: 1.0 - Folds: [0.20923, 0.21225, 0.20651, 0.21403, 0.21241]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0-4</td>\n",
       "      <td>0.000866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0-32</td>\n",
       "      <td>0.002334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0-34</td>\n",
       "      <td>0.002334</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  row_id    target\n",
       "0    0-4  0.000866\n",
       "1   0-32  0.002334\n",
       "2   0-34  0.002334"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test[target_name] = test[target_name]/n_folds\n",
    "nn_pres = test[target_name]\n",
    "score = round(rmspe(y_true = train[target_name].values, y_pred = train[pred_name].values),5)\n",
    "print('RMSPE {}: {} - Folds: {}'.format(model_name, score, scores_folds[model_name]))\n",
    "\n",
    "display(test[['row_id', target_name]].head())\n",
    "\n",
    "# [0.21327, 0.21715, 0.21615, 0.21865, 0.22035] --- submit result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entertaining-clone",
   "metadata": {
    "papermill": {
     "duration": 6.239395,
     "end_time": "2021-09-26T11:21:25.229904",
     "exception": false,
     "start_time": "2021-09-26T11:21:18.990509",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dated-samba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-26T11:21:37.721443Z",
     "iopub.status.busy": "2021-09-26T11:21:37.720277Z",
     "iopub.status.idle": "2021-09-26T11:21:37.804799Z",
     "shell.execute_reply": "2021-09-26T11:21:37.805361Z",
     "shell.execute_reply.started": "2021-09-24T09:45:50.456519Z"
    },
    "papermill": {
     "duration": 6.264,
     "end_time": "2021-09-26T11:21:37.805546",
     "exception": false,
     "start_time": "2021-09-26T11:21:31.541546",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import glob\n",
    "import os\n",
    "import gc\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import joblib\n",
    "from sklearn import preprocessing, model_selection\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import numpy.matlib\n",
    "\n",
    "\n",
    "path_submissions = '/'\n",
    "\n",
    "target_name = 'target'\n",
    "scores_folds = {}\n",
    "\n",
    "# data directory\n",
    "data_dir = '../input/optiver-realized-volatility-prediction/'\n",
    "\n",
    "def realized_absvar(series):\n",
    "    return np.sqrt(np.pi/(2*series.count()))*np.sum(np.abs(series))\n",
    "# realized bipower variation \n",
    "def realized_bipowvar(series):\n",
    "    cnt = series.count()\n",
    "    if cnt<3:\n",
    "        return np.nan\n",
    "    else:\n",
    "        cons = (np.pi/2)*(cnt/(cnt-2))\n",
    "        return cons*np.nansum(np.abs(series)*np.abs(series.shift()))\n",
    "# Calculate order book depth\n",
    "def calc_depth(df):\n",
    "    depth = df['bid_price1'] * df['bid_size1'] + df['ask_price1'] * df['ask_size1'] + df['bid_price2'] * df[\n",
    "               'bid_size2'] + df['ask_price2'] * df['ask_size2']\n",
    "    return depth\n",
    "# Calculate order book slope\n",
    "def calc_slope(df):\n",
    "    v0 = (df['bid_size1']+df['ask_size1'])/2\n",
    "    p0 = (df['bid_price1']+df['ask_price1'])/2\n",
    "    slope_bid = ((df['bid_size1']/v0)-1)/abs((df['bid_price1']/p0)-1)+(\n",
    "                (df['bid_size2']/df['bid_size1'])-1)/abs((df['bid_price2']/df['bid_price1'])-1)\n",
    "    slope_ask = ((df[\n",
    "        'ask_size1']/v0)-1)/abs((df['ask_price1']/p0)-1)+(\n",
    "                (df['ask_size2']/df['ask_size1'])-1)/abs((df['ask_price2']/df['ask_price1'])-1)\n",
    "    return (slope_bid+slope_ask)/2, abs(slope_bid-slope_ask)\n",
    "# Calculate order book dispersion\n",
    "def calc_dispersion(df):\n",
    "    bspread = df['bid_price1'] - df['bid_price2']\n",
    "    aspread = df['ask_price2'] - df['ask_price1']\n",
    "    bmid = (df['bid_price1'] + df['ask_price1'])/2  - df['bid_price1']\n",
    "    bmid2 = (df['bid_price1'] + df['ask_price1'])/2  - df['bid_price2']\n",
    "    amid = df['ask_price1'] - (df['bid_price1'] + df['ask_price1'])/2\n",
    "    amid2 = df['ask_price2'] - (df['bid_price1'] + df['ask_price1'])/2\n",
    "    bdisp = (df['bid_size1']*bmid + df['bid_size2']*bspread)/(df['bid_size1']+df['bid_size2'])\n",
    "    bdisp2 = (df['bid_size1']*bmid + df['bid_size2']*bmid2)/(df['bid_size1']+df['bid_size2'])\n",
    "    adisp = (df['ask_size1']*amid + df['ask_size2']*aspread)/(df['ask_size1']+df['ask_size2'])      \n",
    "    adisp2 = (df['ask_size1']*amid + df['ask_size2']*amid2)/(df['ask_size1']+df['ask_size2'])\n",
    "    return bspread, aspread, bmid, amid, bdisp, adisp, (bdisp + adisp)/2, (bdisp2 + adisp2)/2\n",
    "def calc_price_impact(df):\n",
    "    ask = (df['ask_price1'] * df['ask_size1'] + df['ask_price2'] * df['ask_size2'])/(df['ask_size1']+df['ask_size2'])\n",
    "    bid = (df['bid_price1'] * df['bid_size1'] + df['bid_price2'] * df['bid_size2'])/(df['bid_size1']+df['bid_size2'])\n",
    "    return (df['ask_price1'] - ask)/df['ask_price1'], (df['bid_price1'] - bid)/df['bid_price1']\n",
    "#  order flow imbalance\n",
    "def calc_ofi(df):\n",
    "    a = df['bid_size1']*np.where(df['bid_price1'].diff()>=0,1,0)\n",
    "    b = df['bid_size1'].shift()*np.where(df['bid_price1'].diff()<=0,1,0)\n",
    "    c = df['ask_size1']*np.where(df['ask_price1'].diff()<=0,1,0)\n",
    "    d = df['ask_size1'].shift()*np.where(df['ask_price1'].diff()>=0,1,0)\n",
    "    return a - b - c + d\n",
    "\n",
    "# Function to calculate first WAP\n",
    "def calc_wap1(df):\n",
    "    wap = (df['bid_price1'] * df['ask_size1'] + df['ask_price1'] * df['bid_size1']) / (df['bid_size1'] + df['ask_size1'])\n",
    "    return wap\n",
    "\n",
    "# Function to calculate second WAP\n",
    "def calc_wap2(df):\n",
    "    wap = (df['bid_price2'] * df['ask_size2'] + df['ask_price2'] * df['bid_size2']) / (df['bid_size2'] + df['ask_size2'])\n",
    "    return wap\n",
    "\n",
    "def calc_wap3(df):\n",
    "    wap = (df['bid_price1'] * df['bid_size1'] + df['ask_price1'] * df['ask_size1']) / (df['bid_size1'] + df['ask_size1'])\n",
    "    return wap\n",
    "\n",
    "def calc_wap4(df):\n",
    "    wap = (df['bid_price2'] * df['bid_size2'] + df['ask_price2'] * df['ask_size2']) / (df['bid_size2'] + df['ask_size2'])\n",
    "    return wap\n",
    "\n",
    "# Function to calculate the log of the return\n",
    "# Remember that logb(x / y) = logb(x) - logb(y)\n",
    "def log_return(series):\n",
    "    return np.log(series).diff()\n",
    "\n",
    "# Calculate the realized volatility\n",
    "def realized_volatility(series):\n",
    "    return np.sqrt(np.sum(series**2))\n",
    "\n",
    "# Function to count unique elements of a series\n",
    "def count_unique(series):\n",
    "    return len(np.unique(series))\n",
    "\n",
    "# Function to read our base train and test set\n",
    "def read_train_test():\n",
    "    train = pd.read_csv('../input/optiver-realized-volatility-prediction/train.csv')\n",
    "    test = pd.read_csv('../input/optiver-realized-volatility-prediction/test.csv')\n",
    "    # Create a key to merge with book and trade data\n",
    "    train['row_id'] = train['stock_id'].astype(str) + '-' + train['time_id'].astype(str)\n",
    "    test['row_id'] = test['stock_id'].astype(str) + '-' + test['time_id'].astype(str)\n",
    "    print(f'Our training set has {train.shape[0]} rows')\n",
    "    return train, test\n",
    "\n",
    "# Function to preprocess book data (for each stock id)\n",
    "def book_preprocessor(file_path):\n",
    "    df = pd.read_parquet(file_path)\n",
    "    #calc_depth\n",
    "    df['calc_depth']=calc_depth(df)\n",
    "    #calc_slope\n",
    "    df['calc_slope1'],df['calc_slope2']=calc_slope(df)\n",
    "    #calc_dispersion\n",
    "    df['bspread'], df['aspread'], df['bmid'], df['amid'], df['bdisp'], df['adisp'], df['a_bdisp_1'], df['ba_disp2'] = calc_dispersion(df)\n",
    "    #calc_price_impact\n",
    "    df['calc_price_impact1'],df['calc_price_impact2']=calc_price_impact(df)\n",
    "    #calc_ofi\n",
    "    df['calc_ofi']=calc_ofi(df)\n",
    "    # Calculate Wap\n",
    "    df['wap1'] = calc_wap1(df)\n",
    "    df['wap2'] = calc_wap2(df)\n",
    "    df['wap3'] = calc_wap3(df)\n",
    "    df['wap4'] = calc_wap4(df)\n",
    "    # Calculate log returns\n",
    "    df['log_return1'] = df.groupby(['time_id'])['wap1'].apply(log_return)\n",
    "    df['log_return2'] = df.groupby(['time_id'])['wap2'].apply(log_return)\n",
    "    df['log_return3'] = df.groupby(['time_id'])['wap3'].apply(log_return)\n",
    "    df['log_return4'] = df.groupby(['time_id'])['wap4'].apply(log_return)\n",
    "    # Calculate wap balance\n",
    "    df['wap_balance'] = abs(df['wap1'] - df['wap2'])\n",
    "    # Calculate spread\n",
    "    df['price_spread'] = (df['ask_price1'] - df['bid_price1']) / ((df['ask_price1'] + df['bid_price1']) / 2)\n",
    "    df['price_spread2'] = (df['ask_price2'] - df['bid_price2']) / ((df['ask_price2'] + df['bid_price2']) / 2)\n",
    "    df['bid_spread'] = df['bid_price1'] - df['bid_price2']\n",
    "    df['ask_spread'] = df['ask_price1'] - df['ask_price2']\n",
    "    df[\"bid_ask_spread\"] = abs(df['bid_spread'] - df['ask_spread'])\n",
    "    df['total_volume'] = (df['ask_size1'] + df['ask_size2']) + (df['bid_size1'] + df['bid_size2'])\n",
    "    df['volume_imbalance'] = abs((df['ask_size1'] + df['ask_size2']) - (df['bid_size1'] + df['bid_size2']))\n",
    "    \n",
    "    # Dict for aggregations\n",
    "    create_feature_dict = {\n",
    "        'wap1': [np.sum, np.std],\n",
    "        'wap2': [np.sum, np.std],\n",
    "        'wap3': [np.sum, np.std],\n",
    "        'wap4': [np.sum, np.std],\n",
    "        'log_return1': [realized_volatility,realized_absvar,realized_bipowvar],\n",
    "        'log_return2': [realized_volatility,realized_absvar,realized_bipowvar],\n",
    "        'log_return3': [realized_volatility,realized_absvar,realized_bipowvar],\n",
    "        'log_return4': [realized_volatility,realized_absvar,realized_bipowvar],\n",
    "        'wap_balance': [np.sum, np.max],\n",
    "        'price_spread':[np.sum, np.max],\n",
    "        'price_spread2':[np.sum, np.max],\n",
    "        'bid_spread':[np.sum, np.max],\n",
    "        'ask_spread':[np.sum, np.max],\n",
    "        'total_volume':[np.sum, np.max],\n",
    "        'volume_imbalance':[np.sum, np.max],\n",
    "        \"bid_ask_spread\":[np.sum,  np.max],\n",
    "    }\n",
    "    create_feature_dict_time = {\n",
    "        'log_return1': [realized_volatility,realized_absvar,realized_bipowvar],\n",
    "        'log_return2': [realized_volatility,realized_absvar,realized_bipowvar],\n",
    "        'log_return3': [realized_volatility,realized_absvar,realized_bipowvar],\n",
    "        'log_return4': [realized_volatility,realized_absvar,realized_bipowvar],\n",
    "    }\n",
    "    \n",
    "    # Function to get group stats for different windows (seconds in bucket)\n",
    "    def get_stats_window(fe_dict,seconds_in_bucket, add_suffix = False):\n",
    "        # Group by the window\n",
    "        df_feature = df[df['seconds_in_bucket'] >= seconds_in_bucket].groupby(['time_id']).agg(fe_dict).reset_index()\n",
    "        # Rename columns joining suffix\n",
    "        df_feature.columns = ['_'.join(col) for col in df_feature.columns]\n",
    "        # Add a suffix to differentiate windows\n",
    "        if add_suffix:\n",
    "            df_feature = df_feature.add_suffix('_' + str(seconds_in_bucket))\n",
    "        return df_feature\n",
    "    \n",
    "    # Get the stats for different windows\n",
    "    df_feature = get_stats_window(create_feature_dict,seconds_in_bucket = 0, add_suffix = False)\n",
    "    df_feature_500 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 500, add_suffix = True)\n",
    "    df_feature_400 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 400, add_suffix = True)\n",
    "    df_feature_300 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 300, add_suffix = True)\n",
    "    df_feature_200 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 200, add_suffix = True)\n",
    "    df_feature_100 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 100, add_suffix = True)\n",
    "\n",
    "    # Merge all\n",
    "    df_feature = df_feature.merge(df_feature_500, how = 'left', left_on = 'time_id_', right_on = 'time_id__500')\n",
    "    df_feature = df_feature.merge(df_feature_400, how = 'left', left_on = 'time_id_', right_on = 'time_id__400')\n",
    "    df_feature = df_feature.merge(df_feature_300, how = 'left', left_on = 'time_id_', right_on = 'time_id__300')\n",
    "    df_feature = df_feature.merge(df_feature_200, how = 'left', left_on = 'time_id_', right_on = 'time_id__200')\n",
    "    df_feature = df_feature.merge(df_feature_100, how = 'left', left_on = 'time_id_', right_on = 'time_id__100')\n",
    "    # Drop unnecesary time_ids\n",
    "    df_feature.drop(['time_id__500','time_id__400', 'time_id__300', 'time_id__200','time_id__100'], axis = 1, inplace = True)\n",
    "    \n",
    "    \n",
    "    # Create row_id so we can merge\n",
    "    stock_id = file_path.split('=')[1]\n",
    "    df_feature['row_id'] = df_feature['time_id_'].apply(lambda x: f'{stock_id}-{x}')\n",
    "    df_feature.drop(['time_id_'], axis = 1, inplace = True)\n",
    "    return df_feature\n",
    "\n",
    "# Function to preprocess trade data (for each stock id)\n",
    "def trade_preprocessor(file_path):\n",
    "    df = pd.read_parquet(file_path)\n",
    "    df['log_return'] = df.groupby('time_id')['price'].apply(log_return)\n",
    "    df['amount']=df['price']*df['size']\n",
    "    # Dict for aggregations\n",
    "    create_feature_dict = {\n",
    "        'log_return':[realized_volatility],\n",
    "        'seconds_in_bucket':[count_unique],\n",
    "        'size':[np.sum, np.max, np.min],\n",
    "        'order_count':[np.sum,np.max],\n",
    "        'amount':[np.sum,np.max,np.min],\n",
    "    }\n",
    "    create_feature_dict_time = {\n",
    "        'log_return':[realized_volatility,realized_absvar,realized_bipowvar],\n",
    "        'seconds_in_bucket':[count_unique],\n",
    "        'size':[np.sum],\n",
    "        'order_count':[np.sum],\n",
    "    }\n",
    "    # Function to get group stats for different windows (seconds in bucket)\n",
    "    def get_stats_window(fe_dict,seconds_in_bucket, add_suffix = False):\n",
    "        # Group by the window\n",
    "        df_feature = df[df['seconds_in_bucket'] >= seconds_in_bucket].groupby(['time_id']).agg(fe_dict).reset_index()\n",
    "        # Rename columns joining suffix\n",
    "        df_feature.columns = ['_'.join(col) for col in df_feature.columns]\n",
    "        # Add a suffix to differentiate windows\n",
    "        if add_suffix:\n",
    "            df_feature = df_feature.add_suffix('_' + str(seconds_in_bucket))\n",
    "        return df_feature\n",
    "    \n",
    "\n",
    "    # Get the stats for different windows\n",
    "    df_feature = get_stats_window(create_feature_dict,seconds_in_bucket = 0, add_suffix = False)\n",
    "    df_feature_500 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 500, add_suffix = True)\n",
    "    df_feature_400 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 400, add_suffix = True)\n",
    "    df_feature_300 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 300, add_suffix = True)\n",
    "    df_feature_200 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 200, add_suffix = True)\n",
    "    df_feature_100 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 100, add_suffix = True)\n",
    "    \n",
    "    def tendency(price, vol):    \n",
    "        df_diff = np.diff(price)\n",
    "        val = (df_diff/price[1:])*100\n",
    "        power = np.sum(val*vol[1:])\n",
    "        return(power)\n",
    "    \n",
    "    lis = []\n",
    "    for n_time_id in df['time_id'].unique():\n",
    "        df_id = df[df['time_id'] == n_time_id]        \n",
    "        tendencyV = tendency(df_id['price'].values, df_id['size'].values)      \n",
    "        f_max = np.sum(df_id['price'].values > np.mean(df_id['price'].values))\n",
    "        f_min = np.sum(df_id['price'].values < np.mean(df_id['price'].values))\n",
    "        df_max =  np.sum(np.diff(df_id['price'].values) > 0)\n",
    "        df_min =  np.sum(np.diff(df_id['price'].values) < 0)\n",
    "        # new\n",
    "        abs_diff = np.median(np.abs( df_id['price'].values - np.mean(df_id['price'].values)))        \n",
    "        energy = np.mean(df_id['price'].values**2)\n",
    "        iqr_p = np.percentile(df_id['price'].values,75) - np.percentile(df_id['price'].values,25)\n",
    "        \n",
    "        # vol vars\n",
    "        \n",
    "        abs_diff_v = np.median(np.abs( df_id['size'].values - np.mean(df_id['size'].values)))        \n",
    "        energy_v = np.sum(df_id['size'].values**2)\n",
    "        iqr_p_v = np.percentile(df_id['size'].values,75) - np.percentile(df_id['size'].values,25)\n",
    "        \n",
    "        lis.append({'time_id':n_time_id,'tendency':tendencyV,'f_max':f_max,'f_min':f_min,'df_max':df_max,'df_min':df_min,\n",
    "                   'abs_diff':abs_diff,'energy':energy,'iqr_p':iqr_p,'abs_diff_v':abs_diff_v,'energy_v':energy_v,'iqr_p_v':iqr_p_v})\n",
    "    \n",
    "    df_lr = pd.DataFrame(lis)\n",
    "        \n",
    "   \n",
    "    df_feature = df_feature.merge(df_lr, how = 'left', left_on = 'time_id_', right_on = 'time_id')\n",
    "    \n",
    "    # Merge all\n",
    "    df_feature = df_feature.merge(df_feature_500, how = 'left', left_on = 'time_id_', right_on = 'time_id__500')\n",
    "    df_feature = df_feature.merge(df_feature_400, how = 'left', left_on = 'time_id_', right_on = 'time_id__400')\n",
    "    df_feature = df_feature.merge(df_feature_300, how = 'left', left_on = 'time_id_', right_on = 'time_id__300')\n",
    "    df_feature = df_feature.merge(df_feature_200, how = 'left', left_on = 'time_id_', right_on = 'time_id__200')\n",
    "    df_feature = df_feature.merge(df_feature_100, how = 'left', left_on = 'time_id_', right_on = 'time_id__100')\n",
    "    # Drop unnecesary time_ids\n",
    "    df_feature.drop(['time_id__500','time_id__400', 'time_id__300', 'time_id__200','time_id','time_id__100'], axis = 1, inplace = True)\n",
    "    \n",
    "    \n",
    "    df_feature = df_feature.add_prefix('trade_')\n",
    "    stock_id = file_path.split('=')[1]\n",
    "    df_feature['row_id'] = df_feature['trade_time_id_'].apply(lambda x:f'{stock_id}-{x}')\n",
    "    df_feature.drop(['trade_time_id_'], axis = 1, inplace = True)\n",
    "    return df_feature\n",
    "\n",
    "# Function to get group stats for the stock_id and time_id\n",
    "def get_time_stock(df):\n",
    "    vol_cols = ['log_return1_realized_volatility', 'log_return2_realized_volatility', 'log_return1_realized_volatility_400', 'log_return2_realized_volatility_400', \n",
    "                'log_return1_realized_volatility_300', 'log_return2_realized_volatility_300', 'log_return1_realized_volatility_200', 'log_return2_realized_volatility_200', \n",
    "                'trade_log_return_realized_volatility', 'trade_log_return_realized_volatility_400', 'trade_log_return_realized_volatility_300', 'trade_log_return_realized_volatility_200']\n",
    "\n",
    "\n",
    "    # Group by the stock id\n",
    "    df_stock_id = df.groupby(['stock_id'])[vol_cols].agg(['mean', 'std', 'max', 'min', ]).reset_index()\n",
    "    # Rename columns joining suffix\n",
    "    df_stock_id.columns = ['_'.join(col) for col in df_stock_id.columns]\n",
    "    df_stock_id = df_stock_id.add_suffix('_' + 'stock')\n",
    "\n",
    "    # Group by the stock id\n",
    "    df_time_id = df.groupby(['time_id'])[vol_cols].agg(['mean', 'std', 'max', 'min', ]).reset_index()\n",
    "    # Rename columns joining suffix\n",
    "    df_time_id.columns = ['_'.join(col) for col in df_time_id.columns]\n",
    "    df_time_id = df_time_id.add_suffix('_' + 'time')\n",
    "    \n",
    "    # Merge with original dataframe\n",
    "    df = df.merge(df_stock_id, how = 'left', left_on = ['stock_id'], right_on = ['stock_id__stock'])\n",
    "    df = df.merge(df_time_id, how = 'left', left_on = ['time_id'], right_on = ['time_id__time'])\n",
    "    df.drop(['stock_id__stock', 'time_id__time'], axis = 1, inplace = True)\n",
    "    return df\n",
    "    \n",
    "# Funtion to make preprocessing function in parallel (for each stock id)\n",
    "def preprocessor(list_stock_ids, is_train = True):\n",
    "    \n",
    "    # Parrallel for loop\n",
    "    def for_joblib(stock_id):\n",
    "        # Train\n",
    "        if is_train:\n",
    "            file_path_book = data_dir + \"book_train.parquet/stock_id=\" + str(stock_id)\n",
    "            file_path_trade = data_dir + \"trade_train.parquet/stock_id=\" + str(stock_id)\n",
    "        # Test\n",
    "        else:\n",
    "            file_path_book = data_dir + \"book_test.parquet/stock_id=\" + str(stock_id)\n",
    "            file_path_trade = data_dir + \"trade_test.parquet/stock_id=\" + str(stock_id)\n",
    "    \n",
    "        # Preprocess book and trade data and merge them\n",
    "        df_tmp = pd.merge(book_preprocessor(file_path_book), trade_preprocessor(file_path_trade), on = 'row_id', how = 'left')\n",
    "        \n",
    "        # Return the merge dataframe\n",
    "        return df_tmp\n",
    "    \n",
    "    # Use parallel api to call paralle for loop\n",
    "    df = Parallel(n_jobs = -1, verbose = 1)(delayed(for_joblib)(stock_id) for stock_id in list_stock_ids)\n",
    "    # Concatenate all the dataframes that return from Parallel\n",
    "    df = pd.concat(df, ignore_index = True)\n",
    "    return df\n",
    "\n",
    "# Function to calculate the root mean squared percentage error\n",
    "def rmspe(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square((y_true - y_pred) / y_true)))\n",
    "\n",
    "# Function to early stop with root mean squared percentage error\n",
    "def feval_rmspe(y_pred, lgb_train):\n",
    "    y_true = lgb_train.get_label()\n",
    "    return 'RMSPE', rmspe(y_true, y_pred), False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "devoted-street",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-26T11:21:50.232515Z",
     "iopub.status.busy": "2021-09-26T11:21:50.231754Z",
     "iopub.status.idle": "2021-09-26T13:34:05.085803Z",
     "shell.execute_reply": "2021-09-26T13:34:05.086381Z"
    },
    "papermill": {
     "duration": 7941.0851,
     "end_time": "2021-09-26T13:34:05.086580",
     "exception": false,
     "start_time": "2021-09-26T11:21:44.001480",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our training set has 428932 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 51.6min\n",
      "[Parallel(n_jobs=-1)]: Done 112 out of 112 | elapsed: 131.8min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 4 3 1 3 0 1 3 5 1 0 4 3 3 3 3 3 1 3 3 6 0 0 3 6 3 0 3 6 3 6 3 3 0 4 6 3\n",
      " 6 3 3 3 0 3 3 0 4 3 3 3 4 0 6 6 6 1 4 1 3 0 3 3 0 3 0 0 6 4 0 6 4 5 2 6 4\n",
      " 4 3 4 0 6 4 4 3 0 0 4 4 6 6 3 4 0 3 3 3 3 6 0 6 6 0 0 3 0 0 3 3 0 0 3 4 3\n",
      " 4]\n",
      "[5, 10, 22, 23, 29, 36, 44, 48, 56, 66, 69, 72, 73, 76, 87, 94, 95, 102, 109, 112, 113, 115, 116, 120, 122]\n",
      "[3, 6, 9, 18, 61, 63]\n",
      "[81]\n",
      "[0, 2, 4, 7, 13, 14, 15, 16, 17, 19, 20, 26, 28, 30, 32, 34, 35, 39, 41, 42, 43, 46, 47, 51, 52, 53, 64, 67, 68, 70, 85, 93, 100, 103, 104, 105, 107, 114, 118, 119, 123, 125]\n",
      "[1, 11, 37, 50, 55, 62, 75, 78, 83, 84, 86, 89, 90, 96, 97, 101, 124, 126]\n",
      "[8, 80]\n",
      "[21, 27, 31, 33, 38, 40, 58, 59, 60, 74, 77, 82, 88, 98, 99, 108, 110, 111]\n"
     ]
    }
   ],
   "source": [
    "# Read train and test\n",
    "train, test = read_train_test()\n",
    "\n",
    "# Get unique stock ids \n",
    "train_stock_ids = train['stock_id'].unique()\n",
    "# Preprocess them using Parallel and our single stock id functions\n",
    "train_ = preprocessor(train_stock_ids, is_train = True)\n",
    "train = train.merge(train_, on = ['row_id'], how = 'left')\n",
    "\n",
    "# Get unique stock ids \n",
    "test_stock_ids = test['stock_id'].unique()\n",
    "# Preprocess them using Parallel and our single stock id functions\n",
    "test_ = preprocessor(test_stock_ids, is_train = False)\n",
    "test = test.merge(test_, on = ['row_id'], how = 'left')\n",
    "\n",
    "# Get group stats of time_id and stock_id\n",
    "train = get_time_stock(train)\n",
    "test = get_time_stock(test)\n",
    "\n",
    "# replace by order sum (tau)\n",
    "train['size_tau'] = np.sqrt( 1/ train['trade_seconds_in_bucket_count_unique'] )\n",
    "test['size_tau'] = np.sqrt( 1/ test['trade_seconds_in_bucket_count_unique'] )\n",
    "#train['size_tau_450'] = np.sqrt( 1/ train['trade_seconds_in_bucket_count_unique_450'] )\n",
    "#test['size_tau_450'] = np.sqrt( 1/ test['trade_seconds_in_bucket_count_unique_450'] )\n",
    "train['size_tau_400'] = np.sqrt( 1/ train['trade_seconds_in_bucket_count_unique_400'] )\n",
    "test['size_tau_400'] = np.sqrt( 1/ test['trade_seconds_in_bucket_count_unique_400'] )\n",
    "train['size_tau_300'] = np.sqrt( 1/ train['trade_seconds_in_bucket_count_unique_300'] )\n",
    "test['size_tau_300'] = np.sqrt( 1/ test['trade_seconds_in_bucket_count_unique_300'] )\n",
    "#train['size_tau_150'] = np.sqrt( 1/ train['trade_seconds_in_bucket_count_unique_150'] )\n",
    "#test['size_tau_150'] = np.sqrt( 1/ test['trade_seconds_in_bucket_count_unique_150'] )\n",
    "train['size_tau_200'] = np.sqrt( 1/ train['trade_seconds_in_bucket_count_unique_200'] )\n",
    "test['size_tau_200'] = np.sqrt( 1/ test['trade_seconds_in_bucket_count_unique_200'] )\n",
    "\n",
    "train['size_tau2'] = np.sqrt( 1/ train['trade_order_count_sum'] )\n",
    "test['size_tau2'] = np.sqrt( 1/ test['trade_order_count_sum'] )\n",
    "#train['size_tau2_450'] = np.sqrt( 0.25/ train['trade_order_count_sum'] )\n",
    "#test['size_tau2_450'] = np.sqrt( 0.25/ test['trade_order_count_sum'] )\n",
    "train['size_tau2_400'] = np.sqrt( 0.33/ train['trade_order_count_sum'] )\n",
    "test['size_tau2_400'] = np.sqrt( 0.33/ test['trade_order_count_sum'] )\n",
    "train['size_tau2_300'] = np.sqrt( 0.5/ train['trade_order_count_sum'] )\n",
    "test['size_tau2_300'] = np.sqrt( 0.5/ test['trade_order_count_sum'] )\n",
    "#train['size_tau2_150'] = np.sqrt( 0.75/ train['trade_order_count_sum'] )\n",
    "#test['size_tau2_150'] = np.sqrt( 0.75/ test['trade_order_count_sum'] )\n",
    "train['size_tau2_200'] = np.sqrt( 0.66/ train['trade_order_count_sum'] )\n",
    "test['size_tau2_200'] = np.sqrt( 0.66/ test['trade_order_count_sum'] )\n",
    "\n",
    "# delta tau\n",
    "train['size_tau2_d'] = train['size_tau2_400'] - train['size_tau2']\n",
    "test['size_tau2_d'] = test['size_tau2_400'] - test['size_tau2']\n",
    "\n",
    "train['book_BPV_jump1'] = train['log_return1_realized_volatility'] - train['log_return1_realized_bipowvar'].values\n",
    "train['book_BPV_jump1'] = np.where(train['book_BPV_jump1']<0, 0, train['book_BPV_jump1'])\n",
    "\n",
    "test['book_BPV_jump1'] = test['log_return1_realized_volatility'] - test['log_return1_realized_bipowvar'].values\n",
    "test['book_BPV_jump1'] = np.where(test['book_BPV_jump1']<0, 0, test['book_BPV_jump1'])\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "# making agg features\n",
    "\n",
    "train_p = pd.read_csv('../input/optiver-realized-volatility-prediction/train.csv')\n",
    "train_p = train_p.pivot(index='time_id', columns='stock_id', values='target')\n",
    "\n",
    "corr = train_p.corr()\n",
    "\n",
    "ids = corr.index\n",
    "\n",
    "kmeans = KMeans(n_clusters=7, random_state=0).fit(corr.values)\n",
    "print(kmeans.labels_)\n",
    "\n",
    "l = []\n",
    "for n in range(7):\n",
    "    l.append ( [ (x-1) for x in ( (ids+1)*(kmeans.labels_ == n)) if x > 0] )\n",
    "    \n",
    "\n",
    "mat = []\n",
    "matTest = []\n",
    "\n",
    "n = 0\n",
    "for ind in l:\n",
    "    print(ind)\n",
    "    newDf = train.loc[train['stock_id'].isin(ind) ]\n",
    "    newDf = newDf.groupby(['time_id']).agg(np.nanmean)\n",
    "    newDf.loc[:,'stock_id'] = str(n)+'c1'\n",
    "    mat.append ( newDf )\n",
    "    \n",
    "    newDf = test.loc[test['stock_id'].isin(ind) ]    \n",
    "    newDf = newDf.groupby(['time_id']).agg(np.nanmean)\n",
    "    newDf.loc[:,'stock_id'] = str(n)+'c1'\n",
    "    matTest.append ( newDf )\n",
    "    \n",
    "    n+=1\n",
    "    \n",
    "mat1 = pd.concat(mat).reset_index()\n",
    "mat1.drop(columns=['target'],inplace=True)\n",
    "\n",
    "mat2 = pd.concat(matTest).reset_index()\n",
    "\n",
    "mat2 = pd.concat([mat2,mat1.loc[mat1.time_id==5]])\n",
    "mat1 = mat1.pivot(index='time_id', columns='stock_id')\n",
    "mat1.columns = [\"_\".join(x) for x in mat1.columns.ravel()]\n",
    "mat1.reset_index(inplace=True)\n",
    "\n",
    "mat2 = mat2.pivot(index='time_id', columns='stock_id')\n",
    "mat2.columns = [\"_\".join(x) for x in mat2.columns.ravel()]\n",
    "mat2.reset_index(inplace=True)\n",
    "nnn = ['time_id',\n",
    "     'log_return1_realized_volatility_0c1',\n",
    "     'log_return1_realized_volatility_1c1',     \n",
    "     'log_return1_realized_volatility_3c1',\n",
    "     'log_return1_realized_volatility_4c1',     \n",
    "     'log_return1_realized_volatility_6c1',\n",
    "     'total_volume_sum_0c1',\n",
    "     'total_volume_sum_1c1', \n",
    "     'total_volume_sum_3c1',\n",
    "     'total_volume_sum_4c1', \n",
    "     'total_volume_sum_6c1',\n",
    "     'trade_size_sum_0c1',\n",
    "     'trade_size_sum_1c1', \n",
    "     'trade_size_sum_3c1',\n",
    "     'trade_size_sum_4c1', \n",
    "     'trade_size_sum_6c1',\n",
    "     'trade_order_count_sum_0c1',\n",
    "     'trade_order_count_sum_1c1',\n",
    "     'trade_order_count_sum_3c1',\n",
    "     'trade_order_count_sum_4c1',\n",
    "     'trade_order_count_sum_6c1',      \n",
    "     'price_spread_sum_0c1',\n",
    "     'price_spread_sum_1c1',\n",
    "     'price_spread_sum_3c1',\n",
    "     'price_spread_sum_4c1',\n",
    "     'price_spread_sum_6c1',   \n",
    "     'bid_spread_sum_0c1',\n",
    "     'bid_spread_sum_1c1',\n",
    "     'bid_spread_sum_3c1',\n",
    "     'bid_spread_sum_4c1',\n",
    "     'bid_spread_sum_6c1',       \n",
    "     'ask_spread_sum_0c1',\n",
    "     'ask_spread_sum_1c1',\n",
    "     'ask_spread_sum_3c1',\n",
    "     'ask_spread_sum_4c1',\n",
    "     'ask_spread_sum_6c1',   \n",
    "     'volume_imbalance_sum_0c1',\n",
    "     'volume_imbalance_sum_1c1',\n",
    "     'volume_imbalance_sum_3c1',\n",
    "     'volume_imbalance_sum_4c1',\n",
    "     'volume_imbalance_sum_6c1',       \n",
    "     'bid_ask_spread_sum_0c1',\n",
    "     'bid_ask_spread_sum_1c1',\n",
    "     'bid_ask_spread_sum_3c1',\n",
    "     'bid_ask_spread_sum_4c1',\n",
    "     'bid_ask_spread_sum_6c1',\n",
    "     'size_tau2_0c1',\n",
    "     'size_tau2_1c1',\n",
    "     'size_tau2_3c1',\n",
    "     'size_tau2_4c1',\n",
    "     'size_tau2_6c1'] \n",
    "train = pd.merge(train,mat1[nnn],how='left',on='time_id')\n",
    "test = pd.merge(test,mat2[nnn],how='left',on='time_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "engaged-enlargement",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-26T13:34:17.473460Z",
     "iopub.status.busy": "2021-09-26T13:34:17.472739Z",
     "iopub.status.idle": "2021-09-26T13:34:57.931011Z",
     "shell.execute_reply": "2021-09-26T13:34:57.931471Z"
    },
    "papermill": {
     "duration": 46.58291,
     "end_time": "2021-09-26T13:34:57.931644",
     "exception": false,
     "start_time": "2021-09-26T13:34:11.348734",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1\n",
      "Training fold 2\n",
      "Training fold 3\n",
      "Training fold 4\n",
      "Training fold 5\n",
      "Our out of folds RMSPE is 0.19453429240888334\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x648 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gc\n",
    "del mat1,mat2\n",
    "gc.collect()\n",
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgb\n",
    "\n",
    "seed0=2021\n",
    "params0 = {\n",
    "    'objective': 'rmse',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'max_depth': -1,\n",
    "    'max_bin':100,\n",
    "    'min_data_in_leaf':500,\n",
    "    'learning_rate': 0.05,\n",
    "    'subsample': 0.72,\n",
    "    'subsample_freq': 4,\n",
    "    'feature_fraction': 0.5,\n",
    "    'lambda_l1': 0.5,\n",
    "    'lambda_l2': 1.0,\n",
    "    'categorical_column':[0],\n",
    "    'seed':seed0,\n",
    "    'feature_fraction_seed': seed0,\n",
    "    'bagging_seed': seed0,\n",
    "    'drop_seed': seed0,\n",
    "    'data_random_seed': seed0,\n",
    "    'n_jobs':-1,\n",
    "    'verbose': -1}\n",
    "seed1=42\n",
    "params1 = {\n",
    "        'learning_rate': 0.1,        \n",
    "        'lambda_l1': 2,\n",
    "        'lambda_l2': 7,\n",
    "        'num_leaves': 800,\n",
    "        'min_sum_hessian_in_leaf': 20,\n",
    "        'feature_fraction': 0.8,\n",
    "        'feature_fraction_bynode': 0.8,\n",
    "        'bagging_fraction': 0.9,\n",
    "        'bagging_freq': 42,\n",
    "        'min_data_in_leaf': 700,\n",
    "        'max_depth': 4,\n",
    "        'categorical_column':[0],\n",
    "        'seed': seed1,\n",
    "        'feature_fraction_seed': seed1,\n",
    "        'bagging_seed': seed1,\n",
    "        'drop_seed': seed1,\n",
    "        'data_random_seed': seed1,\n",
    "        'objective': 'rmse',\n",
    "        'boosting': 'gbdt',\n",
    "        'verbosity': -1,\n",
    "        'n_jobs':-1,\n",
    "    }\n",
    "# Function to early stop with root mean squared percentage error\n",
    "def rmspe(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square((y_true - y_pred) / y_true)))\n",
    "\n",
    "def feval_rmspe(y_pred, lgb_train):\n",
    "    y_true = lgb_train.get_label()\n",
    "    return 'RMSPE', rmspe(y_true, y_pred), False\n",
    "\n",
    "def train_and_evaluate_lgb(train, test, params):\n",
    "    # Hyperparammeters (just basic)\n",
    "    \n",
    "    features = [col for col in train.columns if col not in {\"time_id\", \"target\", \"row_id\"}]\n",
    "    y = train['target']\n",
    "    # Create out of folds array\n",
    "    oof_predictions = np.zeros(train.shape[0])\n",
    "    # Create test array to store predictions\n",
    "    test_predictions = np.zeros(test.shape[0])\n",
    "    # Create a KFold object\n",
    "    kfold = KFold(n_splits = 5, random_state = 42, shuffle = True)\n",
    "    # Iterate through each fold\n",
    "    for fold, (trn_ind, val_ind) in enumerate(kfold.split(train)):\n",
    "        print(f'Training fold {fold + 1}')\n",
    "        x_train, x_val = train.iloc[trn_ind], train.iloc[val_ind]\n",
    "        y_train, y_val = y.iloc[trn_ind], y.iloc[val_ind]\n",
    "        # Root mean squared percentage error weights\n",
    "        train_weights = 1 / np.square(y_train)\n",
    "        val_weights = 1 / np.square(y_val)\n",
    "        train_dataset = lgb.Dataset(x_train[features], y_train, weight = train_weights)\n",
    "        val_dataset = lgb.Dataset(x_val[features], y_val, weight = val_weights)\n",
    "#         model = lgb.train(params = params,\n",
    "#                           num_boost_round=1000,\n",
    "#                           train_set = train_dataset, \n",
    "#                           valid_sets = [train_dataset, val_dataset], \n",
    "#                           verbose_eval = 250,\n",
    "#                           early_stopping_rounds=50,\n",
    "#                           feval = feval_rmspe)\n",
    "        # Add predictions to the out of folds array\n",
    "        model = joblib.load('../input/lgbm-most-fe-cv-194/'+f'model_fold{fold}.pkl')\n",
    "        oof_predictions[val_ind] = model.predict(x_val[features])\n",
    "        # Predict the test set\n",
    "        test_predictions += model.predict(test[features]) / 5\n",
    "    rmspe_score = rmspe(y, oof_predictions)\n",
    "    print(f'Our out of folds RMSPE is {rmspe_score}')\n",
    "    lgb.plot_importance(model,max_num_features=20)\n",
    "    # Return test predictions\n",
    "    return test_predictions\n",
    "# Traing and evaluate\n",
    "predictions_lgb= train_and_evaluate_lgb(train, test,params0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adolescent-singer",
   "metadata": {
    "papermill": {
     "duration": 6.225758,
     "end_time": "2021-09-26T13:35:10.426160",
     "exception": false,
     "start_time": "2021-09-26T13:35:04.200402",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Best Public Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "alternative-event",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-26T13:35:22.819181Z",
     "iopub.status.busy": "2021-09-26T13:35:22.818520Z",
     "iopub.status.idle": "2021-09-26T13:35:22.825840Z",
     "shell.execute_reply": "2021-09-26T13:35:22.826385Z"
    },
    "papermill": {
     "duration": 6.228567,
     "end_time": "2021-09-26T13:35:22.826566",
     "exception": false,
     "start_time": "2021-09-26T13:35:16.597999",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import glob\n",
    "import os\n",
    "import gc\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import joblib\n",
    "from sklearn import preprocessing, model_selection\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import numpy.matlib\n",
    "\n",
    "\n",
    "path_submissions = '/'\n",
    "\n",
    "target_name = 'target'\n",
    "scores_folds = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bacterial-rendering",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-26T13:35:35.231673Z",
     "iopub.status.busy": "2021-09-26T13:35:35.230612Z",
     "iopub.status.idle": "2021-09-26T13:35:35.294011Z",
     "shell.execute_reply": "2021-09-26T13:35:35.294580Z"
    },
    "papermill": {
     "duration": 6.25,
     "end_time": "2021-09-26T13:35:35.294772",
     "exception": false,
     "start_time": "2021-09-26T13:35:29.044772",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data directory\n",
    "data_dir = '../input/optiver-realized-volatility-prediction/'\n",
    "\n",
    "# Function to calculate first WAP\n",
    "def calc_wap1(df):\n",
    "    wap = (df['bid_price1'] * df['ask_size1'] + df['ask_price1'] * df['bid_size1']) / (df['bid_size1'] + df['ask_size1'])\n",
    "    return wap\n",
    "\n",
    "# Function to calculate second WAP\n",
    "def calc_wap2(df):\n",
    "    wap = (df['bid_price2'] * df['ask_size2'] + df['ask_price2'] * df['bid_size2']) / (df['bid_size2'] + df['ask_size2'])\n",
    "    return wap\n",
    "\n",
    "def calc_wap3(df):\n",
    "    wap = (df['bid_price1'] * df['bid_size1'] + df['ask_price1'] * df['ask_size1']) / (df['bid_size1'] + df['ask_size1'])\n",
    "    return wap\n",
    "\n",
    "def calc_wap4(df):\n",
    "    wap = (df['bid_price2'] * df['bid_size2'] + df['ask_price2'] * df['ask_size2']) / (df['bid_size2'] + df['ask_size2'])\n",
    "    return wap\n",
    "\n",
    "# Function to calculate the log of the return\n",
    "# Remember that logb(x / y) = logb(x) - logb(y)\n",
    "def log_return(series):\n",
    "    return np.log(series).diff()\n",
    "\n",
    "# Calculate the realized volatility\n",
    "def realized_volatility(series):\n",
    "    return np.sqrt(np.sum(series**2))\n",
    "\n",
    "# Function to count unique elements of a series\n",
    "def count_unique(series):\n",
    "    return len(np.unique(series))\n",
    "\n",
    "# Function to read our base train and test set\n",
    "def read_train_test():\n",
    "    #train = pd.read_csv('../input/optiver-realized-volatility-prediction/train.csv')\n",
    "    test = pd.read_csv('../input/optiver-realized-volatility-prediction/test.csv')\n",
    "    # Create a key to merge with book and trade data\n",
    "    #train['row_id'] = train['stock_id'].astype(str) + '-' + train['time_id'].astype(str)\n",
    "    test['row_id'] = test['stock_id'].astype(str) + '-' + test['time_id'].astype(str)\n",
    "    #print(f'Our training set has {train.shape[0]} rows')\n",
    "    return test\n",
    "\n",
    "# Function to preprocess book data (for each stock id)\n",
    "def book_preprocessor(file_path):\n",
    "    df = pd.read_parquet(file_path)\n",
    "    # Calculate Wap\n",
    "    df['wap1'] = calc_wap1(df)\n",
    "    df['wap2'] = calc_wap2(df)\n",
    "    df['wap3'] = calc_wap3(df)\n",
    "    df['wap4'] = calc_wap4(df)\n",
    "    # Calculate log returns\n",
    "    df['log_return1'] = df.groupby(['time_id'])['wap1'].apply(log_return)\n",
    "    df['log_return2'] = df.groupby(['time_id'])['wap2'].apply(log_return)\n",
    "    df['log_return3'] = df.groupby(['time_id'])['wap3'].apply(log_return)\n",
    "    df['log_return4'] = df.groupby(['time_id'])['wap4'].apply(log_return)\n",
    "    # Calculate wap balance\n",
    "    df['wap_balance'] = abs(df['wap1'] - df['wap2'])\n",
    "    # Calculate spread\n",
    "    df['price_spread'] = (df['ask_price1'] - df['bid_price1']) / ((df['ask_price1'] + df['bid_price1']) / 2)\n",
    "    df['price_spread2'] = (df['ask_price2'] - df['bid_price2']) / ((df['ask_price2'] + df['bid_price2']) / 2)\n",
    "    df['bid_spread'] = df['bid_price1'] - df['bid_price2']\n",
    "    df['ask_spread'] = df['ask_price1'] - df['ask_price2']\n",
    "    df[\"bid_ask_spread\"] = abs(df['bid_spread'] - df['ask_spread'])\n",
    "    df['total_volume'] = (df['ask_size1'] + df['ask_size2']) + (df['bid_size1'] + df['bid_size2'])\n",
    "    df['volume_imbalance'] = abs((df['ask_size1'] + df['ask_size2']) - (df['bid_size1'] + df['bid_size2']))\n",
    "    \n",
    "    # Dict for aggregations\n",
    "    create_feature_dict = {\n",
    "        'wap1': [np.sum, np.std],\n",
    "        'wap2': [np.sum, np.std],\n",
    "        'wap3': [np.sum, np.std],\n",
    "        'wap4': [np.sum, np.std],\n",
    "        'log_return1': [realized_volatility],\n",
    "        'log_return2': [realized_volatility],\n",
    "        'log_return3': [realized_volatility],\n",
    "        'log_return4': [realized_volatility],\n",
    "        'wap_balance': [np.sum, np.max],\n",
    "        'price_spread':[np.sum, np.max],\n",
    "        'price_spread2':[np.sum, np.max],\n",
    "        'bid_spread':[np.sum, np.max],\n",
    "        'ask_spread':[np.sum, np.max],\n",
    "        'total_volume':[np.sum, np.max],\n",
    "        'volume_imbalance':[np.sum, np.max],\n",
    "        \"bid_ask_spread\":[np.sum,  np.max],\n",
    "    }\n",
    "    create_feature_dict_time = {\n",
    "        'log_return1': [realized_volatility],\n",
    "        'log_return2': [realized_volatility],\n",
    "        'log_return3': [realized_volatility],\n",
    "        'log_return4': [realized_volatility],\n",
    "    }\n",
    "    \n",
    "    # Function to get group stats for different windows (seconds in bucket)\n",
    "    def get_stats_window(fe_dict,seconds_in_bucket, add_suffix = False):\n",
    "        # Group by the window\n",
    "        df_feature = df[df['seconds_in_bucket'] >= seconds_in_bucket].groupby(['time_id']).agg(fe_dict).reset_index()\n",
    "        # Rename columns joining suffix\n",
    "        df_feature.columns = ['_'.join(col) for col in df_feature.columns]\n",
    "        # Add a suffix to differentiate windows\n",
    "        if add_suffix:\n",
    "            df_feature = df_feature.add_suffix('_' + str(seconds_in_bucket))\n",
    "        return df_feature\n",
    "    \n",
    "    # Get the stats for different windows\n",
    "    df_feature = get_stats_window(create_feature_dict,seconds_in_bucket = 0, add_suffix = False)\n",
    "    df_feature_500 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 500, add_suffix = True)\n",
    "    df_feature_400 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 400, add_suffix = True)\n",
    "    df_feature_300 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 300, add_suffix = True)\n",
    "    df_feature_200 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 200, add_suffix = True)\n",
    "    df_feature_100 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 100, add_suffix = True)\n",
    "\n",
    "    # Merge all\n",
    "    df_feature = df_feature.merge(df_feature_500, how = 'left', left_on = 'time_id_', right_on = 'time_id__500')\n",
    "    df_feature = df_feature.merge(df_feature_400, how = 'left', left_on = 'time_id_', right_on = 'time_id__400')\n",
    "    df_feature = df_feature.merge(df_feature_300, how = 'left', left_on = 'time_id_', right_on = 'time_id__300')\n",
    "    df_feature = df_feature.merge(df_feature_200, how = 'left', left_on = 'time_id_', right_on = 'time_id__200')\n",
    "    df_feature = df_feature.merge(df_feature_100, how = 'left', left_on = 'time_id_', right_on = 'time_id__100')\n",
    "    # Drop unnecesary time_ids\n",
    "    df_feature.drop(['time_id__500','time_id__400', 'time_id__300', 'time_id__200','time_id__100'], axis = 1, inplace = True)\n",
    "    \n",
    "    \n",
    "    # Create row_id so we can merge\n",
    "    stock_id = file_path.split('=')[1]\n",
    "    df_feature['row_id'] = df_feature['time_id_'].apply(lambda x: f'{stock_id}-{x}')\n",
    "    df_feature.drop(['time_id_'], axis = 1, inplace = True)\n",
    "    return df_feature\n",
    "\n",
    "# Function to preprocess trade data (for each stock id)\n",
    "def trade_preprocessor(file_path):\n",
    "    df = pd.read_parquet(file_path)\n",
    "    df['log_return'] = df.groupby('time_id')['price'].apply(log_return)\n",
    "    df['amount']=df['price']*df['size']\n",
    "    # Dict for aggregations\n",
    "    create_feature_dict = {\n",
    "        'log_return':[realized_volatility],\n",
    "        'seconds_in_bucket':[count_unique],\n",
    "        'size':[np.sum, np.max, np.min],\n",
    "        'order_count':[np.sum,np.max],\n",
    "        'amount':[np.sum,np.max,np.min],\n",
    "    }\n",
    "    create_feature_dict_time = {\n",
    "        'log_return':[realized_volatility],\n",
    "        'seconds_in_bucket':[count_unique],\n",
    "        'size':[np.sum],\n",
    "        'order_count':[np.sum],\n",
    "    }\n",
    "    # Function to get group stats for different windows (seconds in bucket)\n",
    "    def get_stats_window(fe_dict,seconds_in_bucket, add_suffix = False):\n",
    "        # Group by the window\n",
    "        df_feature = df[df['seconds_in_bucket'] >= seconds_in_bucket].groupby(['time_id']).agg(fe_dict).reset_index()\n",
    "        # Rename columns joining suffix\n",
    "        df_feature.columns = ['_'.join(col) for col in df_feature.columns]\n",
    "        # Add a suffix to differentiate windows\n",
    "        if add_suffix:\n",
    "            df_feature = df_feature.add_suffix('_' + str(seconds_in_bucket))\n",
    "        return df_feature\n",
    "    \n",
    "\n",
    "    # Get the stats for different windows\n",
    "    df_feature = get_stats_window(create_feature_dict,seconds_in_bucket = 0, add_suffix = False)\n",
    "    df_feature_500 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 500, add_suffix = True)\n",
    "    df_feature_400 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 400, add_suffix = True)\n",
    "    df_feature_300 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 300, add_suffix = True)\n",
    "    df_feature_200 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 200, add_suffix = True)\n",
    "    df_feature_100 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 100, add_suffix = True)\n",
    "    \n",
    "    def tendency(price, vol):    \n",
    "        df_diff = np.diff(price)\n",
    "        val = (df_diff/price[1:])*100\n",
    "        power = np.sum(val*vol[1:])\n",
    "        return(power)\n",
    "    \n",
    "    lis = []\n",
    "    for n_time_id in df['time_id'].unique():\n",
    "        df_id = df[df['time_id'] == n_time_id]        \n",
    "        tendencyV = tendency(df_id['price'].values, df_id['size'].values)      \n",
    "        f_max = np.sum(df_id['price'].values > np.mean(df_id['price'].values))\n",
    "        f_min = np.sum(df_id['price'].values < np.mean(df_id['price'].values))\n",
    "        df_max =  np.sum(np.diff(df_id['price'].values) > 0)\n",
    "        df_min =  np.sum(np.diff(df_id['price'].values) < 0)\n",
    "        # new\n",
    "        abs_diff = np.median(np.abs( df_id['price'].values - np.mean(df_id['price'].values)))        \n",
    "        energy = np.mean(df_id['price'].values**2)\n",
    "        iqr_p = np.percentile(df_id['price'].values,75) - np.percentile(df_id['price'].values,25)\n",
    "        \n",
    "        # vol vars\n",
    "        \n",
    "        abs_diff_v = np.median(np.abs( df_id['size'].values - np.mean(df_id['size'].values)))        \n",
    "        energy_v = np.sum(df_id['size'].values**2)\n",
    "        iqr_p_v = np.percentile(df_id['size'].values,75) - np.percentile(df_id['size'].values,25)\n",
    "        \n",
    "        lis.append({'time_id':n_time_id,'tendency':tendencyV,'f_max':f_max,'f_min':f_min,'df_max':df_max,'df_min':df_min,\n",
    "                   'abs_diff':abs_diff,'energy':energy,'iqr_p':iqr_p,'abs_diff_v':abs_diff_v,'energy_v':energy_v,'iqr_p_v':iqr_p_v})\n",
    "    \n",
    "    df_lr = pd.DataFrame(lis)\n",
    "        \n",
    "   \n",
    "    df_feature = df_feature.merge(df_lr, how = 'left', left_on = 'time_id_', right_on = 'time_id')\n",
    "    \n",
    "    # Merge all\n",
    "    df_feature = df_feature.merge(df_feature_500, how = 'left', left_on = 'time_id_', right_on = 'time_id__500')\n",
    "    df_feature = df_feature.merge(df_feature_400, how = 'left', left_on = 'time_id_', right_on = 'time_id__400')\n",
    "    df_feature = df_feature.merge(df_feature_300, how = 'left', left_on = 'time_id_', right_on = 'time_id__300')\n",
    "    df_feature = df_feature.merge(df_feature_200, how = 'left', left_on = 'time_id_', right_on = 'time_id__200')\n",
    "    df_feature = df_feature.merge(df_feature_100, how = 'left', left_on = 'time_id_', right_on = 'time_id__100')\n",
    "    # Drop unnecesary time_ids\n",
    "    df_feature.drop(['time_id__500','time_id__400', 'time_id__300', 'time_id__200','time_id','time_id__100'], axis = 1, inplace = True)\n",
    "    \n",
    "    \n",
    "    df_feature = df_feature.add_prefix('trade_')\n",
    "    stock_id = file_path.split('=')[1]\n",
    "    df_feature['row_id'] = df_feature['trade_time_id_'].apply(lambda x:f'{stock_id}-{x}')\n",
    "    df_feature.drop(['trade_time_id_'], axis = 1, inplace = True)\n",
    "    return df_feature\n",
    "\n",
    "# Function to get group stats for the stock_id and time_id\n",
    "def get_time_stock(df):\n",
    "    vol_cols = ['log_return1_realized_volatility', 'log_return2_realized_volatility', 'log_return1_realized_volatility_400', 'log_return2_realized_volatility_400', \n",
    "                'log_return1_realized_volatility_300', 'log_return2_realized_volatility_300', 'log_return1_realized_volatility_200', 'log_return2_realized_volatility_200', \n",
    "                'trade_log_return_realized_volatility', 'trade_log_return_realized_volatility_400', 'trade_log_return_realized_volatility_300', 'trade_log_return_realized_volatility_200']\n",
    "\n",
    "\n",
    "    # Group by the stock id\n",
    "    df_stock_id = df.groupby(['stock_id'])[vol_cols].agg(['mean', 'std', 'max', 'min', ]).reset_index()\n",
    "    # Rename columns joining suffix\n",
    "    df_stock_id.columns = ['_'.join(col) for col in df_stock_id.columns]\n",
    "    df_stock_id = df_stock_id.add_suffix('_' + 'stock')\n",
    "\n",
    "    # Group by the stock id\n",
    "    df_time_id = df.groupby(['time_id'])[vol_cols].agg(['mean', 'std', 'max', 'min', ]).reset_index()\n",
    "    # Rename columns joining suffix\n",
    "    df_time_id.columns = ['_'.join(col) for col in df_time_id.columns]\n",
    "    df_time_id = df_time_id.add_suffix('_' + 'time')\n",
    "    \n",
    "    # Merge with original dataframe\n",
    "    df = df.merge(df_stock_id, how = 'left', left_on = ['stock_id'], right_on = ['stock_id__stock'])\n",
    "    df = df.merge(df_time_id, how = 'left', left_on = ['time_id'], right_on = ['time_id__time'])\n",
    "    df.drop(['stock_id__stock', 'time_id__time'], axis = 1, inplace = True)\n",
    "    return df\n",
    "    \n",
    "# Funtion to make preprocessing function in parallel (for each stock id)\n",
    "def preprocessor(list_stock_ids, is_train = True):\n",
    "    \n",
    "    # Parrallel for loop\n",
    "    def for_joblib(stock_id):\n",
    "        # Train\n",
    "        if is_train:\n",
    "            file_path_book = data_dir + \"book_train.parquet/stock_id=\" + str(stock_id)\n",
    "            file_path_trade = data_dir + \"trade_train.parquet/stock_id=\" + str(stock_id)\n",
    "        # Test\n",
    "        else:\n",
    "            file_path_book = data_dir + \"book_test.parquet/stock_id=\" + str(stock_id)\n",
    "            file_path_trade = data_dir + \"trade_test.parquet/stock_id=\" + str(stock_id)\n",
    "    \n",
    "        # Preprocess book and trade data and merge them\n",
    "        df_tmp = pd.merge(book_preprocessor(file_path_book), trade_preprocessor(file_path_trade), on = 'row_id', how = 'left')\n",
    "        \n",
    "        # Return the merge dataframe\n",
    "        return df_tmp\n",
    "    \n",
    "    # Use parallel api to call paralle for loop\n",
    "    df = Parallel(n_jobs = -1, verbose = 1)(delayed(for_joblib)(stock_id) for stock_id in list_stock_ids)\n",
    "    # Concatenate all the dataframes that return from Parallel\n",
    "    df = pd.concat(df, ignore_index = True)\n",
    "    return df\n",
    "\n",
    "# Function to calculate the root mean squared percentage error\n",
    "def rmspe(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square((y_true - y_pred) / y_true)))\n",
    "\n",
    "# Function to early stop with root mean squared percentage error\n",
    "def feval_rmspe(y_pred, lgb_train):\n",
    "    y_true = lgb_train.get_label()\n",
    "    return 'RMSPE', rmspe(y_true, y_pred), False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "derived-entrepreneur",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-26T13:35:47.733287Z",
     "iopub.status.busy": "2021-09-26T13:35:47.732639Z",
     "iopub.status.idle": "2021-09-26T13:35:53.077644Z",
     "shell.execute_reply": "2021-09-26T13:35:53.077132Z"
    },
    "papermill": {
     "duration": 11.508109,
     "end_time": "2021-09-26T13:35:53.077846",
     "exception": false,
     "start_time": "2021-09-26T13:35:41.569737",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.3s finished\n"
     ]
    }
   ],
   "source": [
    "# Read train and test\n",
    "train =pd.read_pickle(\"../input/myoptivertrainpkl/train.pkl\")\n",
    "test = read_train_test()\n",
    "\n",
    "# Get unique stock ids \n",
    "#train_stock_ids = train['stock_id'].unique()\n",
    "# Preprocess them using Parallel and our single stock id functions\n",
    "#train_ = preprocessor(train_stock_ids, is_train = True)\n",
    "#train = train.merge(train_, on = ['row_id'], how = 'left')\n",
    "\n",
    "# Get unique stock ids \n",
    "test_stock_ids = test['stock_id'].unique()\n",
    "# Preprocess them using Parallel and our single stock id functions\n",
    "test_ = preprocessor(test_stock_ids, is_train = False)\n",
    "test = test.merge(test_, on = ['row_id'], how = 'left')\n",
    "\n",
    "# Get group stats of time_id and stock_id\n",
    "#train = get_time_stock(train)\n",
    "test = get_time_stock(test)\n",
    "\n",
    "train1=train\n",
    "test1=test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "geological-child",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-26T13:36:05.502846Z",
     "iopub.status.busy": "2021-09-26T13:36:05.501487Z",
     "iopub.status.idle": "2021-09-26T13:36:05.542317Z",
     "shell.execute_reply": "2021-09-26T13:36:05.541759Z"
    },
    "papermill": {
     "duration": 6.244774,
     "end_time": "2021-09-26T13:36:05.542460",
     "exception": false,
     "start_time": "2021-09-26T13:35:59.297686",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "194"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace by order sum (tau)\n",
    "train['size_tau'] = np.sqrt( 1/ train['trade_seconds_in_bucket_count_unique'] )\n",
    "test['size_tau'] = np.sqrt( 1/ test['trade_seconds_in_bucket_count_unique'] )\n",
    "#train['size_tau_450'] = np.sqrt( 1/ train['trade_seconds_in_bucket_count_unique_450'] )\n",
    "#test['size_tau_450'] = np.sqrt( 1/ test['trade_seconds_in_bucket_count_unique_450'] )\n",
    "train['size_tau_400'] = np.sqrt( 1/ train['trade_seconds_in_bucket_count_unique_400'] )\n",
    "test['size_tau_400'] = np.sqrt( 1/ test['trade_seconds_in_bucket_count_unique_400'] )\n",
    "train['size_tau_300'] = np.sqrt( 1/ train['trade_seconds_in_bucket_count_unique_300'] )\n",
    "test['size_tau_300'] = np.sqrt( 1/ test['trade_seconds_in_bucket_count_unique_300'] )\n",
    "#train['size_tau_150'] = np.sqrt( 1/ train['trade_seconds_in_bucket_count_unique_150'] )\n",
    "#test['size_tau_150'] = np.sqrt( 1/ test['trade_seconds_in_bucket_count_unique_150'] )\n",
    "train['size_tau_200'] = np.sqrt( 1/ train['trade_seconds_in_bucket_count_unique_200'] )\n",
    "test['size_tau_200'] = np.sqrt( 1/ test['trade_seconds_in_bucket_count_unique_200'] )\n",
    "\n",
    "train['size_tau2'] = np.sqrt( 1/ train['trade_order_count_sum'] )\n",
    "test['size_tau2'] = np.sqrt( 1/ test['trade_order_count_sum'] )\n",
    "#train['size_tau2_450'] = np.sqrt( 0.25/ train['trade_order_count_sum'] )\n",
    "#test['size_tau2_450'] = np.sqrt( 0.25/ test['trade_order_count_sum'] )\n",
    "train['size_tau2_400'] = np.sqrt( 0.33/ train['trade_order_count_sum'] )\n",
    "test['size_tau2_400'] = np.sqrt( 0.33/ test['trade_order_count_sum'] )\n",
    "train['size_tau2_300'] = np.sqrt( 0.5/ train['trade_order_count_sum'] )\n",
    "test['size_tau2_300'] = np.sqrt( 0.5/ test['trade_order_count_sum'] )\n",
    "#train['size_tau2_150'] = np.sqrt( 0.75/ train['trade_order_count_sum'] )\n",
    "#test['size_tau2_150'] = np.sqrt( 0.75/ test['trade_order_count_sum'] )\n",
    "train['size_tau2_200'] = np.sqrt( 0.66/ train['trade_order_count_sum'] )\n",
    "test['size_tau2_200'] = np.sqrt( 0.66/ test['trade_order_count_sum'] )\n",
    "\n",
    "# delta tau\n",
    "train['size_tau2_d'] = train['size_tau2_400'] - train['size_tau2']\n",
    "test['size_tau2_d'] = test['size_tau2_400'] - test['size_tau2']\n",
    "\n",
    "colNames = [col for col in list(train.columns)\n",
    "            if col not in {\"stock_id\", \"time_id\", \"target\", \"row_id\"}]\n",
    "len(colNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "annual-windsor",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-26T13:36:17.953634Z",
     "iopub.status.busy": "2021-09-26T13:36:17.952937Z",
     "iopub.status.idle": "2021-09-26T13:36:19.787837Z",
     "shell.execute_reply": "2021-09-26T13:36:19.787145Z"
    },
    "papermill": {
     "duration": 8.05749,
     "end_time": "2021-09-26T13:36:19.787982",
     "exception": false,
     "start_time": "2021-09-26T13:36:11.730492",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 4 3 1 3 0 1 3 5 1 0 4 3 3 3 3 3 1 3 3 6 0 0 3 6 3 0 3 6 3 6 3 3 0 4 6 3\n",
      " 6 3 3 3 0 3 3 0 4 3 3 3 4 0 6 6 6 1 4 1 3 0 3 3 0 3 0 0 6 4 0 6 4 5 2 6 4\n",
      " 4 3 4 0 6 4 4 3 0 0 4 4 6 6 3 4 0 3 3 3 3 6 0 6 6 0 0 3 0 0 3 3 0 0 3 4 3\n",
      " 4]\n",
      "[5, 10, 22, 23, 29, 36, 44, 48, 56, 66, 69, 72, 73, 76, 87, 94, 95, 102, 109, 112, 113, 115, 116, 120, 122]\n",
      "[3, 6, 9, 18, 61, 63]\n",
      "[81]\n",
      "[0, 2, 4, 7, 13, 14, 15, 16, 17, 19, 20, 26, 28, 30, 32, 34, 35, 39, 41, 42, 43, 46, 47, 51, 52, 53, 64, 67, 68, 70, 85, 93, 100, 103, 104, 105, 107, 114, 118, 119, 123, 125]\n",
      "[1, 11, 37, 50, 55, 62, 75, 78, 83, 84, 86, 89, 90, 96, 97, 101, 124, 126]\n",
      "[8, 80]\n",
      "[21, 27, 31, 33, 38, 40, 58, 59, 60, 74, 77, 82, 88, 98, 99, 108, 110, 111]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "# making agg features\n",
    "\n",
    "train_p = pd.read_csv('../input/optiver-realized-volatility-prediction/train.csv')\n",
    "train_p = train_p.pivot(index='time_id', columns='stock_id', values='target')\n",
    "\n",
    "corr = train_p.corr()\n",
    "\n",
    "ids = corr.index\n",
    "\n",
    "kmeans = KMeans(n_clusters=7, random_state=0).fit(corr.values)\n",
    "print(kmeans.labels_)\n",
    "\n",
    "l = []\n",
    "for n in range(7):\n",
    "    l.append ( [ (x-1) for x in ( (ids+1)*(kmeans.labels_ == n)) if x > 0] )\n",
    "    \n",
    "\n",
    "mat = []\n",
    "matTest = []\n",
    "\n",
    "n = 0\n",
    "for ind in l:\n",
    "    print(ind)\n",
    "    newDf = train.loc[train['stock_id'].isin(ind) ]\n",
    "    newDf = newDf.groupby(['time_id']).agg(np.nanmean)\n",
    "    newDf.loc[:,'stock_id'] = str(n)+'c1'\n",
    "    mat.append ( newDf )\n",
    "    \n",
    "    newDf = test.loc[test['stock_id'].isin(ind) ]    \n",
    "    newDf = newDf.groupby(['time_id']).agg(np.nanmean)\n",
    "    newDf.loc[:,'stock_id'] = str(n)+'c1'\n",
    "    matTest.append ( newDf )\n",
    "    \n",
    "    n+=1\n",
    "    \n",
    "mat1 = pd.concat(mat).reset_index()\n",
    "mat1.drop(columns=['target'],inplace=True)\n",
    "\n",
    "mat2 = pd.concat(matTest).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "african-research",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-26T13:36:32.220833Z",
     "iopub.status.busy": "2021-09-26T13:36:32.220166Z",
     "iopub.status.idle": "2021-09-26T13:36:32.422349Z",
     "shell.execute_reply": "2021-09-26T13:36:32.422832Z"
    },
    "papermill": {
     "duration": 6.375541,
     "end_time": "2021-09-26T13:36:32.423017",
     "exception": false,
     "start_time": "2021-09-26T13:36:26.047476",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mat2 = pd.concat([mat2,mat1.loc[mat1.time_id==5]])\n",
    "mat1 = mat1.pivot(index='time_id', columns='stock_id')\n",
    "mat1.columns = [\"_\".join(x) for x in mat1.columns.ravel()]\n",
    "mat1.reset_index(inplace=True)\n",
    "\n",
    "mat2 = mat2.pivot(index='time_id', columns='stock_id')\n",
    "mat2.columns = [\"_\".join(x) for x in mat2.columns.ravel()]\n",
    "mat2.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "boxed-radius",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-26T13:36:44.911782Z",
     "iopub.status.busy": "2021-09-26T13:36:44.911107Z",
     "iopub.status.idle": "2021-09-26T13:36:50.520315Z",
     "shell.execute_reply": "2021-09-26T13:36:50.520845Z"
    },
    "papermill": {
     "duration": 11.807579,
     "end_time": "2021-09-26T13:36:50.521067",
     "exception": false,
     "start_time": "2021-09-26T13:36:38.713488",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nnn = ['time_id',\n",
    "     'log_return1_realized_volatility_0c1',\n",
    "     'log_return1_realized_volatility_1c1',     \n",
    "     'log_return1_realized_volatility_3c1',\n",
    "     'log_return1_realized_volatility_4c1',     \n",
    "     'log_return1_realized_volatility_6c1',\n",
    "     'total_volume_sum_0c1',\n",
    "     'total_volume_sum_1c1', \n",
    "     'total_volume_sum_3c1',\n",
    "     'total_volume_sum_4c1', \n",
    "     'total_volume_sum_6c1',\n",
    "     'trade_size_sum_0c1',\n",
    "     'trade_size_sum_1c1', \n",
    "     'trade_size_sum_3c1',\n",
    "     'trade_size_sum_4c1', \n",
    "     'trade_size_sum_6c1',\n",
    "     'trade_order_count_sum_0c1',\n",
    "     'trade_order_count_sum_1c1',\n",
    "     'trade_order_count_sum_3c1',\n",
    "     'trade_order_count_sum_4c1',\n",
    "     'trade_order_count_sum_6c1',      \n",
    "     'price_spread_sum_0c1',\n",
    "     'price_spread_sum_1c1',\n",
    "     'price_spread_sum_3c1',\n",
    "     'price_spread_sum_4c1',\n",
    "     'price_spread_sum_6c1',   \n",
    "     'bid_spread_sum_0c1',\n",
    "     'bid_spread_sum_1c1',\n",
    "     'bid_spread_sum_3c1',\n",
    "     'bid_spread_sum_4c1',\n",
    "     'bid_spread_sum_6c1',       \n",
    "     'ask_spread_sum_0c1',\n",
    "     'ask_spread_sum_1c1',\n",
    "     'ask_spread_sum_3c1',\n",
    "     'ask_spread_sum_4c1',\n",
    "     'ask_spread_sum_6c1',   \n",
    "     'volume_imbalance_sum_0c1',\n",
    "     'volume_imbalance_sum_1c1',\n",
    "     'volume_imbalance_sum_3c1',\n",
    "     'volume_imbalance_sum_4c1',\n",
    "     'volume_imbalance_sum_6c1',       \n",
    "     'bid_ask_spread_sum_0c1',\n",
    "     'bid_ask_spread_sum_1c1',\n",
    "     'bid_ask_spread_sum_3c1',\n",
    "     'bid_ask_spread_sum_4c1',\n",
    "     'bid_ask_spread_sum_6c1',\n",
    "     'size_tau2_0c1',\n",
    "     'size_tau2_1c1',\n",
    "     'size_tau2_3c1',\n",
    "     'size_tau2_4c1',\n",
    "     'size_tau2_6c1'] \n",
    "train = pd.merge(train,mat1[nnn],how='left',on='time_id')\n",
    "test = pd.merge(test,mat2[nnn],how='left',on='time_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "radio-sugar",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-26T13:37:02.992953Z",
     "iopub.status.busy": "2021-09-26T13:37:02.992296Z",
     "iopub.status.idle": "2021-09-26T13:37:03.211765Z",
     "shell.execute_reply": "2021-09-26T13:37:03.211210Z"
    },
    "papermill": {
     "duration": 6.444789,
     "end_time": "2021-09-26T13:37:03.211920",
     "exception": false,
     "start_time": "2021-09-26T13:36:56.767131",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6428"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "del mat1,mat2\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "nutritional-vision",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-26T13:37:15.729926Z",
     "iopub.status.busy": "2021-09-26T13:37:15.729217Z",
     "iopub.status.idle": "2021-09-26T13:48:01.779827Z",
     "shell.execute_reply": "2021-09-26T13:48:01.779221Z"
    },
    "papermill": {
     "duration": 652.371467,
     "end_time": "2021-09-26T13:48:01.779981",
     "exception": false,
     "start_time": "2021-09-26T13:37:09.408514",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[250]\ttraining's rmse: 0.000429065\ttraining's RMSPE: 0.198434\tvalid_1's rmse: 0.000440289\tvalid_1's RMSPE: 0.204357\n",
      "[500]\ttraining's rmse: 0.000407399\ttraining's RMSPE: 0.188414\tvalid_1's rmse: 0.000425992\tvalid_1's RMSPE: 0.197722\n",
      "[750]\ttraining's rmse: 0.000393717\ttraining's RMSPE: 0.182086\tvalid_1's rmse: 0.000418483\tvalid_1's RMSPE: 0.194236\n",
      "[1000]\ttraining's rmse: 0.00038396\ttraining's RMSPE: 0.177574\tvalid_1's rmse: 0.000414271\tvalid_1's RMSPE: 0.192281\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's rmse: 0.00038396\ttraining's RMSPE: 0.177574\tvalid_1's rmse: 0.000414271\tvalid_1's RMSPE: 0.192281\n",
      "Training fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[250]\ttraining's rmse: 0.000429401\ttraining's RMSPE: 0.198936\tvalid_1's rmse: 0.000441304\tvalid_1's RMSPE: 0.2034\n",
      "[500]\ttraining's rmse: 0.00040727\ttraining's RMSPE: 0.188683\tvalid_1's rmse: 0.000426268\tvalid_1's RMSPE: 0.19647\n",
      "[750]\ttraining's rmse: 0.000393333\ttraining's RMSPE: 0.182226\tvalid_1's rmse: 0.000418455\tvalid_1's RMSPE: 0.192869\n",
      "[1000]\ttraining's rmse: 0.000383456\ttraining's RMSPE: 0.17765\tvalid_1's rmse: 0.000414175\tvalid_1's RMSPE: 0.190896\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's rmse: 0.000383456\ttraining's RMSPE: 0.17765\tvalid_1's rmse: 0.000414175\tvalid_1's RMSPE: 0.190896\n",
      "Training fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[250]\ttraining's rmse: 0.000429318\ttraining's RMSPE: 0.198544\tvalid_1's rmse: 0.000465573\tvalid_1's RMSPE: 0.216123\n",
      "[500]\ttraining's rmse: 0.000406625\ttraining's RMSPE: 0.188049\tvalid_1's rmse: 0.000451835\tvalid_1's RMSPE: 0.209745\n",
      "[750]\ttraining's rmse: 0.000393171\ttraining's RMSPE: 0.181827\tvalid_1's rmse: 0.000444119\tvalid_1's RMSPE: 0.206164\n",
      "[1000]\ttraining's rmse: 0.000383317\ttraining's RMSPE: 0.17727\tvalid_1's rmse: 0.000439955\tvalid_1's RMSPE: 0.20423\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's rmse: 0.000383317\ttraining's RMSPE: 0.17727\tvalid_1's rmse: 0.000439955\tvalid_1's RMSPE: 0.20423\n",
      "Training fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[250]\ttraining's rmse: 0.000428637\ttraining's RMSPE: 0.198583\tvalid_1's rmse: 0.00044605\tvalid_1's RMSPE: 0.205586\n",
      "[500]\ttraining's rmse: 0.000406552\ttraining's RMSPE: 0.188351\tvalid_1's rmse: 0.000430184\tvalid_1's RMSPE: 0.198273\n",
      "[750]\ttraining's rmse: 0.000393049\ttraining's RMSPE: 0.182095\tvalid_1's rmse: 0.000422662\tvalid_1's RMSPE: 0.194806\n",
      "[1000]\ttraining's rmse: 0.000382821\ttraining's RMSPE: 0.177357\tvalid_1's rmse: 0.000417645\tvalid_1's RMSPE: 0.192494\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's rmse: 0.000382821\ttraining's RMSPE: 0.177357\tvalid_1's rmse: 0.000417645\tvalid_1's RMSPE: 0.192494\n",
      "Training fold 5\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[250]\ttraining's rmse: 0.000430159\ttraining's RMSPE: 0.198967\tvalid_1's rmse: 0.000442537\tvalid_1's RMSPE: 0.205288\n",
      "[500]\ttraining's rmse: 0.000408487\ttraining's RMSPE: 0.188943\tvalid_1's rmse: 0.000428422\tvalid_1's RMSPE: 0.19874\n",
      "[750]\ttraining's rmse: 0.000394577\ttraining's RMSPE: 0.182509\tvalid_1's rmse: 0.000420492\tvalid_1's RMSPE: 0.195061\n",
      "[1000]\ttraining's rmse: 0.000384383\ttraining's RMSPE: 0.177794\tvalid_1's rmse: 0.00041605\tvalid_1's RMSPE: 0.193001\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's rmse: 0.000384383\ttraining's RMSPE: 0.177794\tvalid_1's rmse: 0.00041605\tvalid_1's RMSPE: 0.193001\n",
      "Our out of folds RMSPE is 0.19464154422521382\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x648 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgb\n",
    "\n",
    "seed0=2021\n",
    "params0 = {\n",
    "    'objective': 'rmse',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'max_depth': -1,\n",
    "    'max_bin':100,\n",
    "    'min_data_in_leaf':500,\n",
    "    'learning_rate': 0.05,\n",
    "    'subsample': 0.72,\n",
    "    'subsample_freq': 4,\n",
    "    'feature_fraction': 0.5,\n",
    "    'lambda_l1': 0.5,\n",
    "    'lambda_l2': 1.0,\n",
    "    'categorical_column':[0],\n",
    "    'seed':seed0,\n",
    "    'feature_fraction_seed': seed0,\n",
    "    'bagging_seed': seed0,\n",
    "    'drop_seed': seed0,\n",
    "    'data_random_seed': seed0,\n",
    "    'n_jobs':-1,\n",
    "    'verbose': -1}\n",
    "seed1=42\n",
    "params1 = {\n",
    "        'learning_rate': 0.1,        \n",
    "        'lambda_l1': 2,\n",
    "        'lambda_l2': 7,\n",
    "        'num_leaves': 800,\n",
    "        'min_sum_hessian_in_leaf': 20,\n",
    "        'feature_fraction': 0.8,\n",
    "        'feature_fraction_bynode': 0.8,\n",
    "        'bagging_fraction': 0.9,\n",
    "        'bagging_freq': 42,\n",
    "        'min_data_in_leaf': 700,\n",
    "        'max_depth': 4,\n",
    "        'categorical_column':[0],\n",
    "        'seed': seed1,\n",
    "        'feature_fraction_seed': seed1,\n",
    "        'bagging_seed': seed1,\n",
    "        'drop_seed': seed1,\n",
    "        'data_random_seed': seed1,\n",
    "        'objective': 'rmse',\n",
    "        'boosting': 'gbdt',\n",
    "        'verbosity': -1,\n",
    "        'n_jobs':-1,\n",
    "    }\n",
    "# Function to early stop with root mean squared percentage error\n",
    "def rmspe(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square((y_true - y_pred) / y_true)))\n",
    "\n",
    "def feval_rmspe(y_pred, lgb_train):\n",
    "    y_true = lgb_train.get_label()\n",
    "    return 'RMSPE', rmspe(y_true, y_pred), False\n",
    "\n",
    "def train_and_evaluate_lgb(train, test, params):\n",
    "    # Hyperparammeters (just basic)\n",
    "    \n",
    "    features = [col for col in train.columns if col not in {\"time_id\", \"target\", \"row_id\"}]\n",
    "    y = train['target']\n",
    "    # Create out of folds array\n",
    "    oof_predictions = np.zeros(train.shape[0])\n",
    "    # Create test array to store predictions\n",
    "    test_predictions = np.zeros(test.shape[0])\n",
    "    # Create a KFold object\n",
    "    kfold = KFold(n_splits = 5, random_state = 2021, shuffle = True)\n",
    "    # Iterate through each fold\n",
    "    for fold, (trn_ind, val_ind) in enumerate(kfold.split(train)):\n",
    "        print(f'Training fold {fold + 1}')\n",
    "        x_train, x_val = train.iloc[trn_ind], train.iloc[val_ind]\n",
    "        y_train, y_val = y.iloc[trn_ind], y.iloc[val_ind]\n",
    "        # Root mean squared percentage error weights\n",
    "        train_weights = 1 / np.square(y_train)\n",
    "        val_weights = 1 / np.square(y_val)\n",
    "        train_dataset = lgb.Dataset(x_train[features], y_train, weight = train_weights)\n",
    "        val_dataset = lgb.Dataset(x_val[features], y_val, weight = val_weights)\n",
    "        model = lgb.train(params = params,\n",
    "                          num_boost_round=1000,\n",
    "                          train_set = train_dataset, \n",
    "                          valid_sets = [train_dataset, val_dataset], \n",
    "                          verbose_eval = 250,\n",
    "                          early_stopping_rounds=50,\n",
    "                          feval = feval_rmspe)\n",
    "        joblib.load('../input/optiverbestpublicmodel/'+f'model_lgbm_1_fold{fold}.pkl')\n",
    "        # Add predictions to the out of folds array\n",
    "        oof_predictions[val_ind] = model.predict(x_val[features])\n",
    "        \n",
    "        # Predict the test set\n",
    "        test_predictions += model.predict(test[features]) / 5\n",
    "    rmspe_score = rmspe(y, oof_predictions)\n",
    "    print(f'Our out of folds RMSPE is {rmspe_score}')\n",
    "    lgb.plot_importance(model,max_num_features=20)\n",
    "    # Return test predictions\n",
    "    return test_predictions\n",
    "# Traing and evaluate\n",
    "predictions_lgb1= train_and_evaluate_lgb(train, test,params0)\n",
    "#test['target'] = predictions_lgb\n",
    "#test[['row_id', 'target']].to_csv('submission.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "covered-outdoors",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-26T13:48:14.407276Z",
     "iopub.status.busy": "2021-09-26T13:48:14.400837Z",
     "iopub.status.idle": "2021-09-26T14:00:57.772501Z",
     "shell.execute_reply": "2021-09-26T14:00:57.772987Z"
    },
    "papermill": {
     "duration": 769.624283,
     "end_time": "2021-09-26T14:00:57.773176",
     "exception": false,
     "start_time": "2021-09-26T13:48:08.148893",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[250]\ttraining's rmse: 0.000428825\ttraining's RMSPE: 0.198537\tvalid_1's rmse: 0.000446665\tvalid_1's RMSPE: 0.206425\n",
      "[500]\ttraining's rmse: 0.000407092\ttraining's RMSPE: 0.188475\tvalid_1's rmse: 0.000432202\tvalid_1's RMSPE: 0.199741\n",
      "[750]\ttraining's rmse: 0.000393568\ttraining's RMSPE: 0.182214\tvalid_1's rmse: 0.000424467\tvalid_1's RMSPE: 0.196166\n",
      "[1000]\ttraining's rmse: 0.000383016\ttraining's RMSPE: 0.177328\tvalid_1's rmse: 0.000419386\tvalid_1's RMSPE: 0.193818\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\ttraining's rmse: 0.000376355\ttraining's RMSPE: 0.174245\tvalid_1's rmse: 0.000416756\tvalid_1's RMSPE: 0.192603\n",
      "Training fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[250]\ttraining's rmse: 0.000430406\ttraining's RMSPE: 0.199062\tvalid_1's rmse: 0.000459081\tvalid_1's RMSPE: 0.213045\n",
      "[500]\ttraining's rmse: 0.000408263\ttraining's RMSPE: 0.188821\tvalid_1's rmse: 0.000444695\tvalid_1's RMSPE: 0.206369\n",
      "[750]\ttraining's rmse: 0.000394906\ttraining's RMSPE: 0.182644\tvalid_1's rmse: 0.000436569\tvalid_1's RMSPE: 0.202598\n",
      "[1000]\ttraining's rmse: 0.0003845\ttraining's RMSPE: 0.177831\tvalid_1's rmse: 0.000431339\tvalid_1's RMSPE: 0.200171\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\ttraining's rmse: 0.000377905\ttraining's RMSPE: 0.17478\tvalid_1's rmse: 0.000428277\tvalid_1's RMSPE: 0.19875\n",
      "Training fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[250]\ttraining's rmse: 0.000428876\ttraining's RMSPE: 0.19858\tvalid_1's rmse: 0.000441603\tvalid_1's RMSPE: 0.204007\n",
      "[500]\ttraining's rmse: 0.000407087\ttraining's RMSPE: 0.188491\tvalid_1's rmse: 0.000426621\tvalid_1's RMSPE: 0.197086\n",
      "[750]\ttraining's rmse: 0.000393564\ttraining's RMSPE: 0.182229\tvalid_1's rmse: 0.00041884\tvalid_1's RMSPE: 0.193491\n",
      "[1000]\ttraining's rmse: 0.000383368\ttraining's RMSPE: 0.177509\tvalid_1's rmse: 0.000414079\tvalid_1's RMSPE: 0.191292\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\ttraining's rmse: 0.00037679\ttraining's RMSPE: 0.174462\tvalid_1's rmse: 0.000411389\tvalid_1's RMSPE: 0.190049\n",
      "Training fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[250]\ttraining's rmse: 0.000429302\ttraining's RMSPE: 0.198437\tvalid_1's rmse: 0.000443707\tvalid_1's RMSPE: 0.206381\n",
      "[500]\ttraining's rmse: 0.000407309\ttraining's RMSPE: 0.188271\tvalid_1's rmse: 0.000429729\tvalid_1's RMSPE: 0.19988\n",
      "[750]\ttraining's rmse: 0.000393641\ttraining's RMSPE: 0.181953\tvalid_1's rmse: 0.000423105\tvalid_1's RMSPE: 0.196799\n",
      "[1000]\ttraining's rmse: 0.000383684\ttraining's RMSPE: 0.177351\tvalid_1's rmse: 0.000418731\tvalid_1's RMSPE: 0.194764\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\ttraining's rmse: 0.000377118\ttraining's RMSPE: 0.174316\tvalid_1's rmse: 0.00041647\tvalid_1's RMSPE: 0.193712\n",
      "Training fold 5\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[250]\ttraining's rmse: 0.000428792\ttraining's RMSPE: 0.198673\tvalid_1's rmse: 0.000453021\tvalid_1's RMSPE: 0.208723\n",
      "[500]\ttraining's rmse: 0.000406875\ttraining's RMSPE: 0.188518\tvalid_1's rmse: 0.000439333\tvalid_1's RMSPE: 0.202416\n",
      "[750]\ttraining's rmse: 0.000393391\ttraining's RMSPE: 0.18227\tvalid_1's rmse: 0.000433969\tvalid_1's RMSPE: 0.199945\n",
      "[1000]\ttraining's rmse: 0.000383097\ttraining's RMSPE: 0.1775\tvalid_1's rmse: 0.00042977\tvalid_1's RMSPE: 0.198011\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\ttraining's rmse: 0.000376503\ttraining's RMSPE: 0.174445\tvalid_1's rmse: 0.000427344\tvalid_1's RMSPE: 0.196892\n",
      "Our out of folds RMSPE is 0.19442585162977183\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x648 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgb\n",
    "\n",
    "seed0=1111\n",
    "params111 = {\n",
    "    'objective': 'rmse',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'max_depth': -1,\n",
    "    'max_bin':100,\n",
    "    'min_data_in_leaf':500,\n",
    "    'learning_rate': 0.05,\n",
    "    'subsample': 0.72,\n",
    "    'subsample_freq': 4,\n",
    "    'feature_fraction': 0.5,\n",
    "    'lambda_l1': 0.5,\n",
    "    'lambda_l2': 1.0,\n",
    "    'categorical_column':[0],\n",
    "    'seed':seed0,\n",
    "    'feature_fraction_seed': seed0,\n",
    "    'bagging_seed': seed0,\n",
    "    'drop_seed': seed0,\n",
    "    'data_random_seed': seed0,\n",
    "    'n_jobs':-1,\n",
    "    'verbose': -1}\n",
    "seed1=42\n",
    "params1 = {\n",
    "        'learning_rate': 0.1,        \n",
    "        'lambda_l1': 2,\n",
    "        'lambda_l2': 7,\n",
    "        'num_leaves': 800,\n",
    "        'min_sum_hessian_in_leaf': 20,\n",
    "        'feature_fraction': 0.8,\n",
    "        'feature_fraction_bynode': 0.8,\n",
    "        'bagging_fraction': 0.9,\n",
    "        'bagging_freq': 42,\n",
    "        'min_data_in_leaf': 700,\n",
    "        'max_depth': 4,\n",
    "        'categorical_column':[0],\n",
    "        'seed': seed1,\n",
    "        'feature_fraction_seed': seed1,\n",
    "        'bagging_seed': seed1,\n",
    "        'drop_seed': seed1,\n",
    "        'data_random_seed': seed1,\n",
    "        'objective': 'rmse',\n",
    "        'boosting': 'gbdt',\n",
    "        'verbosity': -1,\n",
    "        'n_jobs':-1,\n",
    "    }\n",
    "# Function to early stop with root mean squared percentage error\n",
    "def rmspe(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square((y_true - y_pred) / y_true)))\n",
    "\n",
    "def feval_rmspe(y_pred, lgb_train):\n",
    "    y_true = lgb_train.get_label()\n",
    "    return 'RMSPE', rmspe(y_true, y_pred), False\n",
    "\n",
    "def train_and_evaluate_lgb(train, test, params):\n",
    "    # Hyperparammeters (just basic)\n",
    "    \n",
    "    features = [col for col in train.columns if col not in {\"time_id\", \"target\", \"row_id\"}]\n",
    "    y = train['target']\n",
    "    # Create out of folds array\n",
    "    oof_predictions = np.zeros(train.shape[0])\n",
    "    # Create test array to store predictions\n",
    "    test_predictions = np.zeros(test.shape[0])\n",
    "    # Create a KFold object\n",
    "    kfold = KFold(n_splits = 5, random_state = 1111, shuffle = True)\n",
    "    # Iterate through each fold\n",
    "    for fold, (trn_ind, val_ind) in enumerate(kfold.split(train)):\n",
    "        print(f'Training fold {fold + 1}')\n",
    "        x_train, x_val = train.iloc[trn_ind], train.iloc[val_ind]\n",
    "        y_train, y_val = y.iloc[trn_ind], y.iloc[val_ind]\n",
    "        # Root mean squared percentage error weights\n",
    "        train_weights = 1 / np.square(y_train)\n",
    "        val_weights = 1 / np.square(y_val)\n",
    "        train_dataset = lgb.Dataset(x_train[features], y_train, weight = train_weights)\n",
    "        val_dataset = lgb.Dataset(x_val[features], y_val, weight = val_weights)\n",
    "        model = lgb.train(params = params,\n",
    "                          num_boost_round=1200,\n",
    "                          train_set = train_dataset, \n",
    "                          valid_sets = [train_dataset, val_dataset], \n",
    "                          verbose_eval = 250,\n",
    "                          early_stopping_rounds=50,\n",
    "                          feval = feval_rmspe)\n",
    "        # Add predictions to the out of folds array\n",
    "        joblib.load('../input/optiverbestpublicmodel/'+f'model_lgbm_2_fold{fold}.pkl')\n",
    "        oof_predictions[val_ind] = model.predict(x_val[features])\n",
    "        # Predict the test set\n",
    "        test_predictions += model.predict(test[features]) / 5\n",
    "    rmspe_score = rmspe(y, oof_predictions)\n",
    "    print(f'Our out of folds RMSPE is {rmspe_score}')\n",
    "    lgb.plot_importance(model,max_num_features=20)\n",
    "    # Return test predictions\n",
    "    return test_predictions\n",
    "# Traing and evaluate\n",
    "predictions_lgb2= train_and_evaluate_lgb(train, test,params111)\n",
    "#test['target'] = predictions_lgb\n",
    "#test[['row_id', 'target']].to_csv('submission.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "governing-studio",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-26T14:01:10.382584Z",
     "iopub.status.busy": "2021-09-26T14:01:10.381786Z",
     "iopub.status.idle": "2021-09-26T14:01:22.143893Z",
     "shell.execute_reply": "2021-09-26T14:01:22.143353Z"
    },
    "papermill": {
     "duration": 18.085725,
     "end_time": "2021-09-26T14:01:22.144058",
     "exception": false,
     "start_time": "2021-09-26T14:01:04.058333",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(42)\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "def root_mean_squared_per_error(y_true, y_pred):\n",
    "         return K.sqrt(K.mean(K.square( (y_true - y_pred)/ y_true )))\n",
    "    \n",
    "es = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', patience=20, verbose=0,\n",
    "    mode='min',restore_best_weights=True)\n",
    "\n",
    "plateau = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=0.2, patience=7, verbose=0,\n",
    "    mode='min')\n",
    "# kfold based on the knn++ algorithm\n",
    "\n",
    "out_train = pd.read_csv('../input/optiver-realized-volatility-prediction/train.csv')\n",
    "out_train = out_train.pivot(index='time_id', columns='stock_id', values='target')\n",
    "\n",
    "#out_train[out_train.isna().any(axis=1)]\n",
    "out_train = out_train.fillna(out_train.mean())\n",
    "out_train.head()\n",
    "\n",
    "# code to add the just the read data after first execution\n",
    "\n",
    "# data separation based on knn ++\n",
    "nfolds = 5 # number of folds\n",
    "index = []\n",
    "totDist = []\n",
    "values = []\n",
    "# generates a matriz with the values of \n",
    "mat = out_train.values\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "mat = scaler.fit_transform(mat)\n",
    "\n",
    "nind = int(mat.shape[0]/nfolds) # number of individuals\n",
    "\n",
    "# adds index in the last column\n",
    "mat = np.c_[mat,np.arange(mat.shape[0])]\n",
    "\n",
    "\n",
    "lineNumber = np.random.choice(np.array(mat.shape[0]), size=nfolds, replace=False)\n",
    "\n",
    "lineNumber = np.sort(lineNumber)[::-1]\n",
    "\n",
    "for n in range(nfolds):\n",
    "    totDist.append(np.zeros(mat.shape[0]-nfolds))\n",
    "\n",
    "# saves index\n",
    "for n in range(nfolds):\n",
    "    \n",
    "    values.append([lineNumber[n]])    \n",
    "\n",
    "\n",
    "s=[]\n",
    "for n in range(nfolds):\n",
    "    s.append(mat[lineNumber[n],:])\n",
    "    \n",
    "    mat = np.delete(mat, obj=lineNumber[n], axis=0)\n",
    "\n",
    "for n in range(nind-1):    \n",
    "\n",
    "    luck = np.random.uniform(0,1,nfolds)\n",
    "    \n",
    "    for cycle in range(nfolds):\n",
    "         # saves the values of index           \n",
    "\n",
    "        s[cycle] = np.matlib.repmat(s[cycle], mat.shape[0], 1)\n",
    "\n",
    "        sumDist = np.sum( (mat[:,:-1] - s[cycle][:,:-1])**2 , axis=1)   \n",
    "        totDist[cycle] += sumDist        \n",
    "                \n",
    "        # probabilities\n",
    "        f = totDist[cycle]/np.sum(totDist[cycle]) # normalizing the totdist\n",
    "        j = 0\n",
    "        kn = 0\n",
    "        for val in f:\n",
    "            j += val        \n",
    "            if (j > luck[cycle]): # the column was selected\n",
    "                break\n",
    "            kn +=1\n",
    "        lineNumber[cycle] = kn\n",
    "        \n",
    "        # delete line of the value added    \n",
    "        for n_iter in range(nfolds):\n",
    "            \n",
    "            totDist[n_iter] = np.delete(totDist[n_iter],obj=lineNumber[cycle], axis=0)\n",
    "            j= 0\n",
    "        \n",
    "        s[cycle] = mat[lineNumber[cycle],:]\n",
    "        values[cycle].append(int(mat[lineNumber[cycle],-1]))\n",
    "        mat = np.delete(mat, obj=lineNumber[cycle], axis=0)\n",
    "\n",
    "\n",
    "for n_mod in range(nfolds):\n",
    "    values[n_mod] = out_train.index[values[n_mod]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "proof-pound",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-26T14:01:34.698228Z",
     "iopub.status.busy": "2021-09-26T14:01:34.690120Z",
     "iopub.status.idle": "2021-09-26T14:02:03.453212Z",
     "shell.execute_reply": "2021-09-26T14:02:03.453901Z"
    },
    "papermill": {
     "duration": 35.089578,
     "end_time": "2021-09-26T14:02:03.454107",
     "exception": false,
     "start_time": "2021-09-26T14:01:28.364529",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#colNames.remove('row_id')\n",
    "train.replace([np.inf, -np.inf], np.nan,inplace=True)\n",
    "test.replace([np.inf, -np.inf], np.nan,inplace=True)\n",
    "qt_train = []\n",
    "train_nn=train[colNames].copy()\n",
    "test_nn=test[colNames].copy()\n",
    "for col in colNames:\n",
    "    #print(col)\n",
    "    qt = QuantileTransformer(random_state=21,n_quantiles=2000, output_distribution='normal')\n",
    "    train_nn[col] = qt.fit_transform(train_nn[[col]])\n",
    "    test_nn[col] = qt.transform(test_nn[[col]])    \n",
    "    qt_train.append(qt)\n",
    "train_nn[['stock_id','time_id','target']]=train[['stock_id','time_id','target']]\n",
    "test_nn[['stock_id','time_id']]=test[['stock_id','time_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "professional-activity",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-26T14:02:15.947189Z",
     "iopub.status.busy": "2021-09-26T14:02:15.946225Z",
     "iopub.status.idle": "2021-09-26T14:02:17.689721Z",
     "shell.execute_reply": "2021-09-26T14:02:17.690225Z"
    },
    "papermill": {
     "duration": 8.02114,
     "end_time": "2021-09-26T14:02:17.690465",
     "exception": false,
     "start_time": "2021-09-26T14:02:09.669325",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 4 3 1 3 0 1 3 5 1 0 4 3 3 3 3 3 1 3 3 6 0 0 3 6 3 0 3 6 3 6 3 3 0 4 6 3\n",
      " 6 3 3 3 0 3 3 0 4 3 3 3 4 0 6 6 6 1 4 1 3 0 3 3 0 3 0 0 6 4 0 6 4 5 2 6 4\n",
      " 4 3 4 0 6 4 4 3 0 0 4 4 6 6 3 4 0 3 3 3 3 6 0 6 6 0 0 3 0 0 3 3 0 0 3 4 3\n",
      " 4]\n",
      "[5, 10, 22, 23, 29, 36, 44, 48, 56, 66, 69, 72, 73, 76, 87, 94, 95, 102, 109, 112, 113, 115, 116, 120, 122]\n",
      "[3, 6, 9, 18, 61, 63]\n",
      "[81]\n",
      "[0, 2, 4, 7, 13, 14, 15, 16, 17, 19, 20, 26, 28, 30, 32, 34, 35, 39, 41, 42, 43, 46, 47, 51, 52, 53, 64, 67, 68, 70, 85, 93, 100, 103, 104, 105, 107, 114, 118, 119, 123, 125]\n",
      "[1, 11, 37, 50, 55, 62, 75, 78, 83, 84, 86, 89, 90, 96, 97, 101, 124, 126]\n",
      "[8, 80]\n",
      "[21, 27, 31, 33, 38, 40, 58, 59, 60, 74, 77, 82, 88, 98, 99, 108, 110, 111]\n"
     ]
    }
   ],
   "source": [
    "# making agg features\n",
    "from sklearn.cluster import KMeans\n",
    "train_p = pd.read_csv('../input/optiver-realized-volatility-prediction/train.csv')\n",
    "train_p = train_p.pivot(index='time_id', columns='stock_id', values='target')\n",
    "\n",
    "corr = train_p.corr()\n",
    "\n",
    "ids = corr.index\n",
    "\n",
    "kmeans = KMeans(n_clusters=7, random_state=0).fit(corr.values)\n",
    "print(kmeans.labels_)\n",
    "\n",
    "l = []\n",
    "for n in range(7):\n",
    "    l.append ( [ (x-1) for x in ( (ids+1)*(kmeans.labels_ == n)) if x > 0] )\n",
    "    \n",
    "\n",
    "mat = []\n",
    "matTest = []\n",
    "\n",
    "n = 0\n",
    "for ind in l:\n",
    "    print(ind)\n",
    "    newDf = train_nn.loc[train_nn['stock_id'].isin(ind) ]\n",
    "    newDf = newDf.groupby(['time_id']).agg(np.nanmean)\n",
    "    newDf.loc[:,'stock_id'] = str(n)+'c1'\n",
    "    mat.append ( newDf )\n",
    "    \n",
    "    newDf = test_nn.loc[test_nn['stock_id'].isin(ind) ]    \n",
    "    newDf = newDf.groupby(['time_id']).agg(np.nanmean)\n",
    "    newDf.loc[:,'stock_id'] = str(n)+'c1'\n",
    "    matTest.append ( newDf )\n",
    "    \n",
    "    n+=1\n",
    "    \n",
    "mat1 = pd.concat(mat).reset_index()\n",
    "mat1.drop(columns=['target'],inplace=True)\n",
    "\n",
    "mat2 = pd.concat(matTest).reset_index()\n",
    "mat2 = pd.concat([mat2,mat1.loc[mat1.time_id==5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "academic-country",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-26T14:02:30.155997Z",
     "iopub.status.busy": "2021-09-26T14:02:30.155336Z",
     "iopub.status.idle": "2021-09-26T14:02:30.158173Z",
     "shell.execute_reply": "2021-09-26T14:02:30.157668Z"
    },
    "papermill": {
     "duration": 6.273299,
     "end_time": "2021-09-26T14:02:30.158317",
     "exception": false,
     "start_time": "2021-09-26T14:02:23.885018",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nnn = ['time_id',\n",
    "     'log_return1_realized_volatility_0c1',\n",
    "     'log_return1_realized_volatility_1c1',     \n",
    "     'log_return1_realized_volatility_3c1',\n",
    "     'log_return1_realized_volatility_4c1',     \n",
    "     'log_return1_realized_volatility_6c1',\n",
    "     'total_volume_sum_0c1',\n",
    "     'total_volume_sum_1c1', \n",
    "     'total_volume_sum_3c1',\n",
    "     'total_volume_sum_4c1', \n",
    "     'total_volume_sum_6c1',\n",
    "     'trade_size_sum_0c1',\n",
    "     'trade_size_sum_1c1', \n",
    "     'trade_size_sum_3c1',\n",
    "     'trade_size_sum_4c1', \n",
    "     'trade_size_sum_6c1',\n",
    "     'trade_order_count_sum_0c1',\n",
    "     'trade_order_count_sum_1c1',\n",
    "     'trade_order_count_sum_3c1',\n",
    "     'trade_order_count_sum_4c1',\n",
    "     'trade_order_count_sum_6c1',      \n",
    "     'price_spread_sum_0c1',\n",
    "     'price_spread_sum_1c1',\n",
    "     'price_spread_sum_3c1',\n",
    "     'price_spread_sum_4c1',\n",
    "     'price_spread_sum_6c1',   \n",
    "     'bid_spread_sum_0c1',\n",
    "     'bid_spread_sum_1c1',\n",
    "     'bid_spread_sum_3c1',\n",
    "     'bid_spread_sum_4c1',\n",
    "     'bid_spread_sum_6c1',       \n",
    "     'ask_spread_sum_0c1',\n",
    "     'ask_spread_sum_1c1',\n",
    "     'ask_spread_sum_3c1',\n",
    "     'ask_spread_sum_4c1',\n",
    "     'ask_spread_sum_6c1',   \n",
    "     'volume_imbalance_sum_0c1',\n",
    "     'volume_imbalance_sum_1c1',\n",
    "     'volume_imbalance_sum_3c1',\n",
    "     'volume_imbalance_sum_4c1',\n",
    "     'volume_imbalance_sum_6c1',       \n",
    "     'bid_ask_spread_sum_0c1',\n",
    "     'bid_ask_spread_sum_1c1',\n",
    "     'bid_ask_spread_sum_3c1',\n",
    "     'bid_ask_spread_sum_4c1',\n",
    "     'bid_ask_spread_sum_6c1',\n",
    "     'size_tau2_0c1',\n",
    "     'size_tau2_1c1',\n",
    "     'size_tau2_3c1',\n",
    "     'size_tau2_4c1',\n",
    "     'size_tau2_6c1'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "former-senior",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-26T14:02:42.790263Z",
     "iopub.status.busy": "2021-09-26T14:02:42.789591Z",
     "iopub.status.idle": "2021-09-26T14:02:42.971920Z",
     "shell.execute_reply": "2021-09-26T14:02:42.971366Z"
    },
    "papermill": {
     "duration": 6.626786,
     "end_time": "2021-09-26T14:02:42.972074",
     "exception": false,
     "start_time": "2021-09-26T14:02:36.345288",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mat1 = mat1.pivot(index='time_id', columns='stock_id')\n",
    "mat1.columns = [\"_\".join(x) for x in mat1.columns.ravel()]\n",
    "mat1.reset_index(inplace=True)\n",
    "\n",
    "mat2 = mat2.pivot(index='time_id', columns='stock_id')\n",
    "mat2.columns = [\"_\".join(x) for x in mat2.columns.ravel()]\n",
    "mat2.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bridal-answer",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-26T14:02:55.479181Z",
     "iopub.status.busy": "2021-09-26T14:02:55.477690Z",
     "iopub.status.idle": "2021-09-26T14:03:01.053193Z",
     "shell.execute_reply": "2021-09-26T14:03:01.053709Z"
    },
    "papermill": {
     "duration": 11.820383,
     "end_time": "2021-09-26T14:03:01.053878",
     "exception": false,
     "start_time": "2021-09-26T14:02:49.233495",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12738"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "train_nn = pd.merge(train_nn,mat1[nnn],how='left',on='time_id')\n",
    "test_nn = pd.merge(test_nn,mat2[nnn],how='left',on='time_id')\n",
    "\n",
    "train1=train_nn\n",
    "test1=test_nn\n",
    "del mat1,mat2\n",
    "del train,test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "coordinate-technology",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-26T14:03:13.565433Z",
     "iopub.status.busy": "2021-09-26T14:03:13.564415Z",
     "iopub.status.idle": "2021-09-26T14:03:13.576854Z",
     "shell.execute_reply": "2021-09-26T14:03:13.577412Z"
    },
    "papermill": {
     "duration": 6.243749,
     "end_time": "2021-09-26T14:03:13.577603",
     "exception": false,
     "start_time": "2021-09-26T14:03:07.333854",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#https://bignerdranch.com/blog/implementing-swish-activation-function-in-keras/\n",
    "from keras.backend import sigmoid\n",
    "def swish(x, beta = 1):\n",
    "    return (x * sigmoid(beta * x))\n",
    "\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras.layers import Activation\n",
    "get_custom_objects().update({'swish': Activation(swish)})\n",
    "\n",
    "hidden_units = (128,64,32)\n",
    "stock_embedding_size = 24\n",
    "\n",
    "cat_data = train_nn['stock_id']\n",
    "\n",
    "def base_model():\n",
    "    \n",
    "    # Each instance will consist of two inputs: a single user id, and a single movie id\n",
    "    stock_id_input = keras.Input(shape=(1,), name='stock_id')\n",
    "    num_input = keras.Input(shape=(244,), name='num_data')\n",
    "\n",
    "\n",
    "    #embedding, flatenning and concatenating\n",
    "    stock_embedded = keras.layers.Embedding(max(cat_data)+1, stock_embedding_size, \n",
    "                                           input_length=1, name='stock_embedding')(stock_id_input)\n",
    "    stock_flattened = keras.layers.Flatten()(stock_embedded)\n",
    "    out = keras.layers.Concatenate()([stock_flattened, num_input])\n",
    "    \n",
    "    # Add one or more hidden layers\n",
    "    for n_hidden in hidden_units:\n",
    "\n",
    "        out = keras.layers.Dense(n_hidden, activation='swish')(out)\n",
    "        \n",
    "\n",
    "    #out = keras.layers.Concatenate()([out, num_input])\n",
    "\n",
    "    # A single output: our predicted rating\n",
    "    out = keras.layers.Dense(1, activation='linear', name='prediction')(out)\n",
    "    \n",
    "    model = keras.Model(\n",
    "    inputs = [stock_id_input, num_input],\n",
    "    outputs = out,\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "sharp-family",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-26T14:03:26.045505Z",
     "iopub.status.busy": "2021-09-26T14:03:26.044514Z",
     "iopub.status.idle": "2021-09-26T14:03:26.050148Z",
     "shell.execute_reply": "2021-09-26T14:03:26.050645Z"
    },
    "papermill": {
     "duration": 6.186274,
     "end_time": "2021-09-26T14:03:26.050832",
     "exception": false,
     "start_time": "2021-09-26T14:03:19.864558",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to calculate the root mean squared percentage error\n",
    "def rmspe(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square((y_true - y_pred) / y_true)))\n",
    "\n",
    "# Function to early stop with root mean squared percentage error\n",
    "def feval_rmspe(y_pred, lgb_train):\n",
    "    y_true = lgb_train.get_label()\n",
    "    return 'RMSPE', rmspe(y_true, y_pred), False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "turned-quality",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-26T14:03:38.579361Z",
     "iopub.status.busy": "2021-09-26T14:03:38.578681Z",
     "iopub.status.idle": "2021-09-26T14:16:59.948773Z",
     "shell.execute_reply": "2021-09-26T14:16:59.799541Z"
    },
    "papermill": {
     "duration": 807.631385,
     "end_time": "2021-09-26T14:16:59.948928",
     "exception": false,
     "start_time": "2021-09-26T14:03:32.317543",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV 1/5\n",
      "Epoch 1/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 23.8191 - val_loss: 0.4237\n",
      "Epoch 2/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.7082 - val_loss: 0.6480\n",
      "Epoch 3/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.5141 - val_loss: 0.6136\n",
      "Epoch 4/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.4024 - val_loss: 0.7761\n",
      "Epoch 5/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.7598 - val_loss: 0.8851\n",
      "Epoch 6/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.6497 - val_loss: 0.7306\n",
      "Epoch 7/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.7249 - val_loss: 0.5537\n",
      "Epoch 8/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.5390 - val_loss: 0.4897\n",
      "Epoch 9/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2552 - val_loss: 0.2172\n",
      "Epoch 10/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2186 - val_loss: 0.2194\n",
      "Epoch 11/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2173 - val_loss: 0.2186\n",
      "Epoch 12/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2172 - val_loss: 0.2157\n",
      "Epoch 13/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2168 - val_loss: 0.2152\n",
      "Epoch 14/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2164 - val_loss: 0.2151\n",
      "Epoch 15/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2153 - val_loss: 0.2232\n",
      "Epoch 16/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2170 - val_loss: 0.2189\n",
      "Epoch 17/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2199 - val_loss: 0.2141\n",
      "Epoch 18/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2233 - val_loss: 0.2202\n",
      "Epoch 19/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2189 - val_loss: 0.2159\n",
      "Epoch 20/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2148 - val_loss: 0.2218\n",
      "Epoch 21/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2201 - val_loss: 0.2738\n",
      "Epoch 22/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2267 - val_loss: 0.2168\n",
      "Epoch 23/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2234 - val_loss: 0.2314\n",
      "Epoch 24/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2188 - val_loss: 0.2266\n",
      "Epoch 25/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2105 - val_loss: 0.2117\n",
      "Epoch 26/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2084 - val_loss: 0.2111\n",
      "Epoch 27/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2075 - val_loss: 0.2113\n",
      "Epoch 28/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2077 - val_loss: 0.2103\n",
      "Epoch 29/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2076 - val_loss: 0.2107\n",
      "Epoch 30/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2071 - val_loss: 0.2108\n",
      "Epoch 31/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2076 - val_loss: 0.2113\n",
      "Epoch 32/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2075 - val_loss: 0.2114\n",
      "Epoch 33/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2076 - val_loss: 0.2112\n",
      "Epoch 34/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2072 - val_loss: 0.2141\n",
      "Epoch 35/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2079 - val_loss: 0.2106\n",
      "Epoch 36/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2060 - val_loss: 0.2104\n",
      "Epoch 37/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2052 - val_loss: 0.2102\n",
      "Epoch 38/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2052 - val_loss: 0.2100\n",
      "Epoch 39/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2050 - val_loss: 0.2107\n",
      "Epoch 40/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2047 - val_loss: 0.2103\n",
      "Epoch 41/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2053 - val_loss: 0.2108\n",
      "Epoch 42/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2051 - val_loss: 0.2099\n",
      "Epoch 43/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2055 - val_loss: 0.2102\n",
      "Epoch 44/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2056 - val_loss: 0.2107\n",
      "Epoch 45/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2052 - val_loss: 0.2103\n",
      "Epoch 46/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2052 - val_loss: 0.2099\n",
      "Epoch 47/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2047 - val_loss: 0.2100\n",
      "Epoch 48/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2039 - val_loss: 0.2099\n",
      "Epoch 49/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2046 - val_loss: 0.2100\n",
      "Epoch 50/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2044 - val_loss: 0.2099\n",
      "Epoch 51/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2056 - val_loss: 0.2101\n",
      "Epoch 52/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2048 - val_loss: 0.2099\n",
      "Epoch 53/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2048 - val_loss: 0.2101\n",
      "Epoch 54/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2050 - val_loss: 0.2100\n",
      "Epoch 55/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2047 - val_loss: 0.2099\n",
      "Epoch 56/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2044 - val_loss: 0.2100\n",
      "Epoch 57/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2039 - val_loss: 0.2099\n",
      "Epoch 58/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2044 - val_loss: 0.2098\n",
      "Epoch 59/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2032 - val_loss: 0.2098\n",
      "Epoch 60/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2043 - val_loss: 0.2100\n",
      "Epoch 61/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2038 - val_loss: 0.2099\n",
      "Epoch 62/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2041 - val_loss: 0.2098\n",
      "Epoch 63/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2041 - val_loss: 0.2099\n",
      "Epoch 64/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2036 - val_loss: 0.2099\n",
      "Epoch 65/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2043 - val_loss: 0.2099\n",
      "Epoch 66/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2044 - val_loss: 0.2099\n",
      "Epoch 67/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2035 - val_loss: 0.2099\n",
      "Epoch 68/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2051 - val_loss: 0.2099\n",
      "Epoch 69/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2034 - val_loss: 0.2099\n",
      "Epoch 70/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2037 - val_loss: 0.2099\n",
      "Epoch 71/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2038 - val_loss: 0.2099\n",
      "Epoch 72/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2050 - val_loss: 0.2099\n",
      "Epoch 73/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2035 - val_loss: 0.2099\n",
      "Epoch 74/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2035 - val_loss: 0.2099\n",
      "Epoch 75/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2044 - val_loss: 0.2099\n",
      "Epoch 76/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2039 - val_loss: 0.2099\n",
      "Epoch 77/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2043 - val_loss: 0.2099\n",
      "Epoch 78/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2042 - val_loss: 0.2099\n",
      "Epoch 79/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2046 - val_loss: 0.2099\n",
      "Epoch 80/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2037 - val_loss: 0.2099\n",
      "Epoch 81/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2043 - val_loss: 0.2099\n",
      "Epoch 82/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2036 - val_loss: 0.2099\n",
      "Fold 1 NN: 0.2098\n",
      "CV 2/5\n",
      "Epoch 1/1000\n",
      "168/168 [==============================] - 3s 14ms/step - loss: 23.8434 - val_loss: 0.3770\n",
      "Epoch 2/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 1.0690 - val_loss: 0.6094\n",
      "Epoch 3/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.8899 - val_loss: 0.5244\n",
      "Epoch 4/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.9724 - val_loss: 0.9522\n",
      "Epoch 5/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.8706 - val_loss: 0.7351\n",
      "Epoch 6/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.7510 - val_loss: 0.5652\n",
      "Epoch 7/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.7792 - val_loss: 0.6416\n",
      "Epoch 8/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.6682 - val_loss: 0.2392\n",
      "Epoch 9/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2801 - val_loss: 0.2765\n",
      "Epoch 10/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2912 - val_loss: 0.2725\n",
      "Epoch 11/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 2.6392 - val_loss: 0.3341\n",
      "Epoch 12/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.3684 - val_loss: 0.2338\n",
      "Epoch 13/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2343 - val_loss: 0.2399\n",
      "Epoch 14/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2334 - val_loss: 0.2261\n",
      "Epoch 15/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2373 - val_loss: 0.2333\n",
      "Epoch 16/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2496 - val_loss: 0.2783\n",
      "Epoch 17/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2478 - val_loss: 0.2312\n",
      "Epoch 18/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2475 - val_loss: 0.2503\n",
      "Epoch 19/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 1.0507 - val_loss: 0.2418\n",
      "Epoch 20/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2388 - val_loss: 0.2455\n",
      "Epoch 21/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2284 - val_loss: 0.2501\n",
      "Epoch 22/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2152 - val_loss: 0.2184\n",
      "Epoch 23/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2122 - val_loss: 0.2205\n",
      "Epoch 24/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2113 - val_loss: 0.2183\n",
      "Epoch 25/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2109 - val_loss: 0.2197\n",
      "Epoch 26/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2124 - val_loss: 0.2179\n",
      "Epoch 27/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2119 - val_loss: 0.2191\n",
      "Epoch 28/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2111 - val_loss: 0.2181\n",
      "Epoch 29/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2105 - val_loss: 0.2180\n",
      "Epoch 30/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2098 - val_loss: 0.2189\n",
      "Epoch 31/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2106 - val_loss: 0.2182\n",
      "Epoch 32/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2100 - val_loss: 0.2213\n",
      "Epoch 33/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2132 - val_loss: 0.2304\n",
      "Epoch 34/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2082 - val_loss: 0.2156\n",
      "Epoch 35/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2062 - val_loss: 0.2150\n",
      "Epoch 36/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2067 - val_loss: 0.2156\n",
      "Epoch 37/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2065 - val_loss: 0.2163\n",
      "Epoch 38/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2069 - val_loss: 0.2158\n",
      "Epoch 39/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2071 - val_loss: 0.2148\n",
      "Epoch 40/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2061 - val_loss: 0.2152\n",
      "Epoch 41/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2065 - val_loss: 0.2156\n",
      "Epoch 42/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2061 - val_loss: 0.2140\n",
      "Epoch 43/1000\n",
      "168/168 [==============================] - 2s 15ms/step - loss: 0.2069 - val_loss: 0.2156\n",
      "Epoch 44/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2064 - val_loss: 0.2145\n",
      "Epoch 45/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2057 - val_loss: 0.2142\n",
      "Epoch 46/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2061 - val_loss: 0.2164\n",
      "Epoch 47/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2053 - val_loss: 0.2140\n",
      "Epoch 48/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2068 - val_loss: 0.2150\n",
      "Epoch 49/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2067 - val_loss: 0.2139\n",
      "Epoch 50/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2056 - val_loss: 0.2147\n",
      "Epoch 51/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2055 - val_loss: 0.2182\n",
      "Epoch 52/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2057 - val_loss: 0.2137\n",
      "Epoch 53/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2050 - val_loss: 0.2185\n",
      "Epoch 54/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2069 - val_loss: 0.2127\n",
      "Epoch 55/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2049 - val_loss: 0.2151\n",
      "Epoch 56/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2047 - val_loss: 0.2156\n",
      "Epoch 57/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2054 - val_loss: 0.2134\n",
      "Epoch 58/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2046 - val_loss: 0.2162\n",
      "Epoch 59/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2045 - val_loss: 0.2147\n",
      "Epoch 60/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2044 - val_loss: 0.2148\n",
      "Epoch 61/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2055 - val_loss: 0.2151\n",
      "Epoch 62/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2022 - val_loss: 0.2125\n",
      "Epoch 63/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2028 - val_loss: 0.2138\n",
      "Epoch 64/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2021 - val_loss: 0.2136\n",
      "Epoch 65/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2022 - val_loss: 0.2133\n",
      "Epoch 66/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2027 - val_loss: 0.2138\n",
      "Epoch 67/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2021 - val_loss: 0.2136\n",
      "Epoch 68/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2025 - val_loss: 0.2132\n",
      "Epoch 69/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2023 - val_loss: 0.2124\n",
      "Epoch 70/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2015 - val_loss: 0.2128\n",
      "Epoch 71/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2015 - val_loss: 0.2132\n",
      "Epoch 72/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2012 - val_loss: 0.2131\n",
      "Epoch 73/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2011 - val_loss: 0.2131\n",
      "Epoch 74/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2013 - val_loss: 0.2129\n",
      "Epoch 75/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2017 - val_loss: 0.2131\n",
      "Epoch 76/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2023 - val_loss: 0.2134\n",
      "Epoch 77/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2014 - val_loss: 0.2132\n",
      "Epoch 78/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2016 - val_loss: 0.2132\n",
      "Epoch 79/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2022 - val_loss: 0.2130\n",
      "Epoch 80/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2013 - val_loss: 0.2132\n",
      "Epoch 81/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2016 - val_loss: 0.2131\n",
      "Epoch 82/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2020 - val_loss: 0.2133\n",
      "Epoch 83/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2016 - val_loss: 0.2131\n",
      "Epoch 84/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2011 - val_loss: 0.2131\n",
      "Epoch 85/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2014 - val_loss: 0.2131\n",
      "Epoch 86/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2011 - val_loss: 0.2131\n",
      "Epoch 87/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2015 - val_loss: 0.2131\n",
      "Epoch 88/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2012 - val_loss: 0.2131\n",
      "Epoch 89/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2008 - val_loss: 0.2131\n",
      "Fold 2 NN: 0.21242\n",
      "CV 3/5\n",
      "Epoch 1/1000\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 27.1628 - val_loss: 0.7253\n",
      "Epoch 2/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.8106 - val_loss: 0.5405\n",
      "Epoch 3/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.6450 - val_loss: 0.6581\n",
      "Epoch 4/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.6269 - val_loss: 0.5644\n",
      "Epoch 5/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.5421 - val_loss: 0.5347\n",
      "Epoch 6/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.5184 - val_loss: 0.8938\n",
      "Epoch 7/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 1.5332 - val_loss: 0.4170\n",
      "Epoch 8/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.4173 - val_loss: 0.3536\n",
      "Epoch 9/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.4051 - val_loss: 0.6090\n",
      "Epoch 10/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.4434 - val_loss: 0.3933\n",
      "Epoch 11/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.3855 - val_loss: 0.4349\n",
      "Epoch 12/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.3882 - val_loss: 0.2961\n",
      "Epoch 13/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.3445 - val_loss: 0.2188\n",
      "Epoch 14/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2198 - val_loss: 0.2210\n",
      "Epoch 15/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2443 - val_loss: 0.2217\n",
      "Epoch 16/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2398 - val_loss: 0.2773\n",
      "Epoch 17/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2556 - val_loss: 0.2665\n",
      "Epoch 18/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2525 - val_loss: 0.2124\n",
      "Epoch 19/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2295 - val_loss: 0.2210\n",
      "Epoch 20/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2363 - val_loss: 0.2426\n",
      "Epoch 21/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2413 - val_loss: 0.2682\n",
      "Epoch 22/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2843 - val_loss: 0.2207\n",
      "Epoch 23/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2417 - val_loss: 0.2656\n",
      "Epoch 24/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2500 - val_loss: 0.2179\n",
      "Epoch 25/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2295 - val_loss: 0.2744\n",
      "Epoch 26/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2161 - val_loss: 0.2094\n",
      "Epoch 27/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2061 - val_loss: 0.2096\n",
      "Epoch 28/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2060 - val_loss: 0.2095\n",
      "Epoch 29/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2053 - val_loss: 0.2110\n",
      "Epoch 30/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2070 - val_loss: 0.2096\n",
      "Epoch 31/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2049 - val_loss: 0.2112\n",
      "Epoch 32/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2064 - val_loss: 0.2100\n",
      "Epoch 33/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2062 - val_loss: 0.2093\n",
      "Epoch 34/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2033 - val_loss: 0.2093\n",
      "Epoch 35/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2031 - val_loss: 0.2087\n",
      "Epoch 36/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2024 - val_loss: 0.2088\n",
      "Epoch 37/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2024 - val_loss: 0.2093\n",
      "Epoch 38/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2023 - val_loss: 0.2094\n",
      "Epoch 39/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2019 - val_loss: 0.2091\n",
      "Epoch 40/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2029 - val_loss: 0.2094\n",
      "Epoch 41/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2025 - val_loss: 0.2124\n",
      "Epoch 42/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2039 - val_loss: 0.2091\n",
      "Epoch 43/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2022 - val_loss: 0.2088\n",
      "Epoch 44/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2012 - val_loss: 0.2085\n",
      "Epoch 45/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2018 - val_loss: 0.2089\n",
      "Epoch 46/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2018 - val_loss: 0.2090\n",
      "Epoch 47/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2019 - val_loss: 0.2086\n",
      "Epoch 48/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2019 - val_loss: 0.2085\n",
      "Epoch 49/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2013 - val_loss: 0.2087\n",
      "Epoch 50/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2018 - val_loss: 0.2088\n",
      "Epoch 51/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2017 - val_loss: 0.2089\n",
      "Epoch 52/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2016 - val_loss: 0.2085\n",
      "Epoch 53/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2024 - val_loss: 0.2086\n",
      "Epoch 54/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2012 - val_loss: 0.2085\n",
      "Epoch 55/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2009 - val_loss: 0.2085\n",
      "Epoch 56/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2013 - val_loss: 0.2086\n",
      "Epoch 57/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2017 - val_loss: 0.2085\n",
      "Epoch 58/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2017 - val_loss: 0.2086\n",
      "Epoch 59/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2015 - val_loss: 0.2085\n",
      "Epoch 60/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2017 - val_loss: 0.2086\n",
      "Epoch 61/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2017 - val_loss: 0.2085\n",
      "Epoch 62/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2019 - val_loss: 0.2085\n",
      "Epoch 63/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2018 - val_loss: 0.2085\n",
      "Epoch 64/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2009 - val_loss: 0.2086\n",
      "Epoch 65/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2016 - val_loss: 0.2085\n",
      "Epoch 66/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2015 - val_loss: 0.2085\n",
      "Epoch 67/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2020 - val_loss: 0.2085\n",
      "Epoch 68/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2015 - val_loss: 0.2085\n",
      "Fold 3 NN: 0.20848\n",
      "CV 4/5\n",
      "Epoch 1/1000\n",
      "168/168 [==============================] - 3s 14ms/step - loss: 28.2284 - val_loss: 1.0758\n",
      "Epoch 2/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.7819 - val_loss: 0.6049\n",
      "Epoch 3/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.6919 - val_loss: 0.2839\n",
      "Epoch 4/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.3841 - val_loss: 0.5995\n",
      "Epoch 5/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.6688 - val_loss: 0.4743\n",
      "Epoch 6/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.5854 - val_loss: 0.6544\n",
      "Epoch 7/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.6781 - val_loss: 0.6499\n",
      "Epoch 8/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.5217 - val_loss: 0.5663\n",
      "Epoch 9/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.5389 - val_loss: 0.4499\n",
      "Epoch 10/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.5501 - val_loss: 0.3942\n",
      "Epoch 11/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2420 - val_loss: 0.2257\n",
      "Epoch 12/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2182 - val_loss: 0.2202\n",
      "Epoch 13/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2132 - val_loss: 0.2222\n",
      "Epoch 14/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2147 - val_loss: 0.2337\n",
      "Epoch 15/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2152 - val_loss: 0.2244\n",
      "Epoch 16/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2135 - val_loss: 0.2274\n",
      "Epoch 17/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2165 - val_loss: 0.2211\n",
      "Epoch 18/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2133 - val_loss: 0.2202\n",
      "Epoch 19/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2109 - val_loss: 0.2237\n",
      "Epoch 20/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2094 - val_loss: 0.2180\n",
      "Epoch 21/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2081 - val_loss: 0.2186\n",
      "Epoch 22/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2083 - val_loss: 0.2170\n",
      "Epoch 23/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2080 - val_loss: 0.2187\n",
      "Epoch 24/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2086 - val_loss: 0.2183\n",
      "Epoch 25/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2070 - val_loss: 0.2188\n",
      "Epoch 26/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2082 - val_loss: 0.2178\n",
      "Epoch 27/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2075 - val_loss: 0.2199\n",
      "Epoch 28/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2070 - val_loss: 0.2185\n",
      "Epoch 29/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2073 - val_loss: 0.2190\n",
      "Epoch 30/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2059 - val_loss: 0.2173\n",
      "Epoch 31/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2066 - val_loss: 0.2172\n",
      "Epoch 32/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2064 - val_loss: 0.2175\n",
      "Epoch 33/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2059 - val_loss: 0.2178\n",
      "Epoch 34/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2060 - val_loss: 0.2179\n",
      "Epoch 35/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2056 - val_loss: 0.2178\n",
      "Epoch 36/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2062 - val_loss: 0.2180\n",
      "Epoch 37/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2060 - val_loss: 0.2175\n",
      "Epoch 38/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2052 - val_loss: 0.2176\n",
      "Epoch 39/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2053 - val_loss: 0.2173\n",
      "Epoch 40/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2059 - val_loss: 0.2174\n",
      "Epoch 41/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2057 - val_loss: 0.2173\n",
      "Epoch 42/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2053 - val_loss: 0.2174\n",
      "Fold 4 NN: 0.21705\n",
      "CV 5/5\n",
      "Epoch 1/1000\n",
      "168/168 [==============================] - 3s 14ms/step - loss: 29.9694 - val_loss: 2.2427\n",
      "Epoch 2/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 1.2274 - val_loss: 0.9087\n",
      "Epoch 3/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.6800 - val_loss: 0.3160\n",
      "Epoch 4/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.3278 - val_loss: 0.5982\n",
      "Epoch 5/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.6667 - val_loss: 1.0373\n",
      "Epoch 6/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.6662 - val_loss: 0.5234\n",
      "Epoch 7/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.5542 - val_loss: 0.7105\n",
      "Epoch 8/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.5703 - val_loss: 0.4843\n",
      "Epoch 9/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.4816 - val_loss: 0.4682\n",
      "Epoch 10/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.4723 - val_loss: 0.5086\n",
      "Epoch 11/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2598 - val_loss: 0.2268\n",
      "Epoch 12/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2171 - val_loss: 0.2208\n",
      "Epoch 13/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2138 - val_loss: 0.2209\n",
      "Epoch 14/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2156 - val_loss: 0.2216\n",
      "Epoch 15/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2129 - val_loss: 0.2264\n",
      "Epoch 16/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2140 - val_loss: 0.2215\n",
      "Epoch 17/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2125 - val_loss: 0.2200\n",
      "Epoch 18/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2117 - val_loss: 0.2195\n",
      "Epoch 19/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2127 - val_loss: 0.2196\n",
      "Epoch 20/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2117 - val_loss: 0.2230\n",
      "Epoch 21/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2124 - val_loss: 0.2241\n",
      "Epoch 22/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2111 - val_loss: 0.2210\n",
      "Epoch 23/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2100 - val_loss: 0.2187\n",
      "Epoch 24/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2112 - val_loss: 0.2273\n",
      "Epoch 25/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2201 - val_loss: 0.2405\n",
      "Epoch 26/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2155 - val_loss: 0.2220\n",
      "Epoch 27/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2358 - val_loss: 0.2591\n",
      "Epoch 28/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2194 - val_loss: 0.4033\n",
      "Epoch 29/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2643 - val_loss: 0.2197\n",
      "Epoch 30/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2110 - val_loss: 0.2264\n",
      "Epoch 31/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2071 - val_loss: 0.2167\n",
      "Epoch 32/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2046 - val_loss: 0.2166\n",
      "Epoch 33/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2047 - val_loss: 0.2169\n",
      "Epoch 34/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2041 - val_loss: 0.2172\n",
      "Epoch 35/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2046 - val_loss: 0.2165\n",
      "Epoch 36/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2035 - val_loss: 0.2159\n",
      "Epoch 37/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2040 - val_loss: 0.2224\n",
      "Epoch 38/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2051 - val_loss: 0.2174\n",
      "Epoch 39/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2033 - val_loss: 0.2173\n",
      "Epoch 40/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2034 - val_loss: 0.2183\n",
      "Epoch 41/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2036 - val_loss: 0.2172\n",
      "Epoch 42/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2040 - val_loss: 0.2224\n",
      "Epoch 43/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2076 - val_loss: 0.2177\n",
      "Epoch 44/1000\n",
      "168/168 [==============================] - 2s 15ms/step - loss: 0.2024 - val_loss: 0.2156\n",
      "Epoch 45/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2018 - val_loss: 0.2154\n",
      "Epoch 46/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2015 - val_loss: 0.2163\n",
      "Epoch 47/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2019 - val_loss: 0.2166\n",
      "Epoch 48/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2017 - val_loss: 0.2160\n",
      "Epoch 49/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2022 - val_loss: 0.2152\n",
      "Epoch 50/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2020 - val_loss: 0.2168\n",
      "Epoch 51/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2017 - val_loss: 0.2171\n",
      "Epoch 52/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2014 - val_loss: 0.2160\n",
      "Epoch 53/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2018 - val_loss: 0.2166\n",
      "Epoch 54/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2014 - val_loss: 0.2157\n",
      "Epoch 55/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2025 - val_loss: 0.2157\n",
      "Epoch 56/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2013 - val_loss: 0.2181\n",
      "Epoch 57/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2008 - val_loss: 0.2156\n",
      "Epoch 58/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2014 - val_loss: 0.2158\n",
      "Epoch 59/1000\n",
      "168/168 [==============================] - 2s 15ms/step - loss: 0.1999 - val_loss: 0.2155\n",
      "Epoch 60/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2004 - val_loss: 0.2160\n",
      "Epoch 61/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2006 - val_loss: 0.2157\n",
      "Epoch 62/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2012 - val_loss: 0.2160\n",
      "Epoch 63/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2004 - val_loss: 0.2159\n",
      "Epoch 64/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2002 - val_loss: 0.2155\n",
      "Epoch 65/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2005 - val_loss: 0.2158\n",
      "Epoch 66/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2005 - val_loss: 0.2156\n",
      "Epoch 67/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2006 - val_loss: 0.2159\n",
      "Epoch 68/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2008 - val_loss: 0.2157\n",
      "Epoch 69/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2009 - val_loss: 0.2161\n",
      "Fold 5 NN: 0.21524\n"
     ]
    }
   ],
   "source": [
    "target_name='target'\n",
    "scores_folds = {}\n",
    "model_name = 'NN'\n",
    "pred_name = 'pred_{}'.format(model_name)\n",
    "\n",
    "n_folds = 5\n",
    "kf = model_selection.KFold(n_splits=n_folds, shuffle=True, random_state=2020)\n",
    "scores_folds[model_name] = []\n",
    "counter = 1\n",
    "\n",
    "features_to_consider = list(train_nn)\n",
    "\n",
    "features_to_consider.remove('time_id')\n",
    "features_to_consider.remove('target')\n",
    "try:\n",
    "    features_to_consider.remove('pred_NN')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n",
    "train_nn[features_to_consider] = train_nn[features_to_consider].fillna(train_nn[features_to_consider].mean())\n",
    "test_nn[features_to_consider] = test_nn[features_to_consider].fillna(train_nn[features_to_consider].mean())\n",
    "\n",
    "train_nn[pred_name] = 0\n",
    "test_nn[target_name] = 0\n",
    "test_predictions_nn = np.zeros(test_nn.shape[0])\n",
    "\n",
    "for n_count in range(n_folds):\n",
    "    print('CV {}/{}'.format(counter, n_folds))\n",
    "    \n",
    "    indexes = np.arange(nfolds).astype(int)    \n",
    "    indexes = np.delete(indexes,obj=n_count, axis=0) \n",
    "    \n",
    "    indexes = np.r_[values[indexes[0]],values[indexes[1]],values[indexes[2]],values[indexes[3]]]\n",
    "    \n",
    "    X_train = train_nn.loc[train_nn.time_id.isin(indexes), features_to_consider]\n",
    "    y_train = train_nn.loc[train_nn.time_id.isin(indexes), target_name]\n",
    "    X_test = train_nn.loc[train_nn.time_id.isin(values[n_count]), features_to_consider]\n",
    "    y_test = train_nn.loc[train_nn.time_id.isin(values[n_count]), target_name]\n",
    "    \n",
    "    #############################################################################################\n",
    "    # NN\n",
    "    #############################################################################################\n",
    "    \n",
    "    model = base_model()\n",
    "    \n",
    "    model.compile(\n",
    "        keras.optimizers.Adam(learning_rate=0.006),\n",
    "        loss=root_mean_squared_per_error\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        features_to_consider.remove('stock_id')\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    num_data = X_train[features_to_consider]\n",
    "    \n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))         \n",
    "    num_data = scaler.fit_transform(num_data.values)    \n",
    "    \n",
    "    cat_data = X_train['stock_id']    \n",
    "    target =  y_train\n",
    "    \n",
    "    num_data_test = X_test[features_to_consider]\n",
    "    num_data_test = scaler.transform(num_data_test.values)\n",
    "    cat_data_test = X_test['stock_id']\n",
    "\n",
    "    model.fit([cat_data, num_data], \n",
    "              target,               \n",
    "              batch_size=2048,\n",
    "              epochs=1000,\n",
    "              validation_data=([cat_data_test, num_data_test], y_test),\n",
    "              callbacks=[es, plateau],\n",
    "              validation_batch_size=len(y_test),\n",
    "              shuffle=True,\n",
    "             verbose = 1)\n",
    "\n",
    "    preds = model.predict([cat_data_test, num_data_test]).reshape(1,-1)[0]\n",
    "    \n",
    "    score = round(rmspe(y_true = y_test, y_pred = preds),5)\n",
    "    print('Fold {} {}: {}'.format(counter, model_name, score))\n",
    "    scores_folds[model_name].append(score)\n",
    "    \n",
    "    tt =scaler.transform(test_nn[features_to_consider].values)\n",
    "    #test_nn[target_name] += model.predict([test_nn['stock_id'], tt]).reshape(1,-1)[0].clip(0,1e10)\n",
    "    test_predictions_nn += model.predict([test_nn['stock_id'], tt]).reshape(1,-1)[0].clip(0,1e10)/n_folds\n",
    "    #test[target_name] += model.predict([test['stock_id'], test[features_to_consider]]).reshape(1,-1)[0].clip(0,1e10)\n",
    "       \n",
    "    counter += 1\n",
    "    features_to_consider.append('stock_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "coordinated-running",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-26T14:17:20.647885Z",
     "iopub.status.busy": "2021-09-26T14:17:20.555665Z",
     "iopub.status.idle": "2021-09-26T14:31:24.284874Z",
     "shell.execute_reply": "2021-09-26T14:31:24.052256Z"
    },
    "papermill": {
     "duration": 854.135891,
     "end_time": "2021-09-26T14:31:24.285029",
     "exception": false,
     "start_time": "2021-09-26T14:17:10.149138",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV 1/5\n",
      "Epoch 1/1000\n",
      "168/168 [==============================] - 3s 14ms/step - loss: 26.2109 - val_loss: 1.2451\n",
      "Epoch 2/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 1.2210 - val_loss: 0.6841\n",
      "Epoch 3/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.6329 - val_loss: 0.7802\n",
      "Epoch 4/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.6071 - val_loss: 0.6644\n",
      "Epoch 5/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.5914 - val_loss: 2.3615\n",
      "Epoch 6/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 1.0008 - val_loss: 0.4440\n",
      "Epoch 7/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.5367 - val_loss: 0.5873\n",
      "Epoch 8/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.5365 - val_loss: 0.5057\n",
      "Epoch 9/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.6116 - val_loss: 0.8302\n",
      "Epoch 10/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.5388 - val_loss: 0.6336\n",
      "Epoch 11/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2847 - val_loss: 0.2288\n",
      "Epoch 12/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2340 - val_loss: 0.2346\n",
      "Epoch 13/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2626 - val_loss: 0.2953\n",
      "Epoch 14/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2466 - val_loss: 0.2890\n",
      "Epoch 15/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2558 - val_loss: 0.2448\n",
      "Epoch 16/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2803 - val_loss: 0.3372\n",
      "Epoch 17/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2731 - val_loss: 0.2560\n",
      "Epoch 18/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2542 - val_loss: 0.2572\n",
      "Epoch 19/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2162 - val_loss: 0.2127\n",
      "Epoch 20/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2105 - val_loss: 0.2102\n",
      "Epoch 21/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2109 - val_loss: 0.2113\n",
      "Epoch 22/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2075 - val_loss: 0.2099\n",
      "Epoch 23/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2086 - val_loss: 0.2169\n",
      "Epoch 24/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2100 - val_loss: 0.2126\n",
      "Epoch 25/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2100 - val_loss: 0.2129\n",
      "Epoch 26/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2096 - val_loss: 0.2123\n",
      "Epoch 27/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2111 - val_loss: 0.2152\n",
      "Epoch 28/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2097 - val_loss: 0.2178\n",
      "Epoch 29/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2105 - val_loss: 0.2135\n",
      "Epoch 30/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2061 - val_loss: 0.2087\n",
      "Epoch 31/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2051 - val_loss: 0.2086\n",
      "Epoch 32/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2057 - val_loss: 0.2108\n",
      "Epoch 33/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2051 - val_loss: 0.2083\n",
      "Epoch 34/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2050 - val_loss: 0.2086\n",
      "Epoch 35/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2045 - val_loss: 0.2085\n",
      "Epoch 36/1000\n",
      "168/168 [==============================] - 2s 15ms/step - loss: 0.2049 - val_loss: 0.2089\n",
      "Epoch 37/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2051 - val_loss: 0.2095\n",
      "Epoch 38/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2051 - val_loss: 0.2091\n",
      "Epoch 39/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2044 - val_loss: 0.2089\n",
      "Epoch 40/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2050 - val_loss: 0.2093\n",
      "Epoch 41/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2035 - val_loss: 0.2082\n",
      "Epoch 42/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2041 - val_loss: 0.2083\n",
      "Epoch 43/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2031 - val_loss: 0.2084\n",
      "Epoch 44/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2029 - val_loss: 0.2081\n",
      "Epoch 45/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2036 - val_loss: 0.2085\n",
      "Epoch 46/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2026 - val_loss: 0.2083\n",
      "Epoch 47/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2035 - val_loss: 0.2083\n",
      "Epoch 48/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2031 - val_loss: 0.2082\n",
      "Epoch 49/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2024 - val_loss: 0.2082\n",
      "Epoch 50/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2027 - val_loss: 0.2084\n",
      "Epoch 51/1000\n",
      "168/168 [==============================] - 2s 15ms/step - loss: 0.2035 - val_loss: 0.2082\n",
      "Epoch 52/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2021 - val_loss: 0.2081\n",
      "Epoch 53/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2030 - val_loss: 0.2085\n",
      "Epoch 54/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2030 - val_loss: 0.2080\n",
      "Epoch 55/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2025 - val_loss: 0.2082\n",
      "Epoch 56/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2029 - val_loss: 0.2084\n",
      "Epoch 57/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2020 - val_loss: 0.2083\n",
      "Epoch 58/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2027 - val_loss: 0.2081\n",
      "Epoch 59/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2027 - val_loss: 0.2082\n",
      "Epoch 60/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2022 - val_loss: 0.2082\n",
      "Epoch 61/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2027 - val_loss: 0.2082\n",
      "Epoch 62/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2024 - val_loss: 0.2082\n",
      "Epoch 63/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2023 - val_loss: 0.2082\n",
      "Epoch 64/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2030 - val_loss: 0.2084\n",
      "Epoch 65/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2022 - val_loss: 0.2082\n",
      "Epoch 66/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2024 - val_loss: 0.2082\n",
      "Epoch 67/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2024 - val_loss: 0.2082\n",
      "Epoch 68/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2030 - val_loss: 0.2082\n",
      "Epoch 69/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2023 - val_loss: 0.2082\n",
      "Epoch 70/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2019 - val_loss: 0.2082\n",
      "Epoch 71/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2030 - val_loss: 0.2082\n",
      "Epoch 72/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2024 - val_loss: 0.2082\n",
      "Epoch 73/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2020 - val_loss: 0.2082\n",
      "Epoch 74/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2022 - val_loss: 0.2082\n",
      "Fold 1 NN: 0.20804\n",
      "CV 2/5\n",
      "Epoch 1/1000\n",
      "168/168 [==============================] - 3s 14ms/step - loss: 21.9121 - val_loss: 1.4011\n",
      "Epoch 2/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.9851 - val_loss: 0.3961\n",
      "Epoch 3/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.4175 - val_loss: 0.8362\n",
      "Epoch 4/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.7475 - val_loss: 0.7770\n",
      "Epoch 5/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.6535 - val_loss: 0.5682\n",
      "Epoch 6/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.6449 - val_loss: 0.3952\n",
      "Epoch 7/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.4443 - val_loss: 0.2375\n",
      "Epoch 8/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.3583 - val_loss: 4.0136\n",
      "Epoch 9/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 1.4122 - val_loss: 0.5092\n",
      "Epoch 10/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.4573 - val_loss: 0.4684\n",
      "Epoch 11/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.4218 - val_loss: 0.4736\n",
      "Epoch 12/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.4040 - val_loss: 0.4293\n",
      "Epoch 13/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.3925 - val_loss: 0.3914\n",
      "Epoch 14/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.4086 - val_loss: 0.3973\n",
      "Epoch 15/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2436 - val_loss: 0.2209\n",
      "Epoch 16/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2115 - val_loss: 0.2212\n",
      "Epoch 17/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2129 - val_loss: 0.2189\n",
      "Epoch 18/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2101 - val_loss: 0.2228\n",
      "Epoch 19/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2131 - val_loss: 0.2188\n",
      "Epoch 20/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2100 - val_loss: 0.2220\n",
      "Epoch 21/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2103 - val_loss: 0.2186\n",
      "Epoch 22/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2083 - val_loss: 0.2176\n",
      "Epoch 23/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2090 - val_loss: 0.2188\n",
      "Epoch 24/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2098 - val_loss: 0.2194\n",
      "Epoch 25/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2085 - val_loss: 0.2205\n",
      "Epoch 26/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2093 - val_loss: 0.2199\n",
      "Epoch 27/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2072 - val_loss: 0.2636\n",
      "Epoch 28/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2200 - val_loss: 0.2199\n",
      "Epoch 29/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2096 - val_loss: 0.2287\n",
      "Epoch 30/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2066 - val_loss: 0.2175\n",
      "Epoch 31/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2043 - val_loss: 0.2163\n",
      "Epoch 32/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2036 - val_loss: 0.2155\n",
      "Epoch 33/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2041 - val_loss: 0.2164\n",
      "Epoch 34/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2034 - val_loss: 0.2148\n",
      "Epoch 35/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2036 - val_loss: 0.2151\n",
      "Epoch 36/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2038 - val_loss: 0.2163\n",
      "Epoch 37/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2031 - val_loss: 0.2167\n",
      "Epoch 38/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2050 - val_loss: 0.2180\n",
      "Epoch 39/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2036 - val_loss: 0.2177\n",
      "Epoch 40/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2042 - val_loss: 0.2220\n",
      "Epoch 41/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2041 - val_loss: 0.2141\n",
      "Epoch 42/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2035 - val_loss: 0.2158\n",
      "Epoch 43/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2037 - val_loss: 0.2223\n",
      "Epoch 44/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2061 - val_loss: 0.2171\n",
      "Epoch 45/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2050 - val_loss: 0.2158\n",
      "Epoch 46/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2041 - val_loss: 0.2205\n",
      "Epoch 47/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2039 - val_loss: 0.2173\n",
      "Epoch 48/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2042 - val_loss: 0.2151\n",
      "Epoch 49/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2012 - val_loss: 0.2156\n",
      "Epoch 50/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2007 - val_loss: 0.2147\n",
      "Epoch 51/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2006 - val_loss: 0.2144\n",
      "Epoch 52/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2008 - val_loss: 0.2147\n",
      "Epoch 53/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2005 - val_loss: 0.2151\n",
      "Epoch 54/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2013 - val_loss: 0.2164\n",
      "Epoch 55/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2006 - val_loss: 0.2164\n",
      "Epoch 56/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2000 - val_loss: 0.2143\n",
      "Epoch 57/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2007 - val_loss: 0.2159\n",
      "Epoch 58/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2008 - val_loss: 0.2148\n",
      "Epoch 59/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2002 - val_loss: 0.2146\n",
      "Epoch 60/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.1999 - val_loss: 0.2152\n",
      "Epoch 61/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2001 - val_loss: 0.2151\n",
      "Fold 2 NN: 0.21413\n",
      "CV 3/5\n",
      "Epoch 1/1000\n",
      "168/168 [==============================] - 3s 14ms/step - loss: 27.1964 - val_loss: 0.4628\n",
      "Epoch 2/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.7759 - val_loss: 0.4966\n",
      "Epoch 3/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.5979 - val_loss: 0.4275\n",
      "Epoch 4/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.5655 - val_loss: 0.2336\n",
      "Epoch 5/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.3999 - val_loss: 0.5090\n",
      "Epoch 6/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.5625 - val_loss: 0.5934\n",
      "Epoch 7/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.5493 - val_loss: 0.8357\n",
      "Epoch 8/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.5307 - val_loss: 0.4121\n",
      "Epoch 9/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.4929 - val_loss: 0.4269\n",
      "Epoch 10/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.5536 - val_loss: 0.6061\n",
      "Epoch 11/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.4923 - val_loss: 0.4062\n",
      "Epoch 12/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2433 - val_loss: 0.2170\n",
      "Epoch 13/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2166 - val_loss: 0.2215\n",
      "Epoch 14/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2153 - val_loss: 0.2163\n",
      "Epoch 15/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2144 - val_loss: 0.2219\n",
      "Epoch 16/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2157 - val_loss: 0.2166\n",
      "Epoch 17/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2139 - val_loss: 0.2203\n",
      "Epoch 18/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2142 - val_loss: 0.2157\n",
      "Epoch 19/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2130 - val_loss: 0.2315\n",
      "Epoch 20/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2157 - val_loss: 0.2147\n",
      "Epoch 21/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2132 - val_loss: 0.2127\n",
      "Epoch 22/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2130 - val_loss: 0.2202\n",
      "Epoch 23/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2128 - val_loss: 0.2147\n",
      "Epoch 24/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2147 - val_loss: 0.2164\n",
      "Epoch 25/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2111 - val_loss: 0.2198\n",
      "Epoch 26/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2129 - val_loss: 0.2189\n",
      "Epoch 27/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2144 - val_loss: 0.2179\n",
      "Epoch 28/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2188 - val_loss: 0.2189\n",
      "Epoch 29/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2088 - val_loss: 0.2111\n",
      "Epoch 30/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2061 - val_loss: 0.2108\n",
      "Epoch 31/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2057 - val_loss: 0.2110\n",
      "Epoch 32/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2055 - val_loss: 0.2103\n",
      "Epoch 33/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2055 - val_loss: 0.2105\n",
      "Epoch 34/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2054 - val_loss: 0.2108\n",
      "Epoch 35/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2064 - val_loss: 0.2100\n",
      "Epoch 36/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2058 - val_loss: 0.2107\n",
      "Epoch 37/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2051 - val_loss: 0.2107\n",
      "Epoch 38/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2046 - val_loss: 0.2108\n",
      "Epoch 39/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2055 - val_loss: 0.2139\n",
      "Epoch 40/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2064 - val_loss: 0.2112\n",
      "Epoch 41/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2056 - val_loss: 0.2107\n",
      "Epoch 42/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2048 - val_loss: 0.2108\n",
      "Epoch 43/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2036 - val_loss: 0.2100\n",
      "Epoch 44/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2038 - val_loss: 0.2116\n",
      "Epoch 45/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2032 - val_loss: 0.2097\n",
      "Epoch 46/1000\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.2041 - val_loss: 0.2096\n",
      "Epoch 47/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2033 - val_loss: 0.2098\n",
      "Epoch 48/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2031 - val_loss: 0.2109\n",
      "Epoch 49/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2032 - val_loss: 0.2094\n",
      "Epoch 50/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2029 - val_loss: 0.2118\n",
      "Epoch 51/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2027 - val_loss: 0.2096\n",
      "Epoch 52/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2031 - val_loss: 0.2096\n",
      "Epoch 53/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2024 - val_loss: 0.2103\n",
      "Epoch 54/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2031 - val_loss: 0.2095\n",
      "Epoch 55/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2028 - val_loss: 0.2099\n",
      "Epoch 56/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2022 - val_loss: 0.2098\n",
      "Epoch 57/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2028 - val_loss: 0.2095\n",
      "Epoch 58/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2016 - val_loss: 0.2096\n",
      "Epoch 59/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2021 - val_loss: 0.2095\n",
      "Epoch 60/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2018 - val_loss: 0.2097\n",
      "Epoch 61/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2014 - val_loss: 0.2094\n",
      "Epoch 62/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2020 - val_loss: 0.2095\n",
      "Epoch 63/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2022 - val_loss: 0.2094\n",
      "Epoch 64/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2019 - val_loss: 0.2095\n",
      "Epoch 65/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2024 - val_loss: 0.2095\n",
      "Epoch 66/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2016 - val_loss: 0.2094\n",
      "Epoch 67/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2009 - val_loss: 0.2094\n",
      "Epoch 68/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2022 - val_loss: 0.2093\n",
      "Epoch 69/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2019 - val_loss: 0.2093\n",
      "Epoch 70/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2019 - val_loss: 0.2093\n",
      "Epoch 71/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2019 - val_loss: 0.2094\n",
      "Epoch 72/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2020 - val_loss: 0.2094\n",
      "Epoch 73/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2013 - val_loss: 0.2094\n",
      "Epoch 74/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2019 - val_loss: 0.2094\n",
      "Epoch 75/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2019 - val_loss: 0.2093\n",
      "Epoch 76/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2017 - val_loss: 0.2094\n",
      "Epoch 77/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2015 - val_loss: 0.2094\n",
      "Epoch 78/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2012 - val_loss: 0.2094\n",
      "Epoch 79/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2020 - val_loss: 0.2094\n",
      "Epoch 80/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2018 - val_loss: 0.2094\n",
      "Epoch 81/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2016 - val_loss: 0.2094\n",
      "Epoch 82/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2013 - val_loss: 0.2094\n",
      "Epoch 83/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2020 - val_loss: 0.2093\n",
      "Epoch 84/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2023 - val_loss: 0.2093\n",
      "Epoch 85/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2013 - val_loss: 0.2094\n",
      "Epoch 86/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2017 - val_loss: 0.2094\n",
      "Epoch 87/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2020 - val_loss: 0.2094\n",
      "Epoch 88/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2012 - val_loss: 0.2094\n",
      "Fold 3 NN: 0.20933\n",
      "CV 4/5\n",
      "Epoch 1/1000\n",
      "168/168 [==============================] - 3s 14ms/step - loss: 30.9251 - val_loss: 0.7084\n",
      "Epoch 2/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.8927 - val_loss: 1.0739\n",
      "Epoch 3/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.8807 - val_loss: 0.4952\n",
      "Epoch 4/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.7500 - val_loss: 0.6789\n",
      "Epoch 5/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.7631 - val_loss: 1.0370\n",
      "Epoch 6/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.8319 - val_loss: 0.6331\n",
      "Epoch 7/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.9598 - val_loss: 0.6129\n",
      "Epoch 8/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.6052 - val_loss: 0.5130\n",
      "Epoch 9/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.6388 - val_loss: 0.3789\n",
      "Epoch 10/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.5315 - val_loss: 0.3613\n",
      "Epoch 11/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.4926 - val_loss: 0.6363\n",
      "Epoch 12/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.6737 - val_loss: 0.3243\n",
      "Epoch 13/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.4249 - val_loss: 0.4145\n",
      "Epoch 14/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.3983 - val_loss: 0.3943\n",
      "Epoch 15/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.3790 - val_loss: 0.2654\n",
      "Epoch 16/1000\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.3750 - val_loss: 0.2959\n",
      "Epoch 17/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.6593 - val_loss: 0.2275\n",
      "Epoch 18/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2276 - val_loss: 0.2348\n",
      "Epoch 19/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2197 - val_loss: 0.2251\n",
      "Epoch 20/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2294 - val_loss: 0.2581\n",
      "Epoch 21/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2315 - val_loss: 0.2193\n",
      "Epoch 22/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2241 - val_loss: 0.2867\n",
      "Epoch 23/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2347 - val_loss: 0.2710\n",
      "Epoch 24/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2381 - val_loss: 0.2263\n",
      "Epoch 25/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2373 - val_loss: 0.2235\n",
      "Epoch 26/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2393 - val_loss: 0.2202\n",
      "Epoch 27/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2378 - val_loss: 0.3266\n",
      "Epoch 28/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.3031 - val_loss: 0.2252\n",
      "Epoch 29/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2121 - val_loss: 0.2156\n",
      "Epoch 30/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2067 - val_loss: 0.2150\n",
      "Epoch 31/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2069 - val_loss: 0.2143\n",
      "Epoch 32/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2057 - val_loss: 0.2136\n",
      "Epoch 33/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2062 - val_loss: 0.2145\n",
      "Epoch 34/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2070 - val_loss: 0.2152\n",
      "Epoch 35/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2048 - val_loss: 0.2179\n",
      "Epoch 36/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2064 - val_loss: 0.2167\n",
      "Epoch 37/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2064 - val_loss: 0.2146\n",
      "Epoch 38/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2063 - val_loss: 0.2224\n",
      "Epoch 39/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2080 - val_loss: 0.2202\n",
      "Epoch 40/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2044 - val_loss: 0.2133\n",
      "Epoch 41/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2031 - val_loss: 0.2125\n",
      "Epoch 42/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2026 - val_loss: 0.2130\n",
      "Epoch 43/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2028 - val_loss: 0.2128\n",
      "Epoch 44/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2025 - val_loss: 0.2135\n",
      "Epoch 45/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2027 - val_loss: 0.2132\n",
      "Epoch 46/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2028 - val_loss: 0.2126\n",
      "Epoch 47/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2018 - val_loss: 0.2128\n",
      "Epoch 48/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2023 - val_loss: 0.2129\n",
      "Epoch 49/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2017 - val_loss: 0.2126\n",
      "Epoch 50/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2018 - val_loss: 0.2127\n",
      "Epoch 51/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2016 - val_loss: 0.2131\n",
      "Epoch 52/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2017 - val_loss: 0.2132\n",
      "Epoch 53/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2018 - val_loss: 0.2132\n",
      "Epoch 54/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2012 - val_loss: 0.2125\n",
      "Epoch 55/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2021 - val_loss: 0.2129\n",
      "Epoch 56/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2016 - val_loss: 0.2126\n",
      "Epoch 57/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2012 - val_loss: 0.2125\n",
      "Epoch 58/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2012 - val_loss: 0.2126\n",
      "Epoch 59/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2008 - val_loss: 0.2127\n",
      "Epoch 60/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2009 - val_loss: 0.2125\n",
      "Epoch 61/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2012 - val_loss: 0.2126\n",
      "Fold 4 NN: 0.21246\n",
      "CV 5/5\n",
      "Epoch 1/1000\n",
      "168/168 [==============================] - 3s 14ms/step - loss: 29.4215 - val_loss: 0.6674\n",
      "Epoch 2/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 1.1018 - val_loss: 1.0812\n",
      "Epoch 3/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.8865 - val_loss: 0.8318\n",
      "Epoch 4/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.7732 - val_loss: 0.5486\n",
      "Epoch 5/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.6579 - val_loss: 0.6239\n",
      "Epoch 6/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.5487 - val_loss: 0.6969\n",
      "Epoch 7/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.5476 - val_loss: 0.4766\n",
      "Epoch 8/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.7102 - val_loss: 0.6606\n",
      "Epoch 9/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.5504 - val_loss: 0.5104\n",
      "Epoch 10/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.5207 - val_loss: 0.5754\n",
      "Epoch 11/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.9960 - val_loss: 0.4844\n",
      "Epoch 12/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.4079 - val_loss: 0.3781\n",
      "Epoch 13/1000\n",
      "168/168 [==============================] - 3s 18ms/step - loss: 0.3795 - val_loss: 0.3867\n",
      "Epoch 14/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.3336 - val_loss: 0.2531\n",
      "Epoch 15/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2369 - val_loss: 0.2308\n",
      "Epoch 16/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2461 - val_loss: 0.4570\n",
      "Epoch 17/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 2.4569 - val_loss: 0.2581\n",
      "Epoch 18/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2462 - val_loss: 0.2492\n",
      "Epoch 19/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.2337 - val_loss: 0.2432\n",
      "Epoch 20/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2304 - val_loss: 0.2366\n",
      "Epoch 21/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2290 - val_loss: 0.2304\n",
      "Epoch 22/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2267 - val_loss: 0.2283\n",
      "Epoch 23/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2355 - val_loss: 0.2225\n",
      "Epoch 24/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.5988 - val_loss: 0.3115\n",
      "Epoch 25/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.3274 - val_loss: 0.2206\n",
      "Epoch 26/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2312 - val_loss: 0.2187\n",
      "Epoch 27/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2196 - val_loss: 0.2317\n",
      "Epoch 28/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2333 - val_loss: 0.2238\n",
      "Epoch 29/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2221 - val_loss: 0.2264\n",
      "Epoch 30/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2330 - val_loss: 0.2322\n",
      "Epoch 31/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2394 - val_loss: 0.2229\n",
      "Epoch 32/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2219 - val_loss: 0.2507\n",
      "Epoch 33/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2284 - val_loss: 0.2664\n",
      "Epoch 34/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2127 - val_loss: 0.2158\n",
      "Epoch 35/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2072 - val_loss: 0.2156\n",
      "Epoch 36/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2068 - val_loss: 0.2184\n",
      "Epoch 37/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2070 - val_loss: 0.2149\n",
      "Epoch 38/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2067 - val_loss: 0.2150\n",
      "Epoch 39/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2072 - val_loss: 0.2164\n",
      "Epoch 40/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2055 - val_loss: 0.2157\n",
      "Epoch 41/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2051 - val_loss: 0.2143\n",
      "Epoch 42/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2056 - val_loss: 0.2164\n",
      "Epoch 43/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2051 - val_loss: 0.2166\n",
      "Epoch 44/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2048 - val_loss: 0.2141\n",
      "Epoch 45/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2058 - val_loss: 0.2155\n",
      "Epoch 46/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2087 - val_loss: 0.2150\n",
      "Epoch 47/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2062 - val_loss: 0.2165\n",
      "Epoch 48/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2070 - val_loss: 0.2222\n",
      "Epoch 49/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2071 - val_loss: 0.2235\n",
      "Epoch 50/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2072 - val_loss: 0.2153\n",
      "Epoch 51/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2056 - val_loss: 0.2226\n",
      "Epoch 52/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2031 - val_loss: 0.2128\n",
      "Epoch 53/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2017 - val_loss: 0.2131\n",
      "Epoch 54/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2010 - val_loss: 0.2138\n",
      "Epoch 55/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2010 - val_loss: 0.2143\n",
      "Epoch 56/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2012 - val_loss: 0.2131\n",
      "Epoch 57/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2012 - val_loss: 0.2152\n",
      "Epoch 58/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2021 - val_loss: 0.2127\n",
      "Epoch 59/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2008 - val_loss: 0.2139\n",
      "Epoch 60/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2006 - val_loss: 0.2131\n",
      "Epoch 61/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.1999 - val_loss: 0.2128\n",
      "Epoch 62/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2003 - val_loss: 0.2125\n",
      "Epoch 63/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.1999 - val_loss: 0.2129\n",
      "Epoch 64/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.1999 - val_loss: 0.2134\n",
      "Epoch 65/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2005 - val_loss: 0.2130\n",
      "Epoch 66/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.1999 - val_loss: 0.2138\n",
      "Epoch 67/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2006 - val_loss: 0.2138\n",
      "Epoch 68/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2005 - val_loss: 0.2131\n",
      "Epoch 69/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2000 - val_loss: 0.2128\n",
      "Epoch 70/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2000 - val_loss: 0.2129\n",
      "Epoch 71/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2000 - val_loss: 0.2130\n",
      "Epoch 72/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.1997 - val_loss: 0.2134\n",
      "Epoch 73/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2002 - val_loss: 0.2127\n",
      "Epoch 74/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.1993 - val_loss: 0.2128\n",
      "Epoch 75/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2002 - val_loss: 0.2132\n",
      "Epoch 76/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.1995 - val_loss: 0.2127\n",
      "Epoch 77/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.1997 - val_loss: 0.2130\n",
      "Epoch 78/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.1995 - val_loss: 0.2129\n",
      "Epoch 79/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.1999 - val_loss: 0.2130\n",
      "Epoch 80/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.1995 - val_loss: 0.2129\n",
      "Epoch 81/1000\n",
      "168/168 [==============================] - 2s 15ms/step - loss: 0.1999 - val_loss: 0.2129\n",
      "Epoch 82/1000\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.1997 - val_loss: 0.2129\n",
      "Fold 5 NN: 0.21252\n"
     ]
    }
   ],
   "source": [
    "from numpy.random import seed\n",
    "seed(2021)\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(2021)\n",
    "from tensorflow import keras\n",
    "\n",
    "target_name='target'\n",
    "scores_folds = {}\n",
    "model_name = 'NN'\n",
    "pred_name = 'pred_{}'.format(model_name)\n",
    "\n",
    "n_folds = 5\n",
    "kf = model_selection.KFold(n_splits=n_folds, shuffle=True, random_state=2021)\n",
    "scores_folds[model_name] = []\n",
    "counter = 1\n",
    "\n",
    "features_to_consider = list(train1)\n",
    "\n",
    "features_to_consider.remove('time_id')\n",
    "features_to_consider.remove('target')\n",
    "try:\n",
    "    features_to_consider.remove('pred_NN')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n",
    "train1[features_to_consider] = train1[features_to_consider].fillna(train1[features_to_consider].mean())\n",
    "test1[features_to_consider] = test1[features_to_consider].fillna(train1[features_to_consider].mean())\n",
    "\n",
    "train1[pred_name] = 0\n",
    "test1[target_name] = 0\n",
    "test_predictions_nn1 = np.zeros(test_nn.shape[0])\n",
    "\n",
    "for n_count in range(n_folds):\n",
    "    print('CV {}/{}'.format(counter, n_folds))\n",
    "    \n",
    "    indexes = np.arange(nfolds).astype(int)    \n",
    "    indexes = np.delete(indexes,obj=n_count, axis=0) \n",
    "    \n",
    "    indexes = np.r_[values[indexes[0]],values[indexes[1]],values[indexes[2]],values[indexes[3]]]\n",
    "    \n",
    "    X_train = train1.loc[train1.time_id.isin(indexes), features_to_consider]\n",
    "    y_train = train1.loc[train1.time_id.isin(indexes), target_name]\n",
    "    X_test = train1.loc[train1.time_id.isin(values[n_count]), features_to_consider]\n",
    "    y_test = train1.loc[train1.time_id.isin(values[n_count]), target_name]\n",
    "    \n",
    "    #############################################################################################\n",
    "    # NN\n",
    "    #############################################################################################\n",
    "    \n",
    "    model = base_model()\n",
    "    \n",
    "    model.compile(\n",
    "        keras.optimizers.Adam(learning_rate=0.006),\n",
    "        loss=root_mean_squared_per_error\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        features_to_consider.remove('stock_id')\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    num_data = X_train[features_to_consider]\n",
    "    \n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))         \n",
    "    num_data = scaler.fit_transform(num_data.values)    \n",
    "    \n",
    "    cat_data = X_train['stock_id']    \n",
    "    target =  y_train\n",
    "    \n",
    "    num_data_test = X_test[features_to_consider]\n",
    "    num_data_test = scaler.transform(num_data_test.values)\n",
    "    cat_data_test = X_test['stock_id']\n",
    "\n",
    "    model.fit([cat_data, num_data], \n",
    "              target,               \n",
    "              batch_size=2048,\n",
    "              epochs=1000,\n",
    "              validation_data=([cat_data_test, num_data_test], y_test),\n",
    "              callbacks=[es, plateau],\n",
    "              validation_batch_size=len(y_test),\n",
    "              shuffle=True,\n",
    "             verbose = 1)\n",
    "\n",
    "    preds = model.predict([cat_data_test, num_data_test]).reshape(1,-1)[0]\n",
    "    \n",
    "    score = round(rmspe(y_true = y_test, y_pred = preds),5)\n",
    "    print('Fold {} {}: {}'.format(counter, model_name, score))\n",
    "    scores_folds[model_name].append(score)\n",
    "    \n",
    "    tt =scaler.transform(test_nn[features_to_consider].values)\n",
    "    #test_nn[target_name] += model.predict([test_nn['stock_id'], tt]).reshape(1,-1)[0].clip(0,1e10)\n",
    "    test_predictions_nn1 += model.predict([test1['stock_id'], tt]).reshape(1,-1)[0].clip(0,1e10)/n_folds\n",
    "    #test[target_name] += model.predict([test['stock_id'], test[features_to_consider]]).reshape(1,-1)[0].clip(0,1e10)\n",
    "       \n",
    "    counter += 1\n",
    "    features_to_consider.append('stock_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "sonic-universe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-26T14:31:52.746929Z",
     "iopub.status.busy": "2021-09-26T14:31:52.746255Z",
     "iopub.status.idle": "2021-09-26T14:31:52.773686Z",
     "shell.execute_reply": "2021-09-26T14:31:52.773109Z"
    },
    "papermill": {
     "duration": 14.167182,
     "end_time": "2021-09-26T14:31:52.773838",
     "exception": false,
     "start_time": "2021-09-26T14:31:38.606656",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0-4</td>\n",
       "      <td>0.002513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0-32</td>\n",
       "      <td>0.002156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0-34</td>\n",
       "      <td>0.002156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  row_id    target\n",
       "0    0-4  0.002513\n",
       "1   0-32  0.002156\n",
       "2   0-34  0.002156"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test=pd.read_csv(\"../input/optiver-realized-volatility-prediction/test.csv\")\n",
    "a=test_predictions_nn*0.57+predictions_lgb2*0.43*0.985\n",
    "b=test_predictions_nn1*0.57*0.986+predictions_lgb1*0.43\n",
    "c = (nn_pres*0.987 +predictions_lgb+model1_predictions)/3\n",
    "test[target_name] = (a+b+c)/3\n",
    "\n",
    "display(test[['row_id', target_name]].head(3))\n",
    "test[['row_id', target_name]].to_csv('submission.csv',index = False)\n",
    "#test[['row_id', target_name]].to_csv('submission.csv',index = False)\n",
    "#kmeans N=5 [0.2101, 0.21399, 0.20923, 0.21398, 0.21175]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "complete-economics",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-26T14:32:21.145123Z",
     "iopub.status.busy": "2021-09-26T14:32:21.144392Z",
     "iopub.status.idle": "2021-09-26T14:32:21.150508Z",
     "shell.execute_reply": "2021-09-26T14:32:21.151026Z"
    },
    "papermill": {
     "duration": 14.255515,
     "end_time": "2021-09-26T14:32:21.151260",
     "exception": false,
     "start_time": "2021-09-26T14:32:06.895745",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test[['row_id', target_name]].to_csv('submission.csv',index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 18543.918789,
   "end_time": "2021-09-26T14:32:37.521232",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-09-26T09:23:33.602443",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
